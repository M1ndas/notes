cron {
	problems {
		#1 {
			- given a cronjob:
				* * * * * (time ruby /home/mindaugas/test1.tb $(date -d 'yesterday' '+\%Y-\%m-\%d')) >> /home/mindaugas/my.log 2>&1
			- it produces the given output:
				time: cannot run ruby: No such file or directory
				Command exited with non-zero status 127
				0.00user 0.00system 0:00.00elapsed ?%CPU (0avgtext+0avgdata 336maxresident)k
				0inputs+8outputs (0major+72minor)pagefaults 0swaps

			- Q: why can't it run ruby?	
				- This has the answer: http://unix.stackexchange.com/questions/76862/running-time-command-with-cron

			- Q: how to derive the answer by yourself
				- a command that would show whether you are calling a shell built in or an executable ===> `type` 
				- http://superuser.com/questions/351889/what-is-the-unix-command-to-find-out-what-executable-file-corresponds-to-a-given
				- you can compare the output when `type` is run from the shell or from the cron

					> mindaugas@Mindaugas-Lenovo-Y50-70:~/Ruby_Scripts/Crontab_Test$ type time
					> time is a shell keyword

					> mindaugas@Mindaugas-Lenovo-Y50-70:~/Ruby_Scripts/Crontab_Test$ cat my.log 
					> time is /usr/bin/time
		}

		#2 {
			* * * * * /bin/bash -c "(time ruby /home/mindaugas/test1.tb $(date -d 'yesterday' '+\%Y-\%m-\%d'))" >> /home/mindaugas/my.log 2>&1
			* * * * * /bin/bash -c "(sleep 10; time (ruby -e "puts \"a\n\"";))" >> /home/mindaugas/my.log 2>&1 
				"an";)): -c: line 1: syntax error: unexpected end of file
				/bin/bash: ruby: command not found

			* * * * * /bin/bash -c "(time ruby /home/mindaugas/test1.tb $(date -d 'yesterday' '+\%Y-\%m-\%d')) >> /home/mindaugas/my.log 2>&1"
			* * * * * /bin/bash -c "(sleep 10; (time ruby -e \"puts \\\"a\\\n\\\"\") >> /home/mindaugas/my.log 2>&1"


			0 1 * * * /bin/bash -c "(echo ""; echo $(date -d 'yesterday' '+\%Y-\%m-\%d'); \
				time /home/zulu/.rvm/rubies/ruby-2.2.2/bin/ruby /home/WAF_report_automation_II_.rb $(date -d 'yesterday' '+\%Y-\%m-\%d')) >> /home/the.log 2>&1"
		}

		#3 {
			sudo -u "mindaugas" /bin/bash -c "ruby --help" 					===> /bin/bash: ruby: command not found
			sudo -u "mindaugas" /bin/bash -c "/home/mindaugas/.rbenv/shims/ruby --help" 	===> works OK.
			The answer: http://askubuntu.com/questions/23009/reasons-why-crontab-does-not-work
		}
	}

	- 0 * * * * - this means the cron will run always when the minutes are 0 (so hourly)
	- 0 1 * * * - this means the cron will run always at 1 o'clock.
	- * 1 * * * - this means the cron will run each minute when the hour is 1. So 1:00, 1:01, ...1:59.
	- 0 0 * * * - every day at midnight

	- Run cron every half a minute
	  * * * * * /usr/bin/php /home/kaunas3/public_html/current/app/console pitaks:getTableAPI 1
	  * * * * * (sleep 30; /usr/bin/php /home/kaunas3/public_html/current/app/console pitaks:getTableAPI 1)

	 * * * * *  command to execute
	 â”¬ â”¬ â”¬ â”¬ â”¬
	 â”‚ â”‚ â”‚ â”‚ â”‚
	 â”‚ â”‚ â”‚ â”‚ â”‚
	 â”‚ â”‚ â”‚ â”‚ â””â”€â”€â”€â”€â”€ day of week (0 - 7) (0 to 6 are Sunday to Saturday, or use names; 7 is Sunday, the same as 0)
	 â”‚ â”‚ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ month (1 - 12)
	 â”‚ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ day of month (1 - 31)
	 â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ hour (0 - 23)
	 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ min (0 - 59)

	- grep CRON /var/log/syslog 	===> cron logs
	- grep run-parts /etc/crontab	===> check when the daily and other crons are running

		01 * * * * root run-parts /etc/cron.hourly
		02 4 * * * root run-parts /etc/cron.daily
		22 4 * * 0 root run-parts /etc/cron.weekly
		42 4 1 * * root run-parts /etc/cron.monthly
}


logrotate {
	- logrotate --force | -f 			===> will rotate file(s) even if they do not meet the specified criteria such as minsize, age, etc.
	- cat /var/lib/logrotate/logrotate.status	===> check logrotate status
		logrotate state -- version 2
		"/var/opt/rh/rh-php70/log/php-fpm/error.log" 2019-11-3-2:39:7
		"/var/log/yum.log" 2020-11-19-4:4:17
		"/var/log/firewalld" 2020-11-14-2:0:0
		
	- logrotate -d /etc/logrotate.conf 2>&1 	===> for grepping when using debug (debug is also DRY RUN!)
	- logrotate -d /etc/logrotate.d/httpd 		===> launch logrotate with debug output for a specific configuration (debug is also DRY RUN!), example output:
		reading config file /etc/logrotate.d/httpd
		Allocating hash table for state file, size 15360 B

		Handling 1 logs

		rotating pattern: /home/sos03/logs/*log  1048576 bytes (no old logs will be kept)
		empty log files are not rotated, old logs are removed
		considering log /home/sos03/logs/www.sos03.lt_access.log
		  log needs rotating
		considering log /home/sos03/logs/www.sos03.lt_error.log
		  log needs rotating
		rotating log /home/sos03/logs/www.sos03.lt_access.log, log->rotateCount is 0
		dateext suffix '-20201227'
		glob pattern '-[0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9]'
		renaming /home/sos03/logs/www.sos03.lt_error.log.1 to /home/sos03/logs/www.sos03.lt_error.log.2 (rotatecount 1, logstart 1, i 1),
		renaming /home/sos03/logs/www.sos03.lt_error.log.0 to /home/sos03/logs/www.sos03.lt_error.log.1 (rotatecount 1, logstart 1, i 0),
		renaming /home/sos03/logs/www.sos03.lt_access.log to /home/sos03/logs/www.sos03.lt_access.log.1
		disposeName will be /home/sos03/logs/www.sos03.lt_access.log.1
		renaming /home/sos03/logs/www.sos03.lt_error.log to /home/sos03/logs/www.sos03.lt_error.log.1
		disposeName will be /home/sos03/logs/www.sos03.lt_error.log.1
		running postrotate script
		running script with arg /home/sos03/logs/*log : "
			/bin/systemctl reload httpd.service > /dev/null 2>/dev/null || true
		"
		removing old log /home/sos03/logs/www.sos03.lt_access.log.1
		error: error opening /home/sos03/logs/www.sos03.lt_access.log.1: No such file or directory
		
	- http logrotate configuration:
		/home/sos03/logs/*.log {
		    daily
		    notifempty
		    missingok
		    sharedscripts
		    delaycompress
		    postrotate
			/bin/systemctl reload httpd.service > /dev/null 2>/dev/null || true
		    endscript
		}
}

Vim {
	- :w !sudo tee % > /dev/null 				===> save contents in a write protected file while not root.
	- dd 							===> delete the whole current line;
	- dG 							===> delete all lines in one blow;
	- D or d$ 						===> to delete the [rest of the] line and continue in command mode;
	- C or c$ 						===> to delete the [rest of the] line and continue in insert mode;
	- :u 							===> undo the change;
	- Ctrl-R 						===> redo the changes that were undone;
	- :u1|u 						===> undo all changes remembered by vim for the current buffer;
	- :set nu 						===> turns on line numbering in vi;
	- :set nu! 						===> turns off the line numbering in vi;
	- 42G 							===> go to line 42;
	- :%s/foo/bar/g 					===> substitute feature: "find each occurrence of 'foo' (in all lines), and replace it with 'bar'.""
	- :%s/db\(\d\).example.com/db\1.zozole.com/g 		===> a more involved vi/vim substitute feature w/ regex pattern and capture groups 
	- :set paste 						===> paste mode, gives a nice indentation;
	- ctrl + v; arrow down ; shift + I ; # ; esc		===> commenting all the lines;
	- ctrl + v; arrow down ; x ; esc			===> delete first symbol from multiple lines
	- :g/^\s*$/d 						===> delete all lines that contain a pattern;
	- :g!/^\s*"/d 						===> delete all lines that do not contain a pattern;
	- :v/^\s*"/d 						===> --||--
	- shift + g 						===> jump to EOF;
	- 1G 							===> jump to the first line;
	- gg 							===> --||--
	- VG 							===> visual select to the end of the file
	- :%y+ 							===> yank the lines from a file to a clipboard, will not work in ZU for some reason;
	- :r some_test_file 					===> read in some text file and adds its contents starting at the current cursor possition;

	searching {
		- /<search_patern> + enter 			===> jump to the following occurance;
		- /<search_patern> + enter + n 			===> jump to the next occurance;
		- /<search_patern> + enter + N 			===> jump to the previous occurance;
	}

	~/.vimrc or /etc/vim/vimrc {
		syntax on     		" Activate Syntax highlighting
		set nu          	" Activate Line numbers
		set expandtab  		" Set Tab Intent 
		set shiftwidth=4 	" set shift width for tab  
		set softtabstop=2 
	}

}

Angular {
	- ng new app + robocopy app app2 /MIR /NFL /NDL /NJH /NJS /nc /ns /np
	- Measure-Command { ng new appdelete }
		Minutes           : 0
		Seconds           : 37
		Milliseconds      : 255
	- Measure-Command { robocopy CourseNestUi2 CourseNestUi3 /MIR /NFL /NDL /NJH /NJS /nc /ns /np }
		Minutes           : 0
		Seconds           : 20
		Milliseconds      : 646
}

Docker {
	Networking:
		- docker network 			===> list all the choises
		- docker network ls 			===> list all the available networks
		- docker network inspect <net-name> 	===> mode details on the network
		- docker info 				===> see the docker network drivers available
		- docker network create -d bridge --subnet 10.0.0.1/24 <net-name> 	===> create a named bridge network (bridge allow communication on a single host)
		- docker0 				===> the default bridge with the name bridge
		
	Connecting from one container to another:
		- First approach - use the hosts ip address to connect to it:
			- 1. Check the ip of the container you want to connect to: docker inspect -f '{{range.NetworkSettings.Networks}}{{.IPAddress}}{{end}}' b4 ==> 172.17.0.2
			- 2. Connect from the other container used the obtained IP address (using telnet if the container has it).
		- Second approach use the shared network:
			- $ docker network create pg
			- $ docker run -d -e POSTGRES_PASSWORD=password --network=pg --name postgres postgres:9-alpine
			- $ docker run -d -p 5050:5050 --name pgadmin --network=pg thajeztah/pgadmin4
		- Third approach: using docker compose you should be able to connect using the hostname.
			- This does not work when --hostname is provided in the command line from an individual container
			- Example configuration to connect PG admin that is installed as a container and Postgress DB using hostname pg_db:
			
				version: '3.7'
				services:
				  pg_admin:
				    image: dpage/pgadmin4
				    ports:
				      - 5050:80
				    environment:
				      PGADMIN_DEFAULT_EMAIL: 'a@b.com'
				      PGADMIN_DEFAULT_PASSWORD: 'qwertyui'
				  pg_db:
				    image: postgres
				    ports:
				      - 5432:5432
				    environment:
				      POSTGRES_PASSWORD: 'pass'
				      PGDATA: '/var/lib/postgresql/data/pgdata'
				    volumes:
				      - ./db:/var/lib/postgresql/data
				      
		      	- Just run: docker-compose up -d after that 
		
	Dockerfile:
		- RUN apt-get update -y && apt-get install -y openssl zip unzip git vim iputils-ping procps

	Docker-compose:
		- command: bash -c 'sleep 10'
		- command: bash -c 'php artisan migrate:fresh --seed && php artisan serve --host 0.0.0.0'

	Docker:
		- docker-compose build
		- docker-compose up -d
		- docker ps
		- docker-compose ps
		- docker images
		- docker stop $(docker ps -aq)
		- docker stop ID ID2
		- docker exec -it <contid> bash 	===> execute bash on a runnning image
		- docker run -it <imgid> bash		===> run 
		- docker run -d test_app
		- docker inspect -f '{{range .NetworkSettings.Networks}}{{.IPAddress}}{{end}}' 324
		- docker inspect mysql | grep Address
		- docker rm ID ID2
		- docker top
		- docker run -d --name mysql -e MYSQL_ROOT_PASSWORD=123456 mysql:5.7
		- docker run -d --name mysql ID

	Rebuild the container:
		- docker stop $(docker ps -aq)
		- docker rm $(docker ps -aq)
		- docker ps -a
		- docker rm ID
		- docker-compose build
		- docker-compose up -d
		- docker run ID
		- docker run ID && docker exec -it ID bash
		- docker system prune -a

	Run container with docker:
		- docker images
		- docker run -d IMAGE ID
		- docker exec -it mysql bash

	Tshoot docker mysql:
		- You must delete the mapped volume if you change the password
		- docker run -d --name mysql -e MYSQL_ROOT_PASSWORD=123456 mysql:8
		- docker exec -it mysql bash
		- mysql -uroot -p123456 -h 127.0.0.1
}

Python {
	syntax tricks {
		- with open("testfile.txt", "r") as f: print([attr for attr in dir(f)]) 				===> all attributes
		- with open("testfile.txt", "r") as f: print([attr for attr in dir(f) if not attr.startswith('_')])  	===> non dunder attributes
	}

	one liners {
		$ printf "{"\"a\"":{},"\"b"\":{}}" | python -m json.tool | python -c 'import sys, json; print json.load(sys.stdin)["a"]'  ===> parse json with python one liner
		$ printf "{"\"a\"":{},"\"b"\":["\"abg\"","\"bg\"","\"yu\""]}" | python3 -m json.tool | python3 -c $"import sys, json;print(json.load(sys.stdin))"
		$ printf "{"\"a\"":{},"\"b"\":["\"abg\"","\"bg\"","\"yu\""]}" | python3 -m json.tool | python3 -c 'import sys, json; [print(foo) for foo in json.load(sys.stdin)["b"]]'
		$ cat caching_yell | python3 -m json.tool | python3 -c 'import sys, json; [print(foo["_source"]["timestamp"]) for foo in json.load(sys.stdin)["hits"]["hits"]]' 
		$ cat caching_yell | python3 -m json.tool | python3 -c 'import sys, json; [print("{}".format(foo["_source"]["http_request"]["headers"])) for foo in json.load(sys.stdin)["hits"]["hits"]]' 2>/dev/null | head -n 1
		$ cat caching_yell | python3 -m json.tool | python3 -c 'import sys, json; [print("{}".format(foo["_source"]["http_request"]["headers"])) for foo in json.load(sys.stdin)["hits"]["hits"]]' | tail -n 1
		$ cat caching_yell | python3 -m json.tool | python3 -c 'import sys, json; [print("{} -- {}".format(foo["_source"]["http_request"]["headers"], foo["_source"]["@timestamp"])) for foo in json.load(sys.stdin)["hits"]["hits"]]' | grep -Po "(?<=\"cookie\":)\".*?(?=\",)"  | perl -pne 's/\n/\n\n/g' | grep -Po "__ZEHIC=\w*(?=;)"
		$ cat caching_yell | python3 -m json.tool | python3 -c 'import sys, json; [print("{} -- {}".format(foo["_source"]["http_request"]["headers"], foo["_source"]["@timestamp"])) for foo in json.load(sys.stdin)["hits"]["hits"]]' | perl -pne 's/(?:.*)(__ZEHIC=\w*(?=;));\s(__z_a=\w*(?=;));(?:.+)\"user-agent\":\"(.+")}\s--\s(.*)/\1\t\2\t\3\t\4/g'
	}

	################# TCP client #################
	import socket
	target_host = "www.google.com"
	target_port = 80

	# create a socket object The AF_INET parameter is saying 
	# we are going to use a standard IPv4 address or hostname, 
	# and SOCK_STREAM indicates that this will be a TCP client.
	client = socket.socket(socket.AF_INET, socket.SOCK_STREAM)

	# connect the client
	client.connect((target_host,target_port))

	# send some data
	client.send("GET / HTTP/1.1\r\nHost: google.com\r\n\r\n")

	# receive some data
	response = client.recv(4096)

	print response


	################# UDP client #################
	import socket
	target_host = "127.0.0.1"
	target_port = 80

	# create a socket object
	client = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)

	# send some data. Because UDP is a connectionless protocol, 
	# there is no call to connect() beforehand.
	client.sendto("AAABBBCCC",(target_host,target_port))

	# receive some data ===> yes, i Python you can return multiple values
	data, addr = client.recvfrom(4096)
	print data
	print addr


	################# TCP server #################
	import socket
	import threading

	bind_ip   = "0.0.0.0"
	bind_port = 9999

	server = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
	server.bind((bind_ip,bind_port))
	server.listen(5) # maximum backlog of connections set to 5

	print "[*] Listening on %s:%d" % (bind_ip,bind_port)

	# this is our client-handling thread
	def handle_client(client_socket):
		# print out what the client sends
		request = client_socket.recv(1024)
		print "[*] Received: %s" % request

	# send back a packet
	client_socket.send("ACK!")
	client_socket.close()

	while True:
		client,addr = server.accept()
		print "[*] Accepted connection from: %s:%d" % (addr[0],addr[1])
		# spin up our client thread to handle incoming data
		client_handler = threading.Thread(target=handle_client,args=(client,))
		client_handler.start()
}

seaborn {
	- sns.heatmap(data=data_obj, annot=True)		===> heatmap
	- sns.scatterplot(x=insurance_data['bmi'], y=insurance_data['charges'], hue=insurance_data['smoker'])
	- sns.lmplot(x="bmi", y="charges", hue="smoker", data=insurance_data)
	- sns.swarmplot(x=candy_data['chocolate'], y=candy_data['winpercent']) 	===> categorical scatterplot
}

pandas {
	- pd.read_csv("data.csv", index_col="Platform") 			===> read CSV data
	- dataFrame.to_csv(r'C:\export_dataframe.csv', index=False)
	- df.columns								===> get all the column names
	- reviews['index_backwards'] = range(len(reviews), 0, -1)
	- reviews.iloc[0]							===> first row
	- reviews.iloc[:, 0]							===> first coll
	- reviews.iloc[[1,2,3,5,8], :]						===> row w/ some specific values (1,2,3,5,8) as the first collumn
	- reviews.loc[[0,1,10,100], ['country', 'province', 'region_1', 'region_2']] ===> specific rows and collumns
	- reviews.loc[((reviews.country == 'Australia') | (reviews.country == 'New Zealand')) & (reviews.points >= 95)]
	- loc[0:100, :] - returns 100th record included (so 101 recs); iloc[0:100, :] - excluded 
 	- ign_data.loc['PC',:].max()						===> get max value for a specific row w/ name 'PC' for the index_col
	- ign_data.loc['PlayStation Vita',:].idxmin()				===> get the name of the label for a minimum value
	- pd.Series([1, 2, 3]).values ===> returns values from pandas series array([1, 2, 3])
	- _aj = candy_data[candy_data['competitorname'] == 'Almond Joy']['winpercent'].values[0]
	- sns.distplot(a=iris_data['Petal Length (cm)'], kde=False) 		===> histogram
	- sns.kdeplot(data=iris_data['Petal Length (cm)'], shade=True)	
	- sns.jointplot(x=iris_data['Petal Length (cm)'], y=iris_data['Sepal Width (cm)'], kind="kde")
	- sns.distplot(...), sns.distplot(...), plt.legend() 			===> histograms per species
	- sns.lineplot(x="timepoint", y="signal", data=fmri)			===> 
	- plt.plot([1, 2, 3, 4], [1, 4, 9, 16])
	- pd.DataFrame({'Yes': [50, 21], 'No': [131, 2]}, index=['Product A', 'Product B'])
	- pd.Series(['4 cups','1 cup','2 large','1 can'], index=['Flour', 'Milk', 'Eggs', 'Spam'], name='Dinner')
	- pd.Series([t, f], index=['tropical', 'fruity']) 			===> creating a pandas series from two numbers 
	- reviews.points.map(lambda p: p - review_points_mean)
	- reviews.points.map(lambda p: 3 if p >= 95 else 1) 			===> map from pd using lambda
	- reviews.apply(remean_points, axis='columns')
	- L = [1, 2, 3, 4] ;; list(map(lambda x: x**2, L))
	- pd.coll.value_counts() 						===> get counts for occurences of each value
	- max_idx = (reviews.points / reviews.price).idxmax() ;; bargain_wine = reviews.loc[max_idx, 'title'] ===> wine with higest point to price ratio
	- reviews.groupby('winery').apply(lambda df: df.title.iloc[0]) 		===> group wines by winery and then access first review
	- reviews.groupby(['country', 'province']).apply(lambda df: df.loc[df.points.idxmax()]) ===> best wine by country and province
	- reviews.groupby(['country']).price.agg([len, min, max]) 		===> run a bunch of functions on a df
	- reviews.groupby('variety')['price'].agg(['min', 'max'])		===> group by a column and select the max and min of another column
	- countries_reviewed.reset_index() 					===> from multi index to regular index
	- countries_reviewed.sort_values(by='len', ascending=False) 		===> sort by value (default is by index)
	- countries_reviewed.sort_index() 					===> sort by index
	- countries_reviewed.sort_values(by=['country', 'len'])			===> sort by multiple collumns
	- countries_reviewed.sort_values(by=['countr', 'len'], ascending=False) ===> by multicol in ascending order	
	- reviews.groupby('taster_twitter_handle').size() 			===> group by with count
	- reviews.groupby('taster_twitter_handl').taster_twitter_handle.count() ===> another group by with count
	- reviews.groupby('price')['points'].max().sort_index() 		===> group by price selecting the max of collumn points while grouping. Then, sort by the price (which is the index collumn)
	- reviewer_mean_ratings.describe()					===> mean, count and other stats about the series
	- reviews.groupby(['country', 'variety']).size().sort_values(ascending=False) ===> group, count variety (last col grouped) and sort
	- reviews.dtypes							===> get datatype of a column in a dataframe or series (string is indeicated as object)
	- reviews.points.astype('float64')					===> convert datatypes
	- reviews[pd.isnull(reviews.country)]					===> select all reviews where country values missing
	- reviews.region_2.fillna("Unknown")					===> replace missing values with word
	- len(reviews[pd.isnull(reviews.price)])				===> count all the reviews where prices is missing
	- reviews.rename(columns={'region_1': 'region', 'region_2':'locale'})	===> rename column
	- reviews.rename_axis('wines')						===> set the value to 'wines' of the index column
	- set_index()								===> rename index
	- pd.concat([canadian_youtube, british_youtube])			===> 
	- concat(), join(), and merge()
	- left.join(right, lsuffix='_CAN', rsuffix='_UK')
	- df.dropna(axis=0)							===> drop missing data
}

scikit-learn, sklearn {
	
	from sklearn.tree import DecisionTreeRegressor
	from sklearn.metrics import mean_absolute_error
	melbourne_features = ['Rooms', 'Bathroom', 'Landsize']
	X = melbourne_data[melbourne_features]
	melbourne_model = DecisionTreeRegressor(random_state=1) 		===> random_state to ensure same results each run
	melbourne_model.fit(X, y)						===> 
	print(melbourne_model.predict(X.head()))				===>
	mean_absolute_error(y, predicted_home_prices) 
	
	
	from sklearn.model_selection import train_test_split
	# Supplying a numeric value to the random_state argument guarantees we get the same split every time we run this script.
	train_X, val_X, train_y, val_y = train_test_split(['LotArea', 'YearBuilt', '1stFlrSF'], home_data.SalePrice, random_state = 0) 
	melbourne_model = DecisionTreeRegressor()
	melbourne_model.fit(train_X, train_y)
	val_predictions = melbourne_model.predict(val_X)
	print(mean_absolute_error(val_y, val_predictions))
	
	
	from sklearn.metrics import mean_absolute_error
	from sklearn.tree import DecisionTreeRegressor
	def get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y):
	    model = DecisionTreeRegressor(max_leaf_nodes=max_leaf_nodes, random_state=0)
	    model.fit(train_X, train_y)
	    preds_val = model.predict(val_X)
	    mae = mean_absolute_error(val_y, preds_val)
	    return(mae)
    	# compare MAE with differing values of max_leaf_nodes
	for max_leaf_nodes in [5, 50, 500, 5000]:
	    my_mae = get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y)
	    print("Max leaf nodes: %d  \t\t Mean Absolute Error:  %d" %(max_leaf_nodes, my_mae))
	    
	    
	from sklearn.ensemble import RandomForestRegressor
	from sklearn.metrics import mean_absolute_error

	forest_model = RandomForestRegressor(random_state=1)
	forest_model.fit(train_X, train_y)
	melb_preds = forest_model.predict(val_X)
	print(mean_absolute_error(val_y, melb_preds))
	
	
	import numpy as np
	import pandas as pd
	from sklearn.model_selection import train_test_split
	from sklearn.ensemble import RandomForestClassifier
	
	data = pd.read_csv('../input/fifa-2018-match-statistics/FIFA 2018 Statistics.csv')
	y = (data['Man of the Match'] == "Yes")  # Convert from string "Yes"/"No" to binary
	feature_names = [i for i in data.columns if data[i].dtype in [np.int64]]
	X = data[feature_names]
	train_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1)
	my_model = RandomForestClassifier(n_estimators=100, random_state=0).fit(train_X, train_y)
	
	import eli5
	from eli5.sklearn import PermutationImportance
	
	perm = PermutationImportance(my_model, random_state=1).fit(val_X, val_y)
	eli5.show_weights(perm, feature_names = val_X.columns.tolist())
	
	
	import numpy as np
	import pandas as pd
	from sklearn.model_selection import train_test_split
	from sklearn.ensemble import RandomForestClassifier
	from sklearn.tree import DecisionTreeClassifier

	data = pd.read_csv('../input/fifa-2018-match-statistics/FIFA 2018 Statistics.csv')
	y = (data['Man of the Match'] == "Yes")  # Convert from string "Yes"/"No" to binary
	feature_names = [i for i in data.columns if data[i].dtype in [np.int64]]
	X = data[feature_names]
	train_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1)
	tree_model = DecisionTreeClassifier(random_state=0, max_depth=5, min_samples_split=5).fit(train_X, train_y)
	
	#### DECISION TREE VISUALIZED ####
	from sklearn import tree
	import graphviz
	tree_graph = tree.export_graphviz(tree_model, out_file=None, feature_names=feature_names)
	graphviz.Source(tree_graph)
	
	
	#### PARTIAL DEPENDENCE PLOT ####
	from matplotlib import pyplot as plt
	from pdpbox import pdp, get_dataset, info_plots
	pdp_goals = pdp.pdp_isolate(model=tree_model, dataset=val_X, model_features=feature_names, feature='Goal Scored')
	pdp.pdp_plot(pdp_goals, 'Goal Scored')
	plt.show()
	
	#### 2D PARTIAL DEPENDENCE PLOT ####
	# use pdp_interact instead of pdp_isolate and pdp_interact_plot instead of pdp_isolate_plot
	features_to_plot = ['Goal Scored', 'Distance Covered (Kms)']
	inter1 = pdp.pdp_interact(model=tree_model, dataset=val_X, model_features=feature_names, features=features_to_plot)
	pdp.pdp_interact_plot(pdp_interact_out=inter1, feature_names=features_to_plot, plot_type='contour')
	plt.show()
	
}

valgrind {
	- valgrind ./prog.exe
	- valgrind -v ./prog.exe
	- valgrind --leak-check=full ./prog.exe
}

jQuery {
	- $('.table_class').rows.length 			===> get the number of rows in the table
	- $('.list2_body > tr:nth-child(1) > td:nth-child(7)')	===> get the value of a table cell in the first row
	- $x("//a[contains(text(), 'OS QC')]")			===> using xpath w/ contains text pattern 
	- $x("//a[contains(string(), 'OS QC')]")		===> this is more robust and works better than text() (which is actually not an xpath function; 
	- $x("//tbody[@class='list2_body']")			===> using xpath w/ class name
	- $x("//tbody[@class='x']/tr[position()=$variable]")	===> 
	- https://devhints.io/xpath
}

Lets encrypt {
	- autorenew with email {
		#!/bin/bash
		# Ref: https://developerinsider.co/how-to-create-and-auto-renew-lets-encrypt-wildcard-certificate/
		. <({ cb_err=$({ cb_out=$(/usr/bin/certbot renew --post-hook "service apache2 restart"); } 2>&1; declare -p cb_out >&2); declare -p cb_err; } 2>&1)

		# If certificate renewal issue if something other than "not up for renewal" - send the email
		if [[ "${cb_err//$'\n'/ }" == "Saving debug log to /var/log/letsencrypt/letsencrypt.log Cert not yet due for renewal" ]]; then
			printf "Hi,<br><br>Certbot renewal failed with:<h3>Stdout:</h3>%s<h3>Stderr:</h3>%s<br><br>Server time: %s" \
				"${cb_out//$'\n'/<br/>}" "${cb_err//$'\n'/<br>}" "$(date)" \
				| mail -s "Certbot Renewal Issue" -a "Content-type: text/html" darbas.mindaugas@gmail.com
		fi

	}

}

Linux mail, postfix {
	- netstat -ltnp | grep 25 				===> check if postfix is running;
	- sudo dpkg-reconfigure postfix 			===> reconfigure postfix
	- apt-get install --reinstall postfix 			===> reinstall postfix (helped on 2019.08.31 w/ Coin_Trade project)
	
	- Enabling SMTP over TLS on postfix
		# TLS parameters
		smtpd_tls_cert_file=/etc/ssl/certs/ssl-cert-snakeoil.pem
		smtpd_tls_key_file=/etc/ssl/private/ssl-cert-snakeoil.key
		# MINDAUGAS :: START - configuring secure email sending (SMTP orver TLS, not SMIME)
		# smtpd_use_tls=yes
		smtp_tls_security_level = may
		smtpd_tls_security_level = may
		# MINDAUGAS :: END
		# Ref: https://askubuntu.com/questions/875986/how-to-set-up-tls-for-postfix-on-ubuntu
		# Ref: https://serverfault.com/questions/931476/how-to-send-encrypted-message-using-postfix
}


Splunk {
	- cat metrics.log | grep -Po "name=(.+?), blocked=true, max_size.+?(?=,)" | sort | uniq -c 	===> get the status and the size of queues from the logs
	- https://docs.splunk.com/Documentation/Forwarder/7.3.1/Forwarder/HowtoforwarddatatoSplunkEnterprise 
	- config example C:\Program Files\SplunkUniversalForwarder\etc\system\local:
		[default]
		host = IVV-win2016

		[tcpout]
		defaultGroup = splunk

		[tcpout:splunk]
		server = 10.150.16.200:XXX

		[WinEventLog://Security]
		disabled = 0
	- logs: C:\Program Files\SplunkUniversalForwarder\var\log\splunk\splunkd.txt:
		08-08-2019 06:23:20.944 -0400 ERROR TcpOutputProc - LightWeightForwarder/UniversalForwarder not configured. Please configure outputs.conf.
}

PowerShell {
	Commands {
		- Measure-Command { echo hi } 		===> benchmark a command
		- (Get-ChildItem | Out-String) -split "`n" | Select-String app 	===> grep for a directory named "app" (more complicated as PS is Object oriented not text based)
		- Get-PSSnapin 				===> extend using commandlets or snapins. Both are extension packages. Check availability of snapins.
		- Get-PSSnapin -Registered 		===> same as above
		- Get-Module -ListAvailable 		===> find modules
		- $PSversiontable 			===> 
		- get-date | select dayofweek
		- Get-PSSnapin -Registered
		- Get-Module -ListAvailable
		- for ($i=0; $i -le 10; $i++){echo $i};		===> simple for loop;
		- Get-WmiObject Win32_Service | Where-Object {$_.Name -Like '*Splunk*'} | Select-Object Name,Path,CommandLine ===> get the command line arguments passed to a service that is already running.
	}

	Dojo {
		- Illustrate why you want the screen buffer size to the same as the window size;
		- Load a module into memory and prove that module loading is a per-process thing (once you start a new PS process you have to load the modules again);
		- Script the whole SQL server installation (custom install and sharedcomponents directory, creation of users for the SQLAgent, SSIS and so on);
	}

	Q {
		- Explain the difference between the console and the ISE. --> Ise is the INTEGRATED SCRIPTING ENVIRONEMENT and provides you some of the capabilities of comfortable scripting; You would use console orientation for calling commands and ISE for writing advanced scripts or commandlets;
		- What is a commandlet? --> a pre-made script / command that can be user in powershell;
		- Why is a profile script usefull? --> It will load modules and snapins on powershell load and othervise you would have to do it in every new powershell window;
	}

	Set Up A Domain {
		- the lab domain would help when doing powershell remoting - issuing commands to other forest and especially untrusting forests is where things get interesting!
		- You can do it with CloudShare.com - which is an inexpensive and lets you spin up DC's and other types of windows VM's from templatesl;
		- VHD test drive - some pre-made virtual mashines in a form of HyperV runnable virtual hard drives (VHD's);
	}
}


Wordpress maintenance {
	- define('FS_METHOD','direct'); 	===> If WP asks for FTP credentials durring version upgrade it can't write to some directory. This is solvable by adding this directive.
	Deactivate plugins {
		- mysql -u <> -p
		- show databases;
		- use <>;
		- show tables;
		- SELECT option_name,option_value FROM wp_options WHERE option_name = 'active_plugins';
		- UPDATE wp_options SET option_value = 'a:0:{}' WHERE option_name = 'active_plugins';
	}
	- cd /var/www/html/wordpress/
	- sudo rm -rf /var/www/html/wordpress/wp-admin
	- sudo rm -rf /var/www/html/wordpress/wp-includes
	- sudo mv /home/mindaugas/wp_5.2/wordpress/* /var/www/html/wordpress/
	- http://blog.mindaugas.cf/wp-admin/upgrade.php
	- reenable plugins from the UI;
	
	iptables rules to allow all outbound traffic (not tested as of 2019-06-02) {
		- sudo iptables -I OUTPUT -o venet0 -d 0.0.0.0/0 -j ACCEPT
		- sudo iptables -I INPUT -i venet0 -m state --state ESTABLISHED,RELATED -j ACCEPT
	}
}

Go / Golang {
	- https://golang.org/doc/code.html 	===> for testing conventions
	- go test -v 				===> log all tests as run. Print all text from Log, Logf calls even if test succeeds;
	- fmt.Println(reflect.TypeOf(a)) 	===> getting the type of variable (import reflect needed)
	- os.Getwd()				===> getting the executable directory (import os)
	- go build -i -o binary packagename 	===> building an executable with custom name (go install does not support that @ 1.12)
	- for index, element := range someStructuArr {
        	fmt.Println("Index :", index," Element :", element)        
    	  }					===> go iterate over an array of structs
}

- Making windows7 go to sleep after 10minutes 	===> timeout /T 360 & rundll32.exe powrprof.dll,SetSuspendState 0,1,0

Salt {
	Commands {
		- curl -L https://bootstrap.saltstack.com -o install-salt.sh 	===> downloads the intall script;
		- sudo sh install-salt.sh -M -A 127.0.0.1	===> install on master: -M master, -A minions master, -I minions id;
		- sudo sh install-salt.sh -A 192.168.1.105	===> install on minion;
		- sudo salt-key 				===> list keys;
		- sudo salt-key -F <mažo_jono_id>		===> check the key fingerprint for specific minion on master;
		- sudo salt-call --local key.finger 		===> check the key fingerprint on minion;
		- sudo salt '*' test.ping 			===> check if minion is reachable;
		----- minion targeting expressions ------
		- sudo salt mast* test.ping 			===> run only on minions that start with mast;
		- sudo salt mast? test.ping 			===> similar, but exactly one char;
		- sudo salt -E '(master|web1)' test.ping 	===> target salt minions using regex;
		- sudo salt -S 10.10.0.0/16 test.ping 		===> target salt minions using regex;
		- sudo salt -C 'S@192.168.0.0/16 and E@(master|web1)' ===> combined minion targetting expression;
		-----------------------------------------
	}
	
	Concepts {
		- Default minion ports: 4505, 4506;
		- Default communication protocol: TCP;
		- ZeroMQ is the underlying queue mechanism - 4096 bit keys are used;
		- cmd.run - cmd execution module executes the command with root account!
	}
	
	Katas {
		- tail -f streaming from 2 hosts;
	}
}

Jenkins {
	Pipeline sprint {
	--------------------------------
		pipeline {
		    agent { label 'VDOS_windows' }
		    // agent any

		    stages {
			stage('Build') {
			    steps {
				echo 'Building..'
			    }
			}
			stage('Test') {
			    steps {
				echo 'Testing..'
			    }
			}
			stage('Deploy') {
			    steps {
				echo 'Deploying....'
			    }
			}
			stage('Get hostname') {
			    steps {
				cmd_exec('wmic computersystem get name')
			    }
			}
		    }
		}

		def cmd_exec(command) {
		    return bat(returnStdout: true, script: "${command}").trim()
		}
	--------------------------------
	}
}
Jenkins Script Console {
	// println(Jenkins.instance.metaClass.methods*.name)
	// Jenkins.instance.getJobProperty()
	String executors = Jenkins.instance.getNumExecutors();
	String jobNames;
	String[] jobNamesArr;
	// jobNames = Jenkins.instance.getJobNames().split('\\s+');
	jobNames = Jenkins.instance.getJobNames()
	jobNamesArr = jobNames.split(',')
	println("Executor count: " + executors);

	jobNamesArr.each{ val -> 
	   println(val)
	}

	return 0;
}

for i in {1..100}; do echo 1; sleep 1 ; done | pv -l -r > /dev/null           /:: [0.998/s ]            --> using pv for counting lines per second added to the file

SEO {
	- site:blog.mindaugas.cf 	===> test whether google/bing/yandex has indexed your site
	- https://support.wix.com/en/article/optimize-your-site-for-seo
	https://www.semrush.com/info/mindaugas.cf
	https://www.searchenginegenie.com/google-rank-checker.html
	https://www.seocentro.com/tools/search-engines/keyword-position.html
	https://www.alexa.com/siteinfo/mindaugas.cf
	
	Adding a sitemap {
		- WP plugins add a sitemap (and or sitemap index file, for several sitemaps). E.g.: Jetpack.
	}
	
	Adding a robots.txt file {
		- WP adds robots.txt file automatically;
	}

	Index on google.com {}
	Index on bing {}
	Index on pinterest {}
	Index on yandex {}
	Index on yahoo {}
}

Web Services {
	- SOAP started the WS-* movement, this is supposed to show how advanced it is and how it showed the possibilities that webservices could provide. SOA term appeared after the intorduction of SOAP;
	- Message formats: POX, XML, JSON, binary (AMF, they are smaller, but not human readable), text;
	- XML-RPC, ODATA, SOAP, REST;
	- Webservices as secured with: authentification (i) (pass, token based auth) and encryption (ii) (SSL);
	- RESOURCES {
		- http://en.wikipedia.org/wiki/List_of_open_APIs
		- https://services.explorecalifornia.org/~desolveo/explorecalservices/rss/tours.php
		- https://services.explorecalifornia.org/~desolveo/explorecalservices/pox/tours.php
		- https://services.explorecalifornia.org/~desolveo/explorecalservices/json/tours.php
		- https://services.explorecalifornia.org/rss/tours.php?packageid=1
		- chrome-extension://<ID_OF_EXTENSION>/<page_like_index.html> :: chrome-extension://cokgbflfommojglbmbpenpphppikmonn/index.html
		- http://maps.googleapis.com/maps/api/geocode/xml?address=New_York&sensor=false
		- http://maps.googleapis.com/maps/api/geocode/json?address=New_York&sensor=false
		ASA webservices start appearing the viligers of oblivion started to think - "how oh, how we will discover all the possible webservices?". Two ways in general - a search engine and an index. Here are some indexes:
		- http://www.xmethods.net:5868/ve2/index.po
		- http://www.service-repository.com/
		- http://www.programmableweb.com/ 
	}
	- Rest is by definition stateless. It started to gain traction due to advances in mobile computing - mobile devices have less storage and have internet connectivity chargable by the megabytes, so it is better to have a JSON complient webservice (more like architecture) - REST;
	- developing a SOAP web service you are freed from any serialization or deserialization issues - this is handled for you by the library the you and your server use to communicate with each other; 
}

Matrices {
	- A matrix is a rectangular array of numbers, terms or equations
	- Definition: http://mathworld.wolfram.com/Matrix.html
	- Usage in computer graphics: http://gamedev.stackexchange.com/questions/68522/what-does-a-matrix-represent
	- representing social relations: http://faculty.ucr.edu/~hanneman/nettext/C5_%20Matrices.html
	- My question on Quora: http://www.quora.com/What-is-an-example-of-a-problem-that-can-be-solved-with-matrices-but-at-first-glance-does-not-appear-to-have-any-relation-to-matrices
}

SQL SERVER {

	Reconnecting to SQL server after all acounts are lost {
		- Launch SQL server with the necessary CMD parameters in single user mode {
			- D:
			- cd '.\Program_Files\Microsoft SQL Server\MSSQL11.MINDAUGAS_MSI\MSSQL\Binn>'
			.\sqlservr.exe -sMINDAUGAS_MSI '-lD:\Program_Files\Microsoft SQL Server\MSSQL11.MINDAUGAS_MSI\MSSQL\DATA\mastlog.ldf' '-eD:\Program_Files\Microsoft SQL Server\MSSQL11.MINDAUGAS_MSI\MSSQL\Log\ERRORLOG' '-dD:\Program_Files\Microsoft SQL Server\MSSQL11.MINDAUGAS_MSI\MSSQL\DATA\master.mdf' -f
			- in another CMD session call the SQLCMD -S <server_name\instance_name>
		}
		- Launch SQLCMD in another console and connect to the launched server: SQLCMD â€“S <Server_Name\Instance_Name> {
			- CREATE LOGIN <name_with_no_qoutes> with PASSWORD = '<pass_with_qoutes>' 
			- GO
			- SP_ADDSRVRROLEMEMBER <name_with_no_qoutes>,<pass_no_qoutes>
			- GO
		}
		- select * from master..syslogins --> check if you have created a log in from SQLCMD;
	}

	- A distributed select query (a select from more than two servers) can be performed most easilly with linked servers. To add a linked server user systemic stored procedure: sp_addlinkedserver("server_name");
	- The process of copying an entire instance of database with all the data to your machine is - backup and restore;
	- The difference between GETDATE(), SYSDATETIME() and CURRENT_TIMESTAMP is --> that only SYSDATETIME() provides nanosecond precision.

	- SQL datagen script performance {
		- turn of printing to console --> SET NOCOUNT ON
		- if you are using the DBCC turn off the trace information --> DBCC	FREEPROCCACHE WITH NO_INFOMSGS {
			- how to find out system traces: SELECT * FROM sys.traces
			- any DBCC command should be followed by WITH NO_INFOMSGS flag :: for example: DBCC	FREEPROCCACHE WITH NO_INFOMSGS; -- Removes all elements from the plan cache, a specific plan from the plan cache by specifying a plan handle or SQL handle, or removes all cache entries associated with a specified resource pool.
		}
		- With (SET NOCOUNT ON) && (DBCC FREEPROCCACHE WITH NO_INFOMSGS) --> time for 10k searches :: 536525 ms --> 8.94208333 minutes
		- Without --> 565921 ms 9.43202 minutes
		- There is one good thing for removing logging - SSMS does not claim much more memory - only SQL server. This eliminates the need to run the SQL script from CMD;
		- 
	}

	Renaming the host that hosts a standalone SQL server {
		- select @@servername --> returns a different host name after you change the hosts name. When you change the name of the computer that is running SQL Server, the new name is recognized during SQL Server startup. You do not have to run Setup again to reset the computer name. Instead, use the following steps to update system metadata that is stored in sys.servers and reported by the system function @@SERVERNAME;
		- Use these statementes in condution with select @@servername and select * from sys.servers ::
			sp_dropserver <old_name\instancename>;
			GO
			sp_addserver <new_name\instancename>, local;
			GO
		- after than you will successfully open the replication configuration window;
	}

	Temporary tables{
		- "#" - local temp table starts with (created  by one connection, deleted once that connection is closed);
		- "##" - global temp table (created  by one connection, deleted once all connections have been closed because available for all of them);
		- CREATE TABLE #LocalTempTable(UserID int,UserName varchar(50));
		- insert into #LocalTempTable values (1, 'Abhijit'); // same for global except "##";
		- select * from #LocalTempTable; // select * from ##GlobalTempTable;
		- Invalid object name '#LocalTempTable'. >> because the scope of Local Temporary table is only bounded with the current connection of current user.
		- Temporary tables are stored in "Temporary Tables directory" (you can see it in the MS SQL management studio objet explorer);
		- Temporary table created on tempdb of SQL Server. This is a separate database. So, this is an additional overhead and can causes performance issues. 
		- Number of rows and columns need to be as minimum as needed.
		- Tables need to be deleted when they are done with their work.
		- Alternative approach is TABLE variable {
			- Declare @TempTableVariable TABLE(UserID int, UserName varchar(50));
			- It is usefull for less data;
		}
		- I can use temporary table - for performance testing results
		- Export temporary tables into .csv or .xlsx{
			- bcp ##myData out MyData.txt -c -T
			- sqlcmd -S MyServer -d myDB -E -Q "select col1, col2, col3 from SomeTable" -o "MyData.csv" -h-1 -s"," -w 700
			- STEP-BY-STEP tutorial: http://www.sqlservercurry.com/2011/01/sql-server-export-table-to-csv.html
			- STEP-BY-STEP tutorial: http://www.66pacific.com/sql_server_export_to_excel.aspx
		}
	}

	Installing MS SQL Management Studio Developers Ed.{
		- Uninstall all SQL tools from Microsoft that you have already;
		- Create new users for some important SQL Server utilities (like SQL Agent, Integration Services, Reporting Services). This is a recomended approach :: In Computer management > Local usr .. > Users; You will be able to plug those users in durring the installation;
		- Delete the registry keys (check online which) OR trys this :: http://it.toolbox.com/blogs/programming-life/sql-server-2008-install-changing-install-path-when-its-defaulted-and-read-only-28355
		- If you choose the registry keys option, then run this command when launching the set up: H:\>setup.exe /action=install /INSTALLSHAREDDIR="F:\Program_Files\Microsoft SQL Server" /INSTALLSHAREDWOWDIR="F:\Program_Files_x86\Microsoft SQL Server"
	}

	Postinstall {
		- Take a look at the SQL Server Configurations Manager, to launch services, check the internet connection configuration and so on;
	}

	Transactional Replication {
		- you can replicate sharded tables : rows only (i). You can have a filter that would filter the things you want replicated (ii) - but don't get too complex because the evaluation happens row by row and can degrade performance - or you can replicate everything (indexes and tables) (iii) -> you can publish Sproc's, views and so on, even DDL commands;
		- the distributor collects data changes by reading log file and stores into the DISTRIBUTION database. 1 distributor per publisher (but many subscribers).
		- PERFORMANCE TIP 1: the best practice is to have a dedicated distributor to unload the work from the main server. That's actually the purpose of replication - unload all the work you can from the master server. THE DECENTRALIZATION OF WORK;
		- PERFORMANCE TIP 2: if you have many subscribers use Pull approach (again distributing the work as much to the local level as possible) - one subscriber: ok to use push;
		- All replication is controlled by SQL Agent jobs (so enable that SQL server component);
		- Replication read from the log file and makes some records in the log file, so that when it's restarted it knows where to start from;
		- Uses SSIS for large amounts of data (log shipping) && when some transformation is needed on that data (ETL processes allow transformation, replication does not) - t-rep for lightweight continuous data-rep;
		- When you configure a remote server to be a distributor configure it to have an file size increases of more than 10MB;
		- To support pull subscriptions created at the Subscriber you need to specify a newtork path that the snapshot will be available in;
		- UnauthorizedAccessException will be thrown by SQLServerAgent if it can't create a job directory;
		- "the process could not connect to distributor <>" --> http://msdn.microsoft.com/en-us/library/ms151868.aspx
		- Enable auditing and see if you are getting a failed login. Right click on your publisher in Management studio, go to properites, security and ensure the audit both successful and failed logins only check box is checked. Then have your subscriber try to connect, if it fails look in the SQL Server Error log for a message. If it successes you will need to enable the error collection in profiler to investigate further. If it fails you have an account issue somehow.

		- Dojo {
			- Create the simplest possible T-Rep between 2 servers;
			- Create T-Rep initialization with snapshot (use agent profiles and copy the non-clustered indexes);
			- Create T-Rep initialization with starting from a backup (use agent profiles and copy the non-clustered indexes);
			- Eplain the difference between T-Rep, Merge-Rep and Snapshot-Rep;
			- Explain what log shipping is;
			- Set up Oracle publishing replication;
			- Set up p-2-p replication;
			- Create a pull subscribtion based replication;
			- Prove T-Rep consistency (because it iguarantees it);
		}
	}

	SQL server {

		- Dojo {
			- DONE: Add default values constraint - test that is works;
			- DONE: Add a check constraint for your table - test that it works;
			- Done: Add unique constraint on multiple columns - test that it works;
			- Done: What are some examples of candidate keys - create a table illustrating this;
			- prove that the clustered index rearanges the values when inserting values (populating the table with scripted inserts);
			- create a clustered index for a table - test that it works;
			- create a non-clustered index for the table - test that it works;
			- create a view;
			- create both types of indexes on a view;
			- prove the performance incdrease when indexes are used (involves proving that they are used);
			- what is the significance of the autogrowth parameter? What will happen if you insert more data into DB in one transaction than the autogrowth size? - test it;
			- DONE: Create a database with tables that deal with M:M relationship;
			- DONE: create a relationship with foreign keys;
			- DONE: referential integrity for delete operations - test that it works;
			- referential integrity for delete operations : cascading deletes - test that it works;
			- create a transactional replication framework - test it;
			- create a partitioning framework that uses sliding window - test it;
			- Test : Is it true that performance difference between char and varchar field containing tables is different?
			- Create a computed column in SQL server;
			- Find some tables that are not normalized and normalize them;
			- Import data and export data in SQL server (advanced: change mappings when inporting data from excell);
			- Create an SSIS package;
			- Import 2 CSV files (you will have to choose flat data file) with different delimiters (i) and have the imports fail initially because of data truncation (ii);
			- Access database file (do a pull to and push from access database) and explain why the push approach is better than the pull;
			- Change the default database and test that it works;
			- Prove the difference between BETWEEN and > & < by exmple. Explain what the difference is;
			- Prove the difference between an underscore and a percent sign when processing textual information;
			- Prove that T-SQL is case insensitive;
			- Answer the question how will the result set be ordered if you have ORDER BY <column1>, <column2> DESC condition?
			- Use the TOP X PERCENT statement and proove it's correctness;
			- How will COUNT(column_with_NULLs) work? Prove it;
			- Show how would you use DISTINCT with two different columns;
			- Prove the difference between INNER AND LEFT/RIGHT OUTER JOIN;
			- Prove that sometimes a subquery is the only way to get the results back;
			- Some columns will be automatically generated - you don't need to insert those - how can you verify? (funtion based columns - computed columns & the identity columns on't need to be inserted);
			- Use OUTPUT statement with update, insert and delete;
			- Use soundex() meaningfully;
			- Create a UDF;
			- Update your UDF by enhanceing it's functionally;
			- Create a stored procedure;
			- Update your UP_ by enhanceing it's functionally;
			- Create a UP with transaction and try catch (user error_message() function to print what happened in the catch block);
			- Execute the same SQL statement on two different servers using local server groups;
			- Run a DBCC checkDB on your database for allocation and consistency error checking (how ofter do you need to run this command on a database? (your maintenance plan should include this step));
			- backup and restore the database from multiple files (a split backup);
			- Set up database mirroring;
			- choose a backup compression option for your database;
			- Create a simple SSRS report with the report builder and view it;
			- Create an indicator in the SSRS report;
			- Set up some security permissions for your report in the report webpage;
		}

		- Questions {
			- Create a simple data flow SSIS package;
			- What can you do with SSIS? --> import data from other sources, perform calculations on them, even mergethat data an import to your SQL server and store the whole logic for later reuse;
			- What is BIDS? --> bussiness intelligence development studio (which is just a cut down of visual studio);
			- What are inbuilt sql server roles usefull for? --> they create mappings for particular actions on particular objects for you as templates so you do not have to asign a login to a permission by yourself.
			- what is the sysadmin role? --> instance specific role, instance administrator, it also is the db_owner for all databases hosted on the instance;
			- what is the db_owner role? --> databases specific role that can do any action on the database on any object; 
			- What is data retention? -->
			- What is a media set in the context of SQL server backups? -->
			- When you backup your database in SQL server you have an option to split the backup in multiple locations - what does that gie you? --> Speed, not redundancy. This is primarilly a speed and not a redundancy option, so do not get confused by it;
			- What is the difference between full and differential backup and why the first time you create a backup only the full options is available?
			- On what operations is the index touched? --> UPDATE, DELETE, INSERT (so all operations that change data);
			- Explain the difference between reorganizing an index and recreating it --> int the first instance the index pages are just reorganized in memory and 100 defragmentation might not be achieved, in the other case the index is completelly droped and recreated from scratch
			- SQL server page size 						---> 8k
			- Describe the sctructure of the page? 		--->
			- Why is it that when you add a unique key constraing in SQL server it also adds a non-clustered index on it? -->
			- Can you use a question mark in a table name? --> YES
			- Is 0 and 1 bits valid booleans in T-SQL? --> YES, You could use the BIT datatype to represent boolean data (a BIT field's value is either 1 or 0);
			- why does SQL server autoincrement by 2 if you delete 1 row?
			- How much space can a clusterd server take?
			- What is a heap? --> A heap is a table without a clustered index. One or more nonclustered indexes can be created on tables stored as a heap. Data is stored in the heap without specifying an order. Usually data is initially stored in the order in which is the rows are inserted into the table, but the Database Engine can move data around in the heap to store the rows efficiently (Heap storage has nothing to do with head datastructure which is a specialized tree-based data structure that satisfies the heap property);
			- What is a transaction and why it is closelly linked to the ACID principle;
			- Explain ACID: what A, C, I, D stand for and what do they mean?
			- What is a linked server? --> Configure a linked server to enable the SQL Server Database Engine to execute commands against OLE DB data sources outside of the instance of SQL Server. Typically linked servers are configured to enable the Database Engine to execute a Transact-SQL statement that includes tables in another instance of SQL Server, or another database product such as Oracle. Many types OLE DB data sources can be configured as linked servers, including Microsoft Access and Excel.
		}

		- Random {
			- SQL server is not a database - it is an RDBMS;
			- Why database? It stops simultaneous writes, and manages access, disallows inserting invalid data types;
			- SQL server compact edition for mobile devices - surprise mf!
			- Reports on every database - user statistics, table space usage, index usage!
			- The 4 initial databases: master, model, msdb and tempdb are important. Master can not be deleted, because it tells what exists in the instance of the SQL server, model - describe how a new db will look like (can be cusomized so that every new database you will want to create would be of some structure that you want), msdb - used internaly for queuing and jobs, like database mail, tempdb - scratchpad for sql server - deleted and recreated on restart;
			- dbo.sales - dbo is a SCHEMA!
			- compound keys;
			- do not forget you can add default values when creating columns - and you should want to add as many constraints in your db design;
			- also you can add a check constraint for a database -The CHECK constraint is used to limit the value range that can be placed in a column {
				CREATE TABLE Persons
				(
				P_Id int NOT NULL CHECK (P_Id>0 AND P_Id<10),
				LastName varchar(255) NOT NULL,
				FirstName varchar(255),
				Address varchar(255),
				City varchar(255)
				)
			}
			- you can add a UNIQUE KEY constraint not only for primary keys but on multiple values in one row e.g.: name and last name can not be dublicated;
			- candidate key - http://www.c-sharpcorner.com/forums/thread/164434/candidate-key-and-alternate-key-in-sql.aspx
			- PLLCIGWTF001\CCI and PLLCIGWTF001\CCI2 - are different instances of SQL server installed on the same server VM (or physical) - PLLCIGWTF001. You can have a developers edition SQL server and express edition as well on the same machine. You can add as many instances as your machines resources allow by installing a new one with the installation wizard.
			- when creating a user account for SQL server always check that SQL server is in a mixed authentification mode. This gives the possibility for users who do not have windows authentication posibilities - like PHP code and SOAP UI tests.
			- had a KATA: "Prove that 1 and 0 are valid boolean values in T-SQL". But this is BS, beause TSQL does not have a boolean data type. And the bit used for that is only an approximation, because it does not support 3 - valued logic. Some interesting thoughts about TSQL and 3-values logic {
				- SQL Server doesn't have a boolean data type. As @Mikael has indicated, the closest approximation is the bit. But that is a numeric type, not a boolean type. In addition, it only supports 2 values - 0 or 1 (and one non-value, NULL). SQL (standard SQL, as well as T-SQL dialect) describes a Three valued logic. The boolean type for SQL should support 3 values - TRUE, FALSE and UNKNOWN (and also, the non-value NULL). So bit isn't actually a good match here. Given that SQL Server has no support for the data type, we should not expect to be able to write literals of that "type".
		}

		- Building a database in general {
			- You will probably never build a database incrementally by design, only by accident. Be incremental / experemental an creative in your user interface, or application features, but with databases you want to be as methodical as possible. And you really can since RD's where around for 40 years and the desing patterns for databases are pretty well known - so you have to learn them and apply them;
			- Your planing will be incremental, your development - not so much.
			- 1st: What is it for: desktop / mobile. Express the answer in the form: I need a database to store user, order and supplier infomation. Also comments so that users would be able to read them. Also the behaviour of customers so we will need time information recorded.
			- 2nd: What is wrong with the current DB? Can I fix old problems in my new DB with some design tweeks?
			- 3rd: What tables do I need? - Customer? Comment? Event? Label?
			- 4th: What data will be stored for each entity - columns. Be as specfic on column information as possible because that way RDBMS will enforce rules on the columns.
			- 5th: keys - which column it is that uniquelly identifies a row;
			- 6th: relationships - foreign keys and normalization, how your entities will relate one to each other - (1:1 ; M:1 ; 1:M (most common relationship) ; M:M (second most common, sometimes disguised as 1:M like one author - many books, but one book can have many authors); none)
			- 7th: indexes;
			- how do you deal with M:M relationship - a junction or linking table. There are by convention named authorTitle or titleAuthor. A table which will contain dublicate author values 77,77,77,78 and dublicate title values like 1,1,5,1. You can recognize junction tables by their names an by checking the relationships in a database diagram;
			- to prove that a table is a junction table you can check it's columns or check it's relationships in the database diagram;
			- foreign keys are constraints as well - it imposses some structure for your tables. You will not be able to delete the values from the primary table without deleting them from junction table (no orphans) - this is handled by cascading deletes or the order of priority the deletes take place (first delete the records in the foreign table, then you will be able to delete them in the primary table). Inserting something in the junction table that does not exist in primary table is also not permited;
		}

		- Building a database with SSMS {
			- When you create a database it is stored in files on the disk drive. A transactional log file - the database log an a data file;
			- You should pay attention to the initial size and autogrowth parameters in SQL server >> so if you had expectations that the size of data written into the DB in one transaction is large you should increase the autogrowth parameter appropriatelly;
			- Collation is the idea of case and accent sensitivity that the DBMS will take into account when grouping, ordering, sorting stuff;
			- Filegroups are ways of abstracting multiple files into one logical unit - filegroup so that it would be dealt with automatically;
		}

		- Some interesting notes on MSSQL datatypes {
			- nchar and nvarchar are 2byte chars that support unicode character set;
			- char and varchar are 1byte chars;
			- if you enter "a" in a varchar(5) field it will be stored as "a", the same will be stored as "a    " in char(5) field - spaces are prepended. A performance tradeoff can be postulated - varchar storing database should be a bit slower in searching data because its not a simple pointer increase by a constant amount anymore - but this would have to be verified... and it should be done on a very simple computer that is sufficiently primitive not to do any optimizations, cacheing and all that stuff;
			- nchar(10) == 20 bytes // char(10) == 10 bytes;
			- nvarchar(4000) && varchar(8000) - maximum lenght that can be specified, if you want more use nvarchar(MAX) - up to 2GB;
			- money and smallmoney - store 4 decimal diggits;
			- decimal and numeric are the same so decimal(3,2), numeric(3,2) are the same and the max value is 9.99;
			- datetime2 is smaller size than datetime and also guarantees more precise time - 100ns;
			- bit - 1 bit, 1/0 - Y/N;
		}

		- Foreign keys {
			- a couple of ways to create them: with diagrams (i) and in the design view (ii) - can you create them with SQL?
			- referential integrity - you will not be able to insert some arbitrary productid in orders table when orders table productid and products table productid are bound with foreign keys. That also means that applications that insert data into the tables have to do it in some order - you can not insert productid into order table if it does not exist in products table;
			- the referential integrity will also be imposed on deletes as well as inserts. If you want to delete productid in the products table you will have to have a cascading delete to delete every productid in the orders table.
		}

		- Indexing: "(index based addressing)" {

			- Kudvenkat :: Indexes in sql server Part 35 {
				- indexes have a lot to do with where clause;
				- index analogy with book index (for nonclustered index - index that is stored outside the table) and telephone book (a clustered index - a part of the table, like ordering phone numbers by last names which are in alphabetical order) and full table scan;
				- compare (where salary > 500 AND salary < 5500) clause - when index is added an not --> query optimizer does not use the index;
				- indexes are ordered and they contain values in the table and address for the row that contains that value as one of its columns
                 ___________________________ 
				|____salary___|_row address_|
				|_____500_____|_x0855616666_|
				|_____600_____|_0x55994545__|
				|_____________|_____________|

				- non unique index -
				- non clustered index - you can have only one of them, because it physically reorders data and the key of this index is one of the columns in the table. It is unique and is ussually used to enforce uniqueness and ordering of the primary key;
				- composite clustered index - an index that is clustered and is composed of more than 1 column;
				- for some reason you can not delete a clustered index that is used to enforce the PRIMARY KEY constraint with a DROP statement, but you can do it with from object explorer;
				- sp_Helpindex <table_name> -> system stored procedure that returns the index information;
				- differences between clustered and non-clustered indexes {
					- only one clustered - many non-clustered;
					- clustered ones are faster, take less space;
					- clustered ones impose order on data, non-clustered ones keep the data in tact;
				}
			}

			- Jens Dittrich playlist on indexes: https://www.youtube.com/playlist?list=PLC4UZxBVGKtdKBV0C9oD9UEDUeRoX-IfK and have
			- David Taylor playlist on B-Trees: https://www.youtube.com/playlist?list=PLA5Lqm4uh9Bbq-E0ZnqTIa8LRaL77ica6 and have
			- Saurabh B-tree video : https://www.youtube.com/watch?v=k5J9M5_IMzg and have
		}

		- Normalization {
			- It gives the advantage of not having redundant data - no garbage, no data invalidation;
			- A set of rules invented 40 years ago
			- (i) have unique key; each field can contain one value; no repeating groups (a classic sign of repeating groups is same column names with numbers added to them);
			- (ii) Any non-key field should be dependent on the entire prime key (only a concern if you are using a compound key, if not - then it is no issue). Rephrase: you should not be able to identify any non key column from any of the key subcolumns;
			- (iii) No non-key fields are dependent on another non-key field; So if I have a table with Room and Capacity columns then I can easilly see that I know the capacity just by knowing the Room - therefore I have to split this table and have capacity in the separate one; Another example unitPrice -> (Quantity -> Total) - the total can be easilly computed and found from non-key fields; If we can figure out one non key column from another we need to store it separatelly;
			- many tables are not in 3rd normal form for a reason - they are called "denormalized". One example (postal code -> state and city) they are often store in the same table.
			- mnemonic: you data should be based on the key, only the key, and nothing but the key;
		}

		Inporting / Exporting Data {
			- SQL server import export wizard is part of SQL server integration services. Integration services can be much more involved than exporting/importing data. You can have multiple periodic exports if you want.
			- There is a 64 and 32 bit versions for exporting data to be imported to a 32 or 64 bit machine.
			- you cna create an SSIS package, but remember this - even a simple import that you are doing is using a SSIS package;
		}

		- SQL {
			- SQL is time tested - it has been around for 40 years and seems that it is here to stay;
			- its a declarative, set oriented language, not a procedural ir imperative language. You describe what you want.
			- how to get negative sets, negative results e.g. customers that did not place any orders you can do a simple trick - get the possitive results and then do an inversion in your query;
			- there are estimated and actual execution plans. When those do not match - then what?
		}
	}
}

DATABASESES {
	- SELECT PERFORAMANCE {
		- Make sure that you have indexes on the fields that are in your WHERE statements and ON conditions, primary keys are indexed by default but you can also create indexes manually if you have to.
		- Check if you really have to select every column in all of the tables? If not, make sure that you only select the columns that you need, avoid using select *;
		- Double check if you really need LEFT JOINS, if no, use INNER JOINs;
		- If performance is still an issue after you're done tweaking your query, consider denormalizing your schema to eliminate joins;
		- You may also want to consider reducing the load on the database by using caching applications like sphinxsearch and memcached;
		- Check none of your joins are to views rather than actual tables;
		- Make sure that the WHERE clause utilizes indexes as much as possible - add aditional indexes if needed;
		- When adding an multicolumn index columns should be in order of highest cardinality to least (the column with the most unique values should come first);
		- Each JOINed table causes an additional lookup per row of the result set. So, if the WHERE clause selects 5,000 rows from vehicles, since you have 8 joins to vehicles, you will have 5,000 * 8 = 40,000 lookups. That's a lot to ask from your database server.
	}
}

TCP/IP networking for developers {

	Q {
		- How will requests travel to a node that is not part of the local subnet? 				===> it will have to do through the default gateway
		- What does a packet pass through and in waht order inside a network connected node? 	===> node networking stack -> firewall -> webserver -> OS (if needed);
		- What will happen if a windows machine is not able to connect to DHCP server 			===> http://superuser.com/questions/238625/why-is-windows-default-ip-address-169-xx-xx-xx
		- What will happen to Linux machine? 													===> ???
		- Can firewalls be inside the operating system and outside? A dedicated firewall server? If the firewall is inside - is it still the one to first examine the network data comming in?
		- why does nslookup operation give different results for "microsof.com" and for "www.microsoft.com" ?
		- How DO YOU EXPECT (would assert) that a tracerout request would differ when tracerouting to a server directly and with a domain that the server hosts?
		- What does a "record type" and the last line of DNS resolver cache records describe?
		- if you flush your DNS and there are still records appearing in your local DNS resolver cache - what are the possible explanations? 
																								===> (i) hosts file is not empty; (ii) background network activity (automatic software update checker) populated the cache;
 		- What is an "A" record in DNS? How does it dffer from NS record? 						===>
 		- What is an "MX" record in DNS?														===>
 		- What is the "CNAME" record?															===>
 		- What is the "AAAA" record (quad-A)? 													===> IPv6 version of the A record;
 		- What is the wildcard record type and how is it used by ISPs?							===> 
 		- What is a subnet? 																	===> A simple answer would be: a collection of computâˆ‚ers that can talk to each other without having to pass their communications through a router;
	}

	Dojo {
		- Draw a diagram illustrating how the DNS resolution works in case when a DNS request has to pass to the ROOT NS servers.
		- perform a nslookup from a different DNS server (like 129.65.16.254) see how your queries for the same domains will differ (for example you will see that microsoft.com is resolved differently);
		- show that DNS resolver chache is cleared on your local machine when you save hosts file;
		- proove that you can have multiline or single line records in your hosts file (you can do it using ping);
		- perform a DNS look up for different types of NS records (use 'set type=MX' command). Then perform the same while tracking your network activity with wireshark;
		- prove that no network activity happens if you do a DNS lookup for a result cached on your machine;
		- prove that your local IPS DNS servers cache DNS queries;
		- compare traceroute and tcptraceroute output and explain the differences (why does one need tcptraceroute if traceroute -T does tcp SYN over 80 itself?):
			- tcptraceroute :: http://p.defau.lt/?WBb8HPEUPfPObiqHQZu4pg
			- traceroute http://p.defau.lt/?5pxA4irmlmZJnpWTelSdmA
	}

	CMD {
		- ipconfig /displaydns
		- ipconfig
		- nslookup set type=MX google.com
		- nslookup -type=PTR 209.85.102.36
	}
}

DNS {
	DNS testing in zulu {
		1. Create a domain @ my.freenom.com;
		2. Create a new DNS zone in nsone for that domain - an "A" record to the origin server, "NS" record will be created automatically;
		3. Create a cname for that A record in ns1 e.g.: cname.mindaugas.ml;
		4. Let that cname point to an "A" record;
		5. In dojo database create a template that will be used when creating cnames for a company{

			SELECT id, name, zone, template FROM cname_templates;		  
			SELECT * FROM partners WHERE cname_template_id <> 1;

			UPDATE partners SET cname_template_id = 1 WHERE cname_template_id <> 1;

			INSERT into cname_templates (name, zone, template) 
				values ('cname.mindaugas.ml', 'mindaugas.ml', 'cname.mindaugas.ml');
		}
		6. Specify that template to be used by a company;
		7. Create a subdomain for the domain - www.mindaugas.ml for the domain mindaugas.ml. Since you can't really create a domain for ;
		8. 
	}

	USEFULL TOOLS {
		- nm-tool | grep DNS 		===> what is the DNS server used by your machine (mine is 192.168.1.1);
		- cat /etc/resolv.conf 		===> resolver configuration file;
		- search wimax 				===> a prefix prepended by the NS system when resolving a name. Example, you would type: http://somesite/path it would prepend http://somesite.wimax/path, which it BS because HTTP 1.1 with it's virtual hosting will not work for http://somesite (DNS answer does not rewrite the URL, it just brings back the IP);
		- dig @8.8.8.8 whypeopledance.com -t NS +short 	===> dig adress for whypeopledance domain specifying the type (-t) of the query (NS) and a short answer. @global server "global d-opts and servers (before host name) affect all queries." If it were dig whypeopledance.com -t NS +short @8.8.8.8 - it would affect only current query;
	}
}

PHP {
	- PHP stands for "PHP Hypertext Preprocessor" (which is a recursive acronym);
	- PHP interpreter is written in C;
	- single quotation marks are faster than double - because when double quotes are used PHP is looking for variables inside it;
	- you can turn on error reporting in php.ini file by finding the error_reporting marker and setting it to error_reporting=E_ALL -- do not use this in production; The line "E_ALL & ~E_NOTICE | E_STRICT";
	- you can change or get the error reporting parameter set in your code using the functions: 
		- ini_get('log_errors') and 
		- ini_get('error_reporting')
	- $myText = (string)$myVar; -- toString() equivalent in PHP;
	- foreach($_SERVER as $key_name => $key_value) {
    	print $key_name . " = " . $key_value . "<br>";
    };
    - Uploading images functionality {
    	- http://stackoverflow.com/questions/3748/storing-images-in-db-yea-or-nay 	<--- against RDB
    	- http://www.phpro.org/tutorials/Storing-Images-in-MySQL-with-PHP.html 		<--- pro RDB && another good explanation. After reading this it seams that many file systems are like databases themselves.
    	- There are no clear answers whether you should store images in RDB or FS. In general it is advisable to not use relational database to store images. They are unstructured data - have no relationships - BLOB's. So a file system would be much better in storing and retrieving them.
    	PROS for RDB {
    		- automatic sync which would be a problem if you would run multiple app servers and store images in /content/users/images/ directory (could be solved by an image server solution);
    		- all data in one place - easier to backup and maintain;
    	}
    	CONS for RDB {
    		- file system caching;
    		- performance of retrieval is better in FS;
    		- maintained referential integrity (no orphants);
    	}
    	- What is the best way to store images in the web application. Maybe NoSQL solution? {
    		- 
    	}
    	- Which file system is the best?
    	- How to optimize image storage for performance and security {
    		- 
    	}
    	- Path example: /content/users/{user_id}.jpg
    }
}

PHP & MySQL essential training {

	Dojo {
		- DONE: Configure Apache to run on a different port;
		- Change the web directory from the default and prove that it works;
		- Change the error logging in PHP and prove that it works;
		- Change MySQL root users password and prove that FLUSH PRIVILAGES command works;
		- //
	}

	Q {
		- What is the difference between scripting language and a programming language? --> A scripting language can do things only in response to events.
		- What is the similarity between ASP and PHP --> ASP is basically microsofts version of PHP;
		- What did PHP first stood for? --> Personal Home Page Tools
		- Is PHP open source? --> YES
		- Is PHP cross platform (Mac, Wind, Linux) --> YES
		- //
	}

	Setup {
		- download LAMP-like install (like WAMP for windows);
		- configure services to not port-clash (apache for example listens to port 80);
		- change mysql root password {
			- mysql.exe -u root;
			- use mysql (change the database);
			- mysql> update user
    			-> set Password=PASSWORD('xxx')
    			-> where user='root';
			- flush privileges;
			- <ctrl+c>;
			- mysql.exe -u root -p
		}
		- //

	MySQL {
		- show databases; 						===> shows all DB's
		- show status like 'Conn%'; 			===> shows connections;
		- SHOW PROCESSLIST; 					===> shows threads that are running;
		- mysqladmin -u root processlist 		===> shows processlist;
		- mysqladmin -i 1 processlist 			===> refreshes the output every second;
		- sudo rm /var/lib/mysql/ib_log* 		===> delete these logs when mysql does not want to start
		- $(which mysql) --verbose --help | grep -A 1 "Default options" ===> find the my.cnf files that mysql is using;
		- strace /usr/bin/mysql  				===> has lines indicating which config file was read (applicable to many other applications)
	}

	Symfony {

		Install on linux {
			curl -sS https://getcomposer.org/installer | php
			sudo mv composer.phar /usr/local/bin/composer
			sudo curl -LsS http://symfony.com/installer -o /usr/local/bin/symfony
			sudo chmod a+x /usr/local/bin/symfony
			.../web/app_dev.php 								===> comment the lines that prevent access to the test app (default symfony app);
		}

		Symfony project structure {

			- When developing a Symfony application, your responsibility as a developer is to write the code that maps the user's request 
			(e.g. http://localhost:8000/) to the resource associated with it (the Welcome to Symfony! HTML page).
			The code to execute is defined in actions and controllers. 

			- The mapping between user's requests and that code is defined via the routing configuration. 
			And the contents displayed in the browser are usually rendered using templates.

			- When you browsed http://localhost:8000/ earlier, Symfony executed the controller defined in the 
			src/AppBundle/Controller/DefaultController.php file and rendered the 
			app/Resources/views/default/index.html.twig template. 
			In the following sections you'll learn in detail the inner workings of Symfony controllers, routes and templates.

			- src/{bundle_name}/Controller/{controller_name} 									===> where controlers reside
			- app/Resources/views/{name_of_view_group}/{name_of_view}.html.twig 				===> where a view resides

			- /home/ubuntu/workspace/test_proj/src/AppBundle/Controller/DefaultController.php 	===> entry point for the default application

			- actions reside in controlers and are short because they use other parts of the application
			- blocks start with /**, whereas regular PHP comments start with /*. like: 
									/**
								     * @Route("/", name="homepage")
								     */
								    public function indexAction(){...}
								    
	    	- // these import the "@Route" and "@Template" annotations
						use Sensio\Bundle\FrameworkExtraBundle\Configuration\Route;
						use Sensio\Bundle\FrameworkExtraBundle\Configuration\Template;
		}

		Routing {
			- A route is a map from a URL path to a controller. It should be nice to look at and easy to change (there should exist one place from where a change can be made);
			- @Route("/blog/{slug}", name="blog_show") ....  public function showAction($slug) ===> $slug acts like a wildcard in /blog/*
			- Routing flow {
				- The request is handled by the Symfony front controller (e.g. app.php);
				- The Symfony core (i.e. Kernel) asks the router to inspect the request;
				- The router matches the incoming URL to a specific route and returns information about the route, including the controller that should be executed;
				- The Symfony Kernel executes the controller, which ultimately returns a Response object.
			}
			- config.yml :: router: resource: "%kernel.root_dir%/config/routing.yml" 
			- you can include external routing references inside the routing.yml where you can point to a directory or to a file <resource: "@AppBundle/Controller/{or_file.php}">. When pointing to a directory, all files in that directory are parsed and put into the routing.
			- This way you can include routes to 3rd party modules;
			- Example {
				app:
				    resource: "@AppBundle/Controller/DefaultController.php"
				    type:     annotation

				app2: 
				    resource: "@AppBundle/Controller/TestControler.php"
				    type:     annotation
			}
		}

		Commands {
			- php app/console server:run $IP:$PORT  				===> run on custom port and ip
			- php app/console server:status $IP:$PORT
			- php app/console server:stop $IP:$PORT
			- php app/console doctrine:database:create 				===> create db
			- php app/console doctrine:database:drop --force 		===> drop database
			- php app/console doctrine:schema:update --force 		===> schema from entities
			- php app/console doctrine:fixtures:load 				===> load a fixture
			- php app/console 										===> displays the usage of the console
			- php app/console debug:router 							===> check all current routes
			- php app/console doctrine:generate:entity 				===> create an entity interactivelly in command line
			- php app/console doctrine:generate:entities Acme 		===> generates all entities of bundles in the Acme namespace
			- php app/console generate:bundle 					
			- php app/console generate:bundle --dir=./src --namespace=BlogBundle --no-interaction
			- php app/console cache:clear 							===> clear the cache (after deleting some stuf it is necessary to do)
			- php app/console command_name --env=prod
			- php app/console cache:clear // rm -rf app/cache/* 	===> clear cache after git pull 
			- php app/console assets:install
			- php app/console assetic:dump
			- php app/console doctrine:schema:update --dump-sql 	===> shows changes
			- php app/console doctrine:database:drop --force --env=prod
			- php app/console doctrine:database:create --env=prod
		}

		HTTP {
			use Symfony\Component\HttpFoundation\Request;

			$request = Request::createFromGlobals();

			$request->getPathInfo(); // the URI being requested (e.g. /about) minus any query parameters

			$request->query->get('foo'); // retrieve GET and POST variables respectively
			$request->request->get('bar', 'default value if bar does not exist');

			$request->server->get('HTTP_HOST'); // retrieve SERVER variables

			$request->files->get('foo'); // retrieves an instance of UploadedFile identified by foo

			$request->cookies->get('PHPSESSID'); // retrieve a COOKIE value
			
			$request->headers->get('host'); // retrieve an HTTP request header, with normalized, lowercase keys
			$request->headers->get('content_type');

			$request->getMethod();    // GET, POST, PUT, DELETE, HEAD
			$request->getLanguages(); // an array of languages the client accepts
		}

		Twig {
			- {{ ... }} 			===> prints a variable or the result of an expression to the template.
			- {% ... %} 			===> a tag that controls the logic of the template; it is used to execute statements such as for-loops for example.
			- {# ... #} 			===> used to add single or multi-line comments. The content of the comments isn't included in the rendered pages.
			- {{ title|upper }} 	===> FILTER. Makes the title variable all uppercase before rendering it.
			- cycle([array], index) ===> {% set fruits = ['apple', 'orange', 'citrus'] %}
											{% for i in 0..10 %}
											    {{ cycle(fruits, i) }}
											{% endfor %}
			- vendor/symfony/symfony/src/Symfony/Bundle/TwigBundle/Resources/views/Exception/  ===> location for the error pages;
			- <>
		}

		Doctrine {
			- configure the app\config\parameters.yml file (which is just a decouplement of the database access config the real version of which resides in the config.yml)
			- Independent from symfony but is generaly used with it
			- setting up the default charset and the collation correctly in the "my.cnf" file {
				[mysqld]
				collation-server = utf8mb4_lithuanian_ci
				character-set-server = utf8mb4
			}
			- create the database : php app/console doctrine:database:creates
			- create the entity - an class the object of which will hold data ... with all sorts of different anotations;
			- provide a mapping between DB and the entity class inside :: src/AppBundle/Entity/Product.php;
			- generate getters and setters: php app/console doctrine:generate:entities AppBundle/Entity/Comment
			- write the code to get or place data inside the database
			- anotation for an entity to specify collation and default charset {
				/**
				* @ORM\Table(name="Comment", options={"collate"="utf8mb4_lithuanian_ci", "charset"="utf8mb4", "engine"="MyISAM"})  
				* @ORM\Entity
				*/
			}
		}

		Delete a bundle {
			- delete /src/Test/BlogBundle directory
			- change /app/config/routing.yml file to remove the bundle routes
			- remove your new bundle from /app/AppKernel.php
			- clear cache (either by deleting cache/{$env} or console cache:clear)
		}

		Projects {
			- Creating a comment system {

			}
		}
	}

	PHP unit {

		<?php
			/**
			 * Created by PhpStorm.
			 * User: Mindaugas
			 * Date: 4/23/15
			 * Time: 5:37 PM
			 */

			namespace algorithms;

			class Example {

			    public function run(){
			        return 1;
			    }

			    public function countSum(){
			        return 1;
			    }

			    public function frogJump(){
			        return 1;
			    }
			}


			<?php

			use algorithms\Example;

			/**
			 * Created by PhpStorm.
			 * User: Mindaugas
			 * Date: 4/23/15
			 * Time: 5:38 PM
			 */

			class ExampleTest extends PHPUnit_Framework_TestCase
			{

			    private $example;

			    // function is executed before each testcase
			    public function setUp()
			    {
			        $this->example = new Example();
			    }

			    public function testReturnOne()
			    {
			        $result = $obj->run();

			        $this->assertEquals(1, $result);
			    }

			    public function sumDataProvider()
			    {
			        return [
			            [3,6],
			            [4,10]
			        ];
			    }

			    /**
			     * @dataProvider sumDataProvider()
			     */
			    public function testSum()
			    {
			        $this->assertEquals(6, $this->example->countSum(3));
			    }

			    public function frogJumpProvider()
			    {
			        return [
			            [2,8,3,2],
			            [1,10,1,10]
			        ];
			    }

			    /**
			     * @dataProvider frogJumpProvider()
			     */
			    public function testFrogJump($x, $y, $r, $expects)
			    {
			        $this->assertEquals($expects, $this->example->frogJump($x, $y, $r));
			    }

			}
			 
		# PSR-4 only works with namespaces. It removed the namespace prefix given in composer.json from the full class name, and the remainder is converted into a path, ".php" added at the end, and searched in the path given. A class myNamespace\myClass and "psr-4":{"myNamespace\\": "src"} will try to load src/myClass.php.

		# composer dumpautoload

			 {
			    "name": "alg/tasks",
			    "require": {
			        "phpunit/phpunit": "~4.6"
			    },
			    "authors": [
			        {
			            "name": "Mindaugas Bernatavicius",
			            "email": "a@b.com"
			        }
			    ],
			    "autoload":{
			        "psr-4": {"algorithms\\":"src/"}
			    }
			}

		# phpunit.xml.dist

			<?xml version="1.0" encoding="UTF-8"?>
			<phpunit
			        color="true"
			        bootstrap="vendor/autoload.php">
			    <testsuites>
			        <testsuite name="Unit">
			            <directory>./tests/</directory>
			        </testsuite>
			    </testsuites>
			</phpunit>

	}
}

Axure{
	- adaptive views
	- global / local guides + guide shemes
	- home, ctrl + home / space for hand
	- generating flow diagrams from your webpage nesting options
	- dynamic panel is used when you want a part of a page to change without needing the page to refresh
}

PMonitor {
	Tasks In Order{
		- Handle malformed URL{
			- 
			- 
		}
		- Handle newtork exception{
			- On mobile devices, data connectivity has always been an issue. While users are on the go, the data source will often switch towers or downgrade/upgrade between 2G and 3G or WiFi or app goes to background by screen lock or by pressing home button. This has an impact on applications/games that rely on persistent data connectivity.
			- The problem reduces to the internet exception;
		}
		- Handle Internet exception{
			- will check whether host (speuders or otomoto, etc) is reachable;
			- if I would check for internet connection with an established host I would still get NP's if any of the websites was down;
			- Do not implement the check on the main thread, because you'll get: android.os.NetworkOnMainThreadException

			- first implement the message "inernet is not reachable" as a toast
			- then as a dialog with retry and cancel buttons {
				- AlertDialog
				- Update UI thread Murach 328
				- What are the adapters? Murach 342
				- Working with system services 392 (there is how to check if internet connection is avaialble)
				- How to work with DialogBox Murach 518
			}
		}
		- Implement throber and cancelation of parsing;
		- 
	}


Jenkins {
	- The hudson / jenkins controversy when oracle bought sun;
	- We need continuous integration so that developers would integrate their changes as often as possible and cont develop in "their caves" for months at a time;
	- Continuous integration is painfull - and it shoiuldd be the least panefull it can be.
	- to start jenkins on windows go the the jenkins diretory and CMD there the command jenkins.exe start; also remember jenkins.exe restart and jenkins.exe stop;
}

Hot-Keys {
	CS: A good craftsman has to know his tools and how to use them. Here are computer hotkeys in key-value-meaning triplets:
	- WINDOWS: 		CTRL + ALT + BREAK - restore the remote connection screen;
	- WINDOWS: 		ALT + TAB - browse between active applications; ALT + TAB + SHIFT - change the direction of browsing
	- ECLIPSE: 		CTRL + D - delete the line on which the cursor is placed;
	- ECLIPSE: 		CTRL + ALT + DOWN - copy the line on which the cursor is placed;
	- EXCEL: 		ALT + ENTER - line break inside the cell;
	- EXCEL: 		F2 - write inside the cell highlihted (usefull when navigating only with the arrows and tab/tab+shift key);
	- EXCEL: 		Scroll Lock - if turned on (indicated by the status panel on excel and you PC's scroll lock light) it allows to scroll the scroll bar wiht the arrow keys on the keyboard
	- PHOTOSHOP: 	CapsLock when quick selction tools are selected - changes the tool targeting indicator;
	- WINDOWS: 		shitf + delete --> delete a whole word per backspace click;
}

RoR {

	RUBY {
		- Open classes :: In Ruby, classes are never closed: you can always add methods to an existing class. This applies to the classes you write as well as the standard, built-in classes. All you have to do is open up a class definition for an existing class, and the new contents you specify will be added to whatever's there.
		- global interpreter lock - only one thread of execution on the regular RMI interpreter;
		- semantic versioning system : MAJOR.MINOR.PATCH {
			- uses semantic versioning system;
			- MAJOR version when you make incompatible API changes;
			- MINOR version when you add functionality in a backwards-compatible manner;
			- PATCH version when you make backwards-compatible bug fixes;
		}
		- rvm list 													===> lists all the packages and ruby version on the server (the command "ruby -v" will not show the ruby version correctly when rvm is used);
		- bundle exec rails c 										===> turns on the console;
		- Node.all 													===> shows all nodes from the database (can be executed in the rails console);
		- "Mindaugas".reverse;
		- "Mindaugas".lenght;
		- "Mindaugas" * 5;
		- 123.to_s.reverse;
		- [1,2,3].max;
		- [1,2,3].sort;
		- to_a, to_s, to_i;
		- variable_name = Hash.new(0);
		- var_name.values.each {|var_name_2| var_name_3[var_name_2] += 1};
		- Dir["/*.txt"]; 											===> prints all the files ending in .txt in root dir;
		- FileUtils.cp('/comics.txt','/Home/comics.txt') 			===> copy file from one location to another;
		- [3,2,6].sort 												===> creates a copy of the array and then sorts it [2,3,6];
		- [3,2,6].reverse 											===> reverses the sorting to the original one;
		- [3,2,6].sort! 											===> in-place sort;
		- variable_name_2['string_to_search']='string_to_replace';
		- variable_name_2.lines.to_a.reverse;
		- variable_name_2.downcase.include? 'some_string;
		- variable_name_2['some_text']=:amazing 					===> the :amazing is a symbol,not a string;
		- hash_variable.keys // hash_variable.values;
		- ruby -e 'p ("a".."z").to_a.shuffle[0..7].join' 			===> one liner;
		- formatter = "%{first} %{second} %{third} %{fourth}"       ===> define a formater for a string and use it - when you want to apply the same format to multiple values. 
            puts formatter % {first: 1, second: 2, third: 3, fourth: 4}
        - first, second, third = ARGV                               ===> assigns 3 values passed to a script to 3 placeholders;
        - in_file = open(from_file); indata = in_file.read; puts #{indata.length} ===> print the size of the file in bytes;
        - File.exist?(to_file)
        - def print_two(*args)                                      ===> function taking many args;
        - ruby -e 'h = Hash[1 => "A", 2 => "B"]; puts h[1]'			===> get the hash value using the key;
        - ruby -e 'h = Hash[1 => "A", 2 => "B"]; puts h.key("B")' 	===> get the hash KEY using the VALUE;
        - ruby -e 'h = Hash[1 => "A", 2 => "B"]; puts h.keys[0]' 	===> get the hash values using indexes;
        - h.keys 													===> get all values;
        - [1,2,3] & [1,2,2,5,6] 									===> the bitwise and can be used as a set intersection operator, retrning common UNIQUE elements in the set;
        - "#{14.to_s(2)} & #{13.to_s(2)} = #{12.to_s(2)}" 			===> bitwise and in it's common usage;
		- f,s,t = "a  b b  c".chomp.split(" ") 						===> ["a", "b", "b", "c"];
		- f,s,t = "a  b b  c".chomp.split("  ") 					===> ["a", "b b", "c"];
		- f,s,t = "a  b b  c".chomp.split("\s")						===> ["a", "b", "b", "c"];
		- f,s,t = "a  b b  c".chomp.split("\s\s")					===> ["a", "b b", "c"];
		- f,s,t = "a  b b  c".chomp.split("\s{1,}") 				===> ["a  b b  c"];
	}
	
	Gemfile {
	 	- gem 'carrierwave', git: 'git@github.com:carrierwaveuploader/carrierwave.git' 	===> specify a gem by its source repository as long as it has a .gemspec file in the root directory
		- gem 'carrierwave', github: 'carrierwaveuploader/carrierwave' 					===> github is also possible
		- gem 'deep_merge', '1.0', git: 'git://github.com/peritor/deep_merge.git' 		===> If there is no .gemspec file at the root of a gemâ€™s git repository
		- git 'git://github.com/rails/rails.git 										===> specify which file to use in the gemfile
		- git 'git://github.com/rails.git', tag: 'v3.2.1' [branch: x] [ref: '4ad'] 		===> specify that git repository should use particular ref, branch, tag as options to git directive
		- gem 'nokogiri', path: '~/code/nokogiri'										===> load gems from a local file system

		- Typical gemfile entry {

			group :development, :test do
				gem 'decent_exposure', '~> 2.0.1'
			end

		}
	}

	RVM {
		PROBLEMS {
			- PATH is not properly set up is not at first place 	===> reinstall rvm, or remove all rvm related directives in the initialization files (/etc/profile && .bashrc, etc.);
			- GEM_PATH and/or GEM_HOME 								===> reinstall rvm, or remove all rvm related directives in the initialization files (/etc/profile && .bashrc, etc.);
		}
	}

	- gem -v 
	- rvm implode 									===> uninstall rvm itself (rvm is a script, not a gem!);
	- rvm gemset list 								===> RVM gives gemsets, sandboxed environments let you maintain separate sets of gems. ideal for multiple versions of Rails.
	- rvm install ruby --latest 					===> install lattest ruby version
	- rvm list known 								===> list all known versionf of rvm packages like jruby, ruby and so on
	- rvm install ruby 2.0.0-p247 					===> install a specific version of ruby
	- rvm gemset create rails42 					===> create a gemset
	- rvm gemset use rails42 						===> instruct usage of a custom gemset
	- gem install rails -v 4.2.0 					===> install a specific version of some gem when using a specific gemset that was custom defined
	- sudo rvm get head; rvm reload; rvm get stable ===> upgrade the RVM package manager (yes, the one that allows you to have multiple sets of gems)
	- gem install rails -v 4.2.0.beta4 				===> install rails, this command actually shows that rails is just another gem;
	- gem update --system 							===> update the RubyGems package manager for gems
	- gem update 									===> update the gems, not the RubyGems package manager
	- rails new sample_app --skip-test-unit 		===> tells Rails not to generate a test directory associated with the default Test::Unit framework, another framework can be used then;
	- rails _4.2.0.beta4_ new hello_app 			===> create a new aplication with the version of rails specified ; runs bundle install automatically
	- rails new first_app --database=postgresql 	===> create a new project with database specified;
	- rails server -b $IP -p $PORT 					===> (in cloud9)
	- > pg_ctl -D F:\Program_Files\PostgreSQL\9.3\data -l startup.log start 	===> start postgresql DB (-D data dir and -l for log file specification);
	- http://localhost:3000/some-non-existing-path 	===> enter to see all pages in your rails app (is it the same for when I deploy to heroku? That would be a security issue then)
	- bundle exec rake db:migrate 					===> use rake that is defined in the gem file;
	- bundle exec rake -T db 						===> a list of possible db operations;
	- bundle exec rspec <path_to_test_file> 		===>
	- bundle exec rake -T 							===> see all ruby make (=rake) tasks;
	- rake -T 										===> same as above
	- rake routes 									===> see all the routes
	- rails generate scaffold User name:string email:string 	===> generate scarfold with Users resource and appropriate properties for that resource;
	- bundle install --without production 			===> installs gems from the gem file excluding the ones that are defined in the production group;
	- bundle update 								===> update the gems to the version specified in the gemfile;
	- rails console 								===> opens interactive rails console where you can write ruby and see how it performs;
	- rails s 										===> same as "rails server";
	- rails generate rspec:install 					===> install and use rspec testing framework instead of Test::unit
	- rails generate controller StaticPages home help --no-test-framework ===> generates a controler called "StaticPages", also additional actions "home" and "help" adn tells rails not to generate the default rspec tests (if you want to use manual ones);
	- rails generate integration_test static_pages 	===> generates request spec (integration test) with RSpec;
	- DEPRECATED: rake gems:install RAILS_ENV=test 	===> install the gems that are specified in the config > environments > test.rb file;

	Common Rails :) - Rails workout{
		1. Create a test with Selenium WEBdriver and BEHAT that looks for non-existing page - see it failing{
			- Install PHP + XAMPP + Composer (remember to enable  openSSL extension in PHP.ini before installing Composer);
			- Add the directory where the behat.bat resides to your environments path;
			- Run "Behat --init" in your ruby projects root directory;
			- create ".feature" file;
			- define a feature;
			- define a(ll) scenarios;
			- create step definitions in FeatureContext.php file;
			- 
 		}
		2. Create a test that looks for a non-existing page with RSpec - see it failing{
			- note: you ahve to create an app before you generate the RSpec tests. An RSpec test is integrate wightly with project by default (for example uses "visit '/static_pages/home'" - function with relative paths);
			- 
		}
		3. Create a database-using app with SQLite DB and the page the tests are looking for - see the test passing;
		4. Commit everything (that's necessary - gitignore should be configured) to GIT;
		5. Deploy to Heroku;
		6. Populate apps DB with data;
		7. Create RSpec and Selenium WD tests that populate app with Data (i), check for the values in DB (ii), delete data as a teardown (iii);
		8. Create tests that are looking for data in DB - counts, specific records;
		9. Migrate app and data to PostgreSQL{
			-
			-
		}
		10. See if your tests that look for specific data (i) and test inputs (ii) pass;
		11. Migrate app back to SQLite DB;
		12. Check that tests pass;
		13. Create another app (steps 1 - 8 reusing most or of the tests and code, but not data);
		14. Run the two apps in parallel (mostly configuration) on my local machine;
		15. Deploy them to Heroku under different domains;
	}

	Dojo & Node Agent {
		- dojo/config/environments/shared.rb 									===> log level can be specified;
		- config.logger = ActiveSupport::BufferedLogger.new( 					===> defined a custom log file in dojo/config/environments/shared.rb
									File.join(ENV['SOME_ENVIRONMENT_VAR'], 
									"var/output/logs/rails.log"))
		- /home/zulu/nodeAgent/releases/<>/app/models/task.rb \
				  def perform
				    in_progress!
				    sleep(1000)
				    instant = false				
    																			===> getting tasks stuck in "in progress" state, adding sleep method in the appropriate place;
		- suspend sidekiq														===> getting tasks stuck in "waiting"
		- break the config templates in admin/templates							===> getting tasks in fail state
		- 																		===> getting task stuck in copied state
	}

	Heroku{
		- heroku login 															===> log in with your email and pass
		- heroku keys:add
		- heroku create 														===> creates heroku in the folder;
		- git push heroku master 												===> push the master branch to heroku (~ something like that);
		- rake assets:precompile 												===> precopile the static assets (some times necesassry when push to heroku does not work);
		- heroku run rake db:migrate 											===> migrate the rake on heroku to migrate the db;
		- heroku apps:destroy --app <app_name> 									===> delete app from heroku;
		- heroku rename rails-tutorial-hello 									===> rename an app on heroku;
	}
}

Git {
	Clone from another machine on the local network {
		git clone ssh://mindaugas@1.1.1.11/home/mindaugas/GoProjects 	===> Only need the folder name where the .git folder exists. In this case the .git folder is /home/mindaugas/GoProjects/.git 
	}
	Types of repositories{
		- Local repository 						===> no backuping to outside machines, no shared version control with a team;
		- Cetralized repo 						===> version history lost if machine is caught on fire;
		- Distributed repo 						===> all files stored in all nodes, alows team work;
	}

	Stages that files go through {
		- Modified
		- Staged 								===> marked "to be saved"
		- Commited								===> have been saved
		- You have 3 spaces corresponding to the file states: compressed database for the commited files, stage area for staged files, modified in the working directory.
	}

	SETUP{
		- sudo apt-get install git 					===> test ===> git -h
		- git config --global user.name "a a" 		===> test ===> git config --global user.name
		- git config --global user.email a@b.com 	===> test ===> git config --global user.email
		- git config --global core.editor "vim" 	===> test ===> git config --list
		- /usr/local/specific_directory$ git init 	===> initialize git in a specific_directory
		- git add *.java 							===> track changes only in files that end with .java
		- .gitignore 								===> specify which files to ignore {can be with patterns {can download a definitive one :: https://github.com/github/gitignore}}
		- git diff 									===> show the chnages that are not commited
	}

	- PROBLEM :: Permission denied (publickey) {
		- ssh -vt git@github.com 					===> see the verbose output for the ssh connection establishment;
		- The problem arises because there are two wys to authenticate to github from your local git installation - HTTPS and SSH. If you use HTTPS then you will be asked for password and username, if you use SSH you need KEYS.
		- Instructions: https://help.github.com/articles/generating-ssh-keys/#platform-linux
	}

	- PROBLEM :: git clone <> :: fatal: The remote end hung up unexpectedly {
		- change git config with : git config --global http.postBuffer 524288000
		- http://stackoverflow.com/questions/6842687/the-remote-end-hung-up-unexpectedly-while-git-cloning
	}

	- PROBLEM :: ssh connection to the github always asks for password {
		- ssh-add ~/.ssh/<key_file>
		- git config --global credential.helper cache 					===> cache the password for some time so you would not be asked for it for some time
		- git config --global credential.helper 'cache --timeout=3600'	===> configure the time you will not be asked to enter the password
	}
	- git clean -df 					===> removes all untracked files
	- git checkout <branch> .			===> clears all unstaged changes
	- git rm $(git ls-files --deleted)  ===> delete staged files if you deleted them not with git -rm but with rm
	- **/.sass-cache/** 				===> ignore .sass-cache dir in any directory and ignore all the files in all the dirs and subdirs of the sass-cache
	
	Git log{
		- git log --pretty=oneline			===> check the commit log in a more readable format;
		- git log --pretty=format:"%h : %an : %ar : %s" ===> show commit log <hash, authors name, time, commit string>;
		- git log -p -2 					===> see the last 2 commits;
		- git log -stats  					===> abreviated stats;
		- git log --since="2014-04-12" 		===> get changes since a specified date;
		- git log --before="2014-04-12"		===> get changes before a specified date;
		- git log --author="a a" 			===> check changes made by a scecific author; 
	}

	- git rm --cached some_file 		===> remove a staged file;
	- git rm [-f] some_file				===> remove the from the filesystem and git (has to be staged already);
	- git checkout -b modify-README 	===> create a branch "modify-README" and switch to it;
	- git init 							===> initializes a repository in the directory;
	- git add . 						===> adds all the files to the trackable file index in the repository (recursivelly);
	- git commit -m "Initial commit" 	===> commits changes to the reporsitory with a comment (-m flag);
	- git commit -a 					===> commit ALL changes;
	- git commit --amend 				===> edit commit message;
	- git remote -v 					===> list remotes including origin and others;
	- git fetch origin 					===> get data from the remote without merging with the local repo, creates a remote branch
	- git remote add origin https://github.com/<username>/<app_name>.git 	
										===> adding HTTPS remote origin
	- git remote add origin git@github.com:<username>/<app_name>.git 		
										===> adding SSH remote origin
	- git remote rm <some_remote_name>	===> revome some remote;
	- git push -u origin master 		===> pushing master branch to upstream called "origin"
	
	Checkout{
		- git checkout file/to/revert 		===> revert one file;
		- git checkout -- . 				===> revert all files;
		- git checkout master^^ 			===> second generation ancestor of the master (grandparent);
		- git checkout HEAD^ 				===> travel up the GIT tree one step at a time; 
		- git checkout master~<num> 		===> move a number of steps up the GIT tree;
	}

	Delete branches{
		- git push origin :branchName 		===> delete remote branch;
		- git branch -d your_branchname 	===> delete local branch;
	}

	Store git credentials{
		- git config --global credential.helper cache 					===> stores credentials in cache;
		- git config --global credential.helper "cache --timeout=3600"	===> set cache timeout;
		- git config credential.helper store 							===> stores credentials in plaintext;
	}

	- git branch -f master HEAD~3 		===> Moves (by force) the master branch to three parents behind HEAD;
	
	Reset{
		- git reset HEAD~1 					===> head will point to the one commit before last (as if the last commit had never happened);
		- git reset HEAD some_file 			===> reset the staged file (reverses the changes made by "git add some_file" command);
		- git reset current_branch_name~1 	===> same as above;
		- git reset --hard HEAD~1 			===> delete a 1 commit before head (basically deletes the last commit shown in git log);
	}

	- git revert HEAD 					===> In order to reverse changes and share those reversed changes with others, we need to use git revert;
	
	Cherry-pick{
		- git cherry-pick --abort 			===> abort in case one file has thiers and ours modifications (conflict in one file);
		- git cherry-pick --strategy=recursive -Xours {Imported_Commit}
		- git cherry-pick <Comm1> <Comm2> 	===> add commits to the WORKING branch - meaning you have to checkout the branch you want the commit to be added! Not the one that contains the changes already!
	}
	
	- git add <file> 					===> the file is not being tracked (meaning the changes are tracked) before you add it by using the add command. 
	- git add . 						===> adds all current directory;
	- git branch 						===> shows local branches;
	- git branch -a 					===> shows both local and remote branches (on the origin);
	- git push <remote> <branch> 		===> pushing the changes you have made to other repositories;
	- git rebase -i <base> 				===> launches rebase process in an interactive, non automatic mode;
	- cat .git/refs/heads/master 		===> check to which commint the HEAD is pointing;

	- is there a way to move up the GIt tree;
	- Detaching HEAD just means attaching it to a commit instead of a branch.

	- git show 36975c886ae4d54a1f1c33040552f22bf4947ffa 	===> check what was done in the commit (outputs a diff)
	- git log 												===> you won't have a nice commit tree visualization next to your terminal, so you'll have to use git log to see commit hashes;
	- git checkout <some_commit> 							===> detaching the HEAD (Detaching HEAD just means attaching it to a commit instead of a branch);
	- git branch <branch_name> <commit> 					===> creating a branch from some specific commit
	- git status 											===> shows us the repository status > It's healthy to run git status often. Sometimes things change and you don't notice it.
	- git branch <target_branch_name> 						===> create a branch;
	- git checkout <target_branch_name> 					===> switch to branch;
	- git merge <brach_you_have_not_currently_checkedout> 	===> creates a special commit that has two parents (together with all of their parents). Merging is one way of combining the work;
	- get rebase <brach_you_are_not_currently_checkedout> 	===> another way to merge changes. Rebasing essentially takes a set of commits, "copies" them, and plops them down somewhere else;
	- git --versions
	- git config --list :: verify GIT configuration
	- cat ~/.gitconfig :: verify GIT configuration
	- git clone http://git.cig.l/callvalidate.git <f_name>  ===> checkout ussing http (try when SSH does not work), you can find the link in git hub and git lab
	- git diff mybranch master 								===> compare two branches;
	- git diff mybranch master -- <file> 					===> compare two files from different branches;
	- git update-index --assume-unchanged <file> 			===> if you added a file to a repo, and only after that you added it to the .gitignore the file will be tracked. Update git index with --assume-unchanged flag

	- GIT workout{
		Add your changes{
			- create a file;
			- add >> git add . || git add <some_file>;
			- create a ticket for your commit, if there is none;
			- check the branch you are on >> git branch -a;
			- change the branch you want to target >> git checkout <branch_name>;
			- commit >> git commit  -m "#<ticket_number> comment" (the convention for comment);
			- push changes >> git push origin enhancedvelocity (you have to have permission rights to push);
		}
		Pull changes{
			- git pull;
			- git checkout <path/to/file> in case there is a staged file which will be overridden: "error: Your local changes to 'xxx' would be overwritten by merge. Aborting."
		}
	}
}

WINDOWS CMD {
    - dir <Folder Name> /AD /s 				===> find a dir in all subdirs of a drive
    											/A - Displays files with specified attributes. 
    											/D - Attribute be Directories 
    											/s - Displays files in specified directory and all subdirectories;
    - curl -s -D - http://www.delfi.lt -o NUL:    						===> redirect output to NUL (like /dev/null);
    - dir /s /b myfile.txt 												===> find a file in windows file system (very fast); you have to be at the root of the dir you search in;
    - for /l %x in (1, 1, 10) do echo %x								===> for loop;
    - for /l %x in (1, 1, 100) do (curl https://dojo-rc.zulu.com -L) ===> simple for loop onliner in windoes;
    - for /l %x in (1, 1, 100) do (
    	echo %x
    	copy %x.txt z:\whatever\etc
	)
	- routes print 														===> check the routes table;
	- 
}


ZU LOGING MECHANISM{

	ELASTIC SEARCH{
		Documentation {
			Life inside a cluster{
				- What is a cluster: users (and other computers) see the cluster as a single machine even though it is made up of multiple servers. The single machine that the users see is the virtual server. The physical servers that make up the virtual server are known as cluster nodes.
					- Network Load Balancing - many nodes, all or many active;
					- Server clusters - many nodes, ony one active - RDBS instances;
				- Quorum is just a onfiguration database (orconfiguarion file) - the quorum tells the cluster which node is currently active and which node or nodes are in stand by.
				- The partition that â€œownsâ€ the quorum is allowed to continue running the application. The other partition is removed from the cluster.
				- The cluster generally requires more than half the nodes to be running, which is known as having â€œquorumâ€. The model is "prefer the majority:  majority of nodes running, so only one of these groups will stay online.
				- Horizontal scale, or scaling out;
				- Elasticsearch is distributed by nature: it knows how to manage multiple nodes to provide scale and high availability;
				- cluster consists of one or more nodes with the same cluster.name
				- As nodes are added to or removed from the cluster, the cluster reorganizes itself to spread the data evenly;
				- Any node can be a master and it does not need to be involved in doc processing;
				- Cluster-wide changes:
					- Creating or deleting an index;
					- Adding or removing a node from the cluster;
					- Q: any more?
				- Every node knows where each document lives and can forward our request directly to the nodes that hold the data;
				- https://es.zulu.com/_plugin/kopf/#!/rest 		===> test ES queries here;
				- https://es.zulu.com/_nodes 					===> reposts all the plugins and settings for the nodes in the cluster;
				- GET /_cat/master 									===> check which node is master;
				- es.zulu.com/_cluster/state?pretty=true 		===> also can check which node is master; 		===>
				- es.zulu.com/_cache/clear?query_cache=true 		===> invalidate query cache 					===> returns: {"_shards":{"total":134,"successful":134,"failed":0}}
				- GET /_cluster/health??pretty=true					===> status of either green, yellow, or red;
					{
					  "cluster_name" : "elasticsearch",
					  "status" : "green",
					  "timed_out" : false,
					  "number_of_nodes" : 2,
					  "number_of_data_nodes" : 2,
					  "active_primary_shards" : 67,
					  "active_shards" : 134,
					  "relocating_shards" : 0,
					  "initializing_shards" : 0,
					  "unassigned_shards" : 0,
					  "number_of_pending_tasks" : 0
					}
				}
					- Green: All primary and replica shards are active;
					- Yellow: All primary shards are active, but not all replica shards are active;
					- Red: Not all primary shards are active;

				Split brain problem {
					- Primary shard (0P) and replica shard (0R) exist in master node and non-master node;
					- the communication is lost between them, so both become masters (as the non-master one elects itself as a master). Both nodes think that the other one failed.
					- Q: do elastic instance send failure massages to master node when they fail?
					- Now we have two nodes, indexing requests succeed on any on both nodes, but the results of queries would  be different depending on which nodes is hit. So the cluster is now in an inconsisten state; Divergent indexes. For a non-cluster aware indexing client (e.g. one using the REST interface) this problem will be totally transparent â€“ indexing requests will be successfully completed every time, regardless of which node is called. The problem would only be slightly noticeable when searching for data: depending on the node the search request hits, results will differ.
					- discovery.zen.minimum_master_nodes 								===> This parameter determines how many nodes need to be in communication in order to elect a master. Itâ€™s default value is 1. The rule of thumb is that this should be set to N/2 + 1, where N is the number of nodes in the cluster. For example in the case of a 3 node cluster, the minimum_master_nodes should be set to 3/2 + 1 = 2 (rounding down to the nearest integer).
					- discovery.zen.ping.timeout 										===> determines how much time a node will wait for a response from other nodes in the cluster before assuming that the node has failed.
					- why would you want to set up a cluster with a minimum of 3 nodes 	===> because there is tradeof in two nodes cluster. Either you will have a possiblity to have split brain problem or you will have the high availability with the replica shards. 
					- node.data 														===> each elasticsearch node you can chose if that node will hold data or not; data-less node, it can be started on less expensive hardware. Now you have a cluster of three nodes, can safely set the minimum_master_nodes to 2, avoiding the split-brain and still afford to lose a node without losing data
				}
			}

			Template {
				  "zulu_node" : {
				    "order" : 0,
				    "template" : "*",
				    "settings" : {
				      "index.refresh_interval" : "60s"
				    },
				    "mappings" : {
				      "js_challenge_logs" : {
				        "properties" : {
				          "request" : {
				            "index" : "analyzed",
				            "type" : "string",
				            "fields" : {
				              "raw" : {
				                "ignore_above" : 256,
				                "index" : "not_analyzed",
				                "type" : "string"
				              }
				            }
				          },
				          "headers" : {
				            "properties" : {
				              "user-agent" : {
				                "index" : "analyzed",
				                "type" : "string",
				                "fields" : {
				                  "raw" : {
				                    "ignore_above" : 256,
				                    "index" : "not_analyzed",
				                    "type" : "string"
				                  }
				                }
				              }
				            }
				          }
				        }
				      },
				      "_default_" : {
				        "dynamic_templates" : [ {
				          "string_fields" : {
				            "mapping" : {
				              "index" : "not_analyzed",
				              "omit_norms" : true,
				              "type" : "string",
				              "fields" : {
				                "raw" : {
				                  "ignore_above" : 256,
				                  "index" : "not_analyzed",
				                  "type" : "string"
				                }
				              }
				            },
				            "match_mapping_type" : "string",
				            "match" : "*"
				          }
				        } ],
				        "properties" : {
				          "geoip" : {
				            "path" : "full",
				            "dynamic" : true,
				            "type" : "object",
				            "properties" : {
				              "location" : {
				                "type" : "geo_point"
				              }
				            }
				          },
				          "@version" : {
				            "index" : "not_analyzed",
				            "type" : "string"
				          },
				          "http_request" : {
				            "properties" : {
				              "all" : {
				                "type" : "string"
				              }
				            }
				          }
				        },
				        "_all" : {
				          "enabled" : true
				        }
				      },
				      "modsec_logs" : {
				        "properties" : {
				          "req_headers" : {
				            "type" : "nested"
				          },
				          "messages" : {
				            "type" : "nested"
				          }
				        }
				      },
				      "api_logs" : {
				        "properties" : {
				          "request" : {
				            "index" : "analyzed",
				            "type" : "string",
				            "fields" : {
				              "raw" : {
				                "ignore_above" : 256,
				                "index" : "not_analyzed",
				                "type" : "string"
				              }
				            }
				          },
				          "response_headers" : {
				            "type" : "nested"
				          },
				          "clientip" : {
				            "index" : "analyzed",
				            "type" : "string",
				            "fields" : {
				              "raw" : {
				                "ignore_above" : 256,
				                "index" : "not_analyzed",
				                "type" : "string"
				              }
				            }
				          },
				          "request_headers" : {
				            "type" : "nested"
				          }
				        }
				      },
				      "caching_logs" : {
				        "_routing" : {
				          "path" : "webapp_domain",
				          "required" : true
				        },
				        "properties" : {
				          "request" : {
				            "index" : "analyzed",
				            "type" : "string",
				            "fields" : {
				              "raw" : {
				                "ignore_above" : 256,
				                "index" : "not_analyzed",
				                "type" : "string"
				              }
				            }
				          },
				          "req_headers" : {
				            "type" : "nested"
				          }
				        }
				      }
				    },
				    "aliases" : { }
				  },
				  "logstash" : {
				    "order" : 0,
				    "template" : "logstash-*",
				    "settings" : {
				      "index.refresh_interval" : "5s"
				    },
				    "mappings" : {
				      "_default_" : {
				        "dynamic_templates" : [ {
				          "message_field" : {
				            "mapping" : {
				              "index" : "analyzed",
				              "omit_norms" : true,
				              "type" : "string"
				            },
				            "match_mapping_type" : "string",
				            "match" : "message"
				          }
				        }, {
				          "string_fields" : {
				            "mapping" : {
				              "index" : "analyzed",
				              "omit_norms" : true,
				              "type" : "string",
				              "fields" : {
				                "raw" : {
				                  "ignore_above" : 256,
				                  "index" : "not_analyzed",
				                  "type" : "string"
				                }
				              }
				            },
				            "match_mapping_type" : "string",
				            "match" : "*"
				          }
				        } ],
				        "_all" : {
				          "omit_norms" : true,
				          "enabled" : true
				        },
				        "properties" : {
				          "geoip" : {
				            "dynamic" : true,
				            "type" : "object",
				            "properties" : {
				              "location" : {
				                "type" : "geo_point"
				              }
				            }
				          },
				          "@version" : {
				            "index" : "not_analyzed",
				            "type" : "string"
				          }
				        }
				      }
				    },
				    "aliases" : { }
				  }
				}

			}
		}
		- horizontal scale, or scaling out
		- https://stage-es.zulu.com/_template/?pretty 										===> check that templates exist for a particular elastic;
		- https://stage-es.zulu.com/2015.07.06/_mapping/caching_logs/?pretty 				===> mapping for a particular day based index;
		- http://stackoverflow.com/questions/21749997/see-all-executed-elasticsearch-queries 	===> check queries executed
		- zulu@stage-elasticsearch1-new:~$ sudo find / -name "*elasticsearch.yml 			===> /etc/elasticsearch/elasticsearch.yml
		- zulu@stage-elasticsearch1-new:~$ sudo find / -name "*elasticsearch.log" 			===> /var/log/elasticsearch/elasticsearch.log




		Parsing logs retrieved directly from ES {
			- curl -XGET 'http://localhost:9200/2015.10.01,2015.10.02,2015.10.03,2015.10.04,2015.10.05,2015.10.06,2015.10.07/_search?q=hostname:media.ttms.co&size=100'
			- curl -s -u **:** -XPOST 'https://es.zulu.com/_search?pretty' -d '{"query":{"query_string":{"query":"webapp_domain: www.example* AND _type:modsec_logs","analyze_wildcard":true}}}'
			- curl -s -u zulubot:123 -XPOST 'https://es.zulu.com/_search?pretty' -d '{"query":{"query_string":{"query":"webapp_domain: www.example* AND _type:modsec_logs","analyze_wildcard":true}},"size":1000}' | python -m json.tool | grep index\"
			- curl -s -u **:** -XGET 'https://es.zulu.com/_cat/indices?v' | grep green 		===> get all green indexes
			- '{"query":{"match_all":{}},"sort":{"balance":{"order":"desc"}}}'
			- '{"query":{"query_string":{"query":"webapp_domain: www.examples.com AND _type:modsec_logs AND index_name:'2015.10.09'","analyze_wildcard":true}},"size":100000}'
			- "aggregations" : {
				"mind_agg" : {
				"doc_count_error_upper_bound" : 0,
				"sum_other_doc_count" : 0,
				"buckets" : [
				{
				"key" : "demo.netcielo.com",
				"doc_count" : 7009
				},
				{
				"key" : "www.examples.com",
				"doc_count" : 4631 ...

				===> this is what a query with an aggregation returns, the result of such query;
		} 


		KIBANA{
			- http://www.lucenetutorial.com/lucene-query-syntax.html 										===> kibana queries;
			- webapp_domain:php2-mindaugasb.c9.io AND type:access_control_logs
			- hostname:*.example.com AND (!response:2** OR !response:3**) AND type:caching_logs 			===> wildcard and negation
			- AND (response:>200 OR response:<200) | AND NOT response:200															===> every response code except 200
			- _type: "caching_logs" AND NOT agent:"-" AND NOT agent:"" 										===> one can use NOT keyword
			- verb:HEAD AND (clientip:10.* OR clientip:172.16.* OR clientip:172.17.* OR clientip:172.18.* OR clientip:172.19.* OR clientip:172.20.* OR clientip:172.21.* OR clientip:172.22.* OR clientip:172.23.* OR clientip:172.24.* OR clientip:172.25.* clientip:172.26.* OR clientip:172.27.* OR clientip:172.28.* OR clientip:172.29.* OR clientip:172.30.* OR clientip:172.31.* OR clientip:192.168.*) 	
																											===> get all the HEAD requests issued from internal IP's (10.0.0.0/8, 172.16.0.0./12, 192.168.0.0/16)
			- 400 AND NOT verb: HEAD AND NOT (clientip: [172.16.* TO 172.32.*] OR 10.* OR 192.168.*) 		===> same as above just using ranges;
			- clientip:[10.0.0.0 TO 10.255.255.255] OR 
				>/dev/null OR 
				clientip:[192.168.0.0 TO 192.168.255.255]													===> correct way to query with IP ranges;
			- webapp_domain:www.examples.com AND _type:modsec_logs AND url: \/shop\/prod*					===> beings with url /shop ... + wildcard usage;
			- { "analyze_wildcard": true, "lowercase_expanded_terms": false } 								===> in search.zulu.com/#/settings/advanced to spot Lucene query engine lowercasing the expanded terms (whihc are )


			Building top blocked IP's by WAF {
				- _type: "modsec_logs" AND action: "ENABLED";
				- use the rare OS's visualization as an example;
			}

			Tutorial (w/ vagrant VM): https://www.timroes.de/2015/02/07/kibana-4-tutorial-part-2-discover/

		}
	} Synonyms: elastic, elastic search, elasticsearch;

	
	TROUBLESHOOTING{
		-
	}

	HEKA{
		- https://hekad.readthedocs.org/en/v0.10.0b0/ 				===> heka documentation;
		- sudo service hekad [stop|start]
		- /var/log/heka.log
		- hekad -config=/path/to/sanity_check.toml 					===> start heka with overriden params
		- How dows heka know where to start parsing after restart  	===> Heka stores the current location in a â€œseekjournalâ€ file, at /var/cache/hekad/logstreamer/LogstreamerInput by default. If you delete this file and then restart Heka you should see it load the entire file from the beginning again.
		- /var/cache/hekad/ 										===> default base_dir

		-Our main toml file {

			[hekad] 																	# TOML section header
			maxprocs = 2 																# This setting corresponds to Goâ€™s GOMAXPROCS environment variable. It specifies how many CPU 																																	cores the hekad process will be allowed to use. For dedicated Heka aggregator machines, this should 																				  										usually be equal to the number of cpu cores available, or perhaps number of cores minus one, while 																			   												for Heka processes running on otherwise busy boxes one or two is probably a better choice.

			# [StatsdInput] 															# Heka config to include StatsdInput and StatAccumInput. First one uses all defaults. Second one overrides two of them.

			# [StatAccumInput] 															# This and the one below are the same, just toml header now is an arbitrary name, and type is specified explicitly
			# ticker_interval = 1
			# emit_in_fields = true

			# [stat_accumulator]
			# type = "StatAccumInput"
			# ticker_interval = 1
			# emit_in_fields = true


			[zul_caching_logs]
			type = "LogstreamerInput"
			log_directory = "/usr/local/openresty/nginx/logs"
			file_match = '(?P<webapp_domain>.*)_access\.log' 							# Capture a matching group into the webapp_domain variable. Can be optional: 
																						  file_match = 'access\.log\.?(?P<Index>\d+)?(.gz)?'
			priority = ["webapp_domain"] 												# Sort by webapp_domain. (^) reverses the order of the priority, here - lower digits mean 																			   			  newer files. So newer = higher. B is newer than A, 2 is newer than 1.
			differentiator = ["webapp_domain", "_zul_caching_logs"] 					# differentiator = ["nginx.", "DomainName", ".access"]
																						  "hekathings.com-access.log" will become
																						  "nginx.hekathings.com.access" due to the file match file_match = '(?P<DomainName>[^/]+)-access\.log'
																						  it will create the logger name attached to each message
			decoder = "zulCachingLogsDecoder"											# a decoder simply parses the content. Default behavior - Heka creates a new message for each 																				  	  line in the log file, storing the text of the log line as the payload of the Heka message. 

			[zulCachingLogsDecoder]
			type = "SandboxDecoder"
			script_type = "lua"
			filename = "lua_decoders/zul_caching_logs.lua" 								# script location


			# Ships:
			# 1) our Lua logs, that are read from webapp error log. This includes
			# many types of logs like access_rules_logs, threat_logs, captcha_logs, etc.
			# 2) Lua errors
			[zul_lua_logs]
			type = "LogstreamerInput"
			log_directory = "/usr/local/openresty/nginx/logs"
			file_match = '(?P<webapp_domain>.*)_error\.log'
			priority = ["webapp_domain"]
			differentiator = ["webapp_domain", "_zul_lua_logs"]
			decoder = "zul_lua_logs_decoder"
			splitter = "zul_lua_logs_splitter"

			[zul_lua_logs_decoder]
			type = "SandboxDecoder"
			script_type = "lua"
			filename = "lua_decoders/zul_lua_logs.lua"

			[zul_lua_logs_splitter]
			type = "RegexSplitter"
			delimiter = '(, client: \d+\.\d+\.\d+\.\d+, server: .*?, request: "[^"]*", host: "[^"]*")'


			[nginx_error_logs]
			type = "LogstreamerInput"
			log_directory = "/usr/local/openresty/nginx/logs"
			file_match = 'error\.log'
			decoder = "zul_nginx_error_logs_decoder"

			[zul_nginx_error_logs_decoder]
			type = "SandboxDecoder"
			script_type = "lua"
			filename = "lua_decoders/zul_nginx_error_logs.lua"

			{

						// path: /usr/share/heka/lua_decoders/zul_nginx_error_logs.lua

						local cjson  = require "cjson"
						local os     = require "os"
						local string = require "string"

						local zul    = require "zul"


						function process_message()
						  local log = read_message("Payload")

						  local msg
						  local pat = "(%d+)/(%d+)/(%d+) (%d+):(%d+):(%d+) %[(%w+)%] %d+#%d+: (.*)" 	===> then look at how the pattern is matched

									This shit:
										(%d+)/(%d+)/(%d+) (%d+):(%d+):(%d+) %[(%w+)%] %d+#%d+: (.*)
									Becomes this:
										(\d+)\/(\d+)\/(\d+) (\d+):(\d+):(\d+) \[(\w+)\] \d+#\d+: (.*)
									And matches this: 
										2015/10/04 18:27:44 [error] 24864#0: *9016379 connect() failed (110: Connection timed out) while connecting to upstream, client: 31.184.238.235, server: students.cc.org, request: "GET /kaitlin2015104/hs-art-classes/honors-studio-art/knowledge/isometric-drawing-idea/ HTTP/1.0", upstream: "http://211.152.40.155:80/kaitlin2015104/hs-art-classes/honors-studio-art/knowledge/isometric-drawing-idea/", host: "students.cc.org"

						  string.gsub(log, pat, function (
						      year, month, day, hour, min, sec, severity, text)

						    if not zul.NGINX_LOG_SEVERITY[severity] then return end

						    local time_sec = os.time{
						      year  = year,
						      month = month,
						      day   = day,
						      hour  = hour,
						      min   = min,
						      sec   = sec,
						    }

						    local data = {
						      type            = 'nginx_error_logs', 									===> pay attention, that the decoder contains the actual data, part of which is 
						      hostname        = read_message("Hostname"),
						      ['@timestamp']  = os.date("!%Y-%m-%dT%TZ", time_sec),
						      text            = log,
						    }

						    msg = {
						      Timestamp = time_sec * 1000000000,
						      Type      = 'nginx_error_logs',
						      Payload   = cjson.encode(data),
						    }
						  end)

						  -- this should only ignore nginx logs with too low severity to be shipped
						  if not msg then
						    -- This is a hack to drop the message.
						    -- Heka sandbox decoders don't have a way of dropping a message
						    -- without logging an error (only encoders can do that).
						    -- We don't want to log an error for messages that are legitimately
						    -- dropped, so instead we form a dummy message with a special type
						    -- "__drop" that is then filtered out in the message_matcher.
						    -- @see https://github.com/mozilla-services/heka/issues/1398
						    msg = {
						      Type    = "__drop",
						      Payload = "{}",
						    }
						  end

						  if not pcall(inject_message, msg) then return -1 end

						  return 0
						end
			}

			[apache_error_logs]
			type = "LogstreamerInput"
			log_directory = "/usr/local/apache2/logs"
			file_match = '(?P<webapp_domain>.*)_error\.log'
			priority = ["webapp_domain"]
			differentiator = ["webapp_domain", "_apache_error_logs"]
			decoder = "zul_apache_error_logs_decoder"

			zul_apache_error_logs_decoder {
							local cjson   = require "cjson"
							local os      = require "os"
							local string  = require "string"

							local dt      = require "date_time"


							function process_message()
							  local log = read_message("Payload")

							  local msg
							  local pat = "%[(%w+) (%w+) (%d+) (%d+):(%d+):(%d+)%.(%d+) (%d+)%]"
							  string.gsub(log, pat, function (
							      _, month, day, hour, min, sec, microsec, year)

							    local date_str  = string.format(
							      "%s %02d %02d:%02d:%02d %d",
							      month, day, hour, min, sec, year)
							    local time      = dt.rfc3164_timestamp:match(date_str)
							    local time_ns   = dt.time_to_ns(time) + (microsec * 1000)
							    local time_sec  = time_ns / 1000000000

							    local type = 'apache_error_logs'
							    local data = {
							      type            = type,
							      hostname        = read_message("Hostname"),
							      ['@timestamp']  = os.date("!%Y-%m-%dT%TZ", time_sec),
							      text            = log,
							    }

							    msg = {
							      Type      = type,
							      Timestamp = time_ns,
							      Payload   = cjson.encode(data),
							    }
							  end)

							  if not msg then return -1, "Failed to parse log message" end

							  if not pcall(inject_message, msg) then return -1 end

							  return 0
							end
			}


			[zul_apache_error_logs_decoder]
			type = "SandboxDecoder"
			script_type = "lua"
			filename = "lua_decoders/zul_apache_error_logs.lua"


			[modsec_logs]
			type = "LogstreamerInput"
			log_directory = "/usr/local/openresty/nginx/logs/waf"
			file_match = '(?P<webapp_domain>.*)'
			priority = ["webapp_domain"]
			differentiator = ["webapp_domain", "_modsec_logs"]
			decoder = "modsec_logs_decoder"
			splitter = "modsec_logs_splitter"

			[modsec_logs_decoder]
			type = "SandboxDecoder"
			script_type = "lua"
			filename = "lua_decoders/modsec_logs.lua"

			[modsec_logs_splitter]
			type = "RegexSplitter"
			delimiter = '--[a-fA-F0-9]{8}-Z--'


			#[LogOutput] 											# This is left here for debug purposes. It will print stuff to hekas stdout.
			#message_matcher = "TRUE" 								# We set message_matcher = â€œTRUEâ€ to specify that this output should capture every single message that flows through the Heka pipeline. 
			#encoder = "PayloadEncoder" 							# The encoder setting tells Heka to use the PayloadEncoder that weâ€™ve configured, which extracts the payload from each 
																		captured message and uses that as the raw data that the output will send.

			[PayloadEncoder]
			append_newlines = false

			[central-collector]
			type = "TcpOutput"
			address = "172.31.41.6:5555"
			message_matcher = "Type != '__drop'" 					# Message matching is done by the hekad router to choose an appropriate filter(s) to run. Every filter that matches 															  will get a copy of the message.
		}

		Central collector config {

			#rc
			[hekad]
			maxprocs = 2
			max_message_size = 2000000

			#listen for logs from LB
			[HttpListenInput]
			address = ":5000"

			#listen for logs from the nodes
			[TcpInput]
			address = ":5555"

			[RstEncoder]

			#[LogOutput]
			#message_matcher = "Type == 'heka.httpdata.request' || Logger =~ /_zul_caching_logs$/ || Logger =~ /_zul_lua_logs$/ || Logger =~ /_modsec_logs$/"
			#encoder = "RstEncoder"

			[PayloadEncoder]
			append_newlines = false


			[ElasticSearchOutput]
			message_matcher = "Type == 'heka.httpdata.request' || Logger =~ /_zul_caching_logs$/ || Logger =~ /_zul_lua_logs$/ || Logger =~ /_modsec_logs$/"
			encoder = "zul_es_payload"
			flush_interval = 50
			username = "zulubot"
			password = "123"
			server = "https://stage-es.zulu.com"

			[zul_es_payload]
			type = "SandboxEncoder"
			filename = "lua_encoders/zul_es_payload.lua"
			output_limit = 2000000

			    [zul_es_payload.config]
			    es_index_from_timestamp = true
			    index = "%{%Y.%m.%d}"
			    type_name = "%{Type}"


			[Dashboard]
			type = "DashboardOutput"
			address = "0.0.0.0:80"
			ticker_interval = 1


			[log_file]
			type = "FileOutput"
			message_matcher = "Type == 'heka.httpdata.request' || Logger =~ /_zul_caching_logs$/ || Logger =~ /_zul_lua_logs$/ || Logger =~ /_modsec_logs$/"
			path = "/stats/collect.log"
			perm = "666"
			flush_count = 100
			flush_operator = "OR"
			encoder = "zul_es_payload"

		}

		This is an interesting decoder{ 
			[modsec_geoip_decoder]
			type = "GeoIpDecoder"
			db_file = "/usr/share/GeoIP/GeoLiteCity.dat"
			source_ip_field = "__ip_for_geo" 	# source field is in the modsec decoder;
			target_field = "__modsec_geoip"		# target field is in the 
		}
	}

	LOGSTASH {
		- sudo initctl status logstash-daily-agent
		- sudo initctl stop logstash-daily-agent
		- sudo initctl start logstash-daily-agent
		- /usr/local/logstash/logstash.log
		- sudo initctl start logstash-daily-agent
		- sudo rm -f .* 							===> to solve logstash sincedb issue you need to remove the files where logstash tracks where it last finished processing the logs file;
		- ls -li 									===> check the inode of the log files and match them with the logstash dot-files;
	} Synonyms: logstash;



LINUX {

	Questions{
		Facebook interview {
			1. What phase of a server booting does kexec skip? 					===> kexec just skips POST or UEFI. Long form: hardware initialization normally performed by the BIOS or firmware (depending on architecture) is not performed during a kexec boot;
			2. What TCP option is used to terminate connection?					===> FIN and RST;
			3. What is the length of ipv6 address in bytes? 					===> 16 bytes, 128 bits;	
			4. What protocol is used to convert IP to MAC? 						===> ARP;
			5. Which command is used to generate initrd file? 					===> mkinitrd arba dracus
			6. What does strace do? 											===> system calls tracing;
			7. What is tcpdump? 												===> network sniffer with which you can inspect network traffic in / out. Provides advanced filtering capabilities with BPF style syntax and inbuilt options for filtering (like dst port). Is not capable of decrypting TLS/SSL traffic in that case tshark or other tools should be used. Provides a possibility to save network traffic for latter inspection.
			8. Which signals can't you use in application as signal handlers? 	===> SIGKILL ir SIGSTOP. â€œkill -9 <PID> tells the kill command that you want to send signal #9, which is called SIGKILL. â€œ
			9. Can you kill a zombie process? 									===> A zombie is already dead, so you cannot kill it. To clean up a zombie, it must be waited on by its parent, so killing the parent should work to eliminate the zombie. (After the parent dies, the zombie will be inherited by init , which will wait on it and clear its entry in the process table.) ... Zombie isn't a process, it's just a state which wasn't sent to parent
			10. Tell 3 or more process states. 									===> interuptable sleep, uninteruptable sleep, zombie, running, sleeping. Zombie is a process state and deamon is not. Deamon is process TYPE (together with background process, foreground process). Why is zombie a state - because it has no resources allocated, just state is not freed; State is a variable with some value in the kernel process structure, something like "struct task_struct {}".
			11. What file controls the size of a core dump for a process running as a named user or group? 	===>  /etc/security/limits.conf arba ulimit -a;
			12. Where is resolv.conf located? 									===> /etc/resolv.conf
			13. What does 'uname -a' print? 									===> information about OS;
			14. What's the shortest ipv6 address? 								===> :: (all zeros);
			15. What command can show you I/O queue size?						===> vmstat;
			16. What is the length of ipv6 header in bytes? 					===> The IPv6 header is always present and is a fixed size of 40 bytes.
			17. How to check which OS version (name) you are using in a portable way ===> cat /etc/issue
			18. Which syscall is used to create a new process? 					===> fork() the operating system will create a new process that is exactly the same as the parent process. \
																					 exec() new process is not part of the same program as parent process, \
																					 clone() su CLONE_FS, CLONE_NEWPID; In the kernel, fork is actually implemented by a clone system call. Fork() is just a wrapper for clone() with some flagging options \
			19. What is filedescriptor number 2? 								===> stderr
			20. What is the first available file descriptor for a process? 		===> fd 3
			
		}
		Other {
			- How to check file descriptors available for a process? 			===>
			- Find out the counte of IP addresses owned by google / facebook 	===> IS this the way: http://snurps.blogspot.com/2013/10/how-many-ip-addresses-does-google-have.html ? \
																					or would you rather find our the AS number and then the prefixes owned by that number.
		}
	}

	LINUX CMD / TERMINAL / CLI {

		TROUBLESHOOTIG {
			apt-get install does not work {
				E: Encountered a section with no Package: header
				E: Problem with MergeList /var/lib/apt/lists/archive.ubuntu.com_ubuntu_dists_natty_main_binary-i386_Packages
				E: The package lists or status file could not be parsed or opened.

				Solution: 
					sudo rm /var/lib/apt/lists/* -vf
					sudo apt-get update
			}
		}

		Dojo {
			- list all file that begin with 'c' in a directory {
				- ls -alht | egrep ' [c].+'
				- ls | egrep ^c
			}
		}
		ANDROID SHELL{
			- adb shell ls -aR | grep jpg -- find all jpg's in the device
			-
		}

		- ctrl+r + ctrl+r 					===> reverse-search w/ cycling though bash history (I wonder if that works for other shells as well); 
		- command #usefull 					===> bashtags, to find the commands fast with reverse-search;
		- tr -cd "[:print:]" < file1 				===> remove all non printable characters from a file;
		- /bin/bash -c "ruby -e "puts \"a\n\n\""" >> some.log 2>&1 				===> produces and empty file, because the qoutes are incorrectly added;
		- /bin/bash -c "sleep 2; (time ruby -e \"puts \\\"a\\\n\\\"\") >> /my.log 2>&1" 	===> correctly escaped time + ruby command with internal statments;
		- { time ; } 2> my.log 									===> redirect `time` commands output to a file (you have to obtain it from standard error);
		- (time ruby -e "puts \"a\n\"") >> /home/my.log 2>&1 					===> redirect `time` commands output - you have to add parentheses;
		- (time ruby /home/mindaugas/Ruby_Scripts/Crontab_Test/test1.tb $(date -d 'yesterday' '+\%Y-\%m-\%d')) >> \
				/home/mindaugas/Ruby_Scripts/Crontab_Test/my.log 2>&1	===> redirect time + ruby command output to a file ... can place it to cron directly

		- sudo sh -c "echo 'aaaa' > /usr/local/apache2/conf/httpd.conf" 			===> appdend something to a file belonging to root user (sudo echo will not work because the shell is 																					doing output redirection, not echo or sudo);
		- stat, fstat, lstat <path> 					===> get file status;
		- cat /proc/sys/fs/file-max 					===> see global max open files:
		- cat /proc/sys/fs/file-nr 					===> see global current open files: 
		- sysctl -w fs.file-max=1000000 or edit sysctl.conf 		===> change global max open files: 
		- ulimit -Hn   (hard limit) 					===> limits for the current user
		- ulimit -Sn   (soft limit)
		- apache2 soft nofile 4096 					===> edit /etc/security/limit.conf to set limits for a webserver for example
		- apache2 hard nofile 10000
		- for pid in $(pgrep apache2); do ls /proc/$pid/fd | wc -l; done 	===> you can have a script go through /proc and gives you some statistics:
		- dd if=/dev/urandom of=foo bs=14MB count=1 				===> create a file of precise size and with random data;
		- truncate -s 10G foo 							===> create a file of precise size (empty, can be useless when trying to determine download speeds) 
		- fallocate -l 5G bar 														===> create a file of precise size (empty, can be useless when trying to determine download speeds) 
		- watch -n 0.5 'date ; date' 												===> continuous monitoring in place;
		- watch -n 1 'echo $(date)';
		- # watch does not provide scrolling capabilities
			watch -n 1 \
				'echo ""; \
				echo "----- local <-- client-----" ; netstat -ant | grep "172\.31\.31\.51:80" | grep "EST"; echo; \
				echo "----- server blocks   -----" ; netstat -ant | grep "127\.0\.0\.1:80" | grep "EST"; echo; \
				echo "----- proxy --> origin-----" ; netstat -ant | grep "178\.62\.187\.247:80" | grep "EST"; echo; \
				echo `date` ; echo "---------------------------------------------------------------" ;'

		- ssh zulu@95.85.60.162 -L 3210:localhost:2812 							===> ssh tunneling, general statment ssh user@host -L <local port>:localhost:<remote port>
		- ./nci . php-mindaugasb.c9.io/ | grep . -c | awk '{printf "%d\n", $1/2}' 	===> get the real count of cached resources by dividing the output into two;
		- <username> ALL=(ALL:ALL) NOPASSWD:ALL 									===> add this to the end of the file so user could masquerade as sudo w/o entering a password
		- sudo apt-cache showpkg <packagename> 										===> check where the package is
		- sudo apt-get purge <packagename> 											===> delete package with dependencies	
		- z(cat|diff) 																===> inspect gziped files without extracting them
	 	- ./configure && make && sudo make install  								===> 3 commands for installing software in Linux
		- cat /proc/meminfo 														===> check how much memory is avaialbe on the machine
		- file --mime-type -b filename 												===> find the mime type of a file;
		- dig -x 52.0.119.115 														===> check the domain that this ip belongs to
		- echo $(pwd)/file.txt 				 										===> echo the full path to some file
		- readlink -f file.txt 														===> echo the full path to some file
		- dpkg -l | grep linux-image 												===> list all installed kernels on a machine
		- dpkg -l | grep ze-lua 											
		- dpkg-query -l ze-lua 													
		- apt-cache policy ze-lua 					
		- uname -r | sed -r 's/-[a-z]+//'											===> check which kernel you are using
		- sudo apt-get autoremove linux-image-a.b.c linux-image-x.y.z 				===> remove unwanted kernels
		- ls -LR 																	===> Recursively (-R) list all files in a directory including files in symlink directories 
															- L :: dereferences symbolic links (a special type of file that contains a reference to another file or directory in the form of an absolute or relative path))
		- sudo find <dir> -name "*security*.erb" 									===> finds files like: "config/templates/security/limit_per_ip_security_setting.erb"
		- find /dir -type f -exec cat '{}' +; 										===> cat all files in the dir and all subdirs;
		- find . -type f -exec cat '{}' + > ~/Desktop/seed_rules.txt 				===> have to use full path;
		- find /usr/local/openresty/nginx/cache -maxdepth 1 -regextype posix-extended -regex '.+doga.+|.+goody.+' -type d | xargs ls -lht ===> using find with regex;
		- sudo grep -r -H --color "never" . 										===> grep recursively for some text in the current directory (for the period) printing out the lines with matches and coloring the matched pattern; -H for including the file name for each match;
		- ls -alht .. a - all (does not hide "." and ".."); l - long version (permisions to groups, file size, time of midification); h - size in human readable form; t - sort by time (from most recently modified)
		- cd.. - go back(up) one directory
		- axel - command line download accelerator for windows. You can download files with it from the internet to the diretory you are at(e.g.: mindaugas@ubuntu:~/Downloads$ axel -n20 http://c758482.r82.cf2.rackcdn.com/sublime_text_3_build_3059_x64.tar.bz2 :: download sublime text with maximum number of 20 connections)

		TAR {
			- tar -xvf <target-file.tar> 					===> extract conntents of an archive into a directory (xvf = extract all verboselly);
			- tar -xzvf <target-file.tar.gz> -C <target-dir> 		===> z flag for a tarball that is also gziped;
			- tar -czvf <name_of_archive_$(date +%Y%m%d-%H%M%S).tar.gz> <dir>	===> tar a directory
			- tar -czvf <name_of_archive_$(date +%Y%m%d-%H%M%S).tar.gz> <file> 	===> tar a file
		}

		- whereis - command that finds where a name occures in the filesystem (can be used to see where a program is installed to)
		- which - command "mindaugas@ubuntu:~/Downloads$ which google-chrome" >> /usr/bin/google-chrome
		- env | grep some-string - "env" is a shell command for Unix and Unix-like operating systems. It is used to either print a list of environment variables or run another utility in an altered environment without having to modify the currently existing environment. So in this case you are grepping inside the environment variables for "some-string"
		- rm -i - remove a file or directory from the current directory, but first inquire (-i) on whether I really want to do that (Y/N). You wont be able to remove directory before deleting the files in it with only "rm"
		- mv 					===> move command moves all the data from one file/directory to another and deletes the first one
		- mv * .. 				===> move all files from a directory to parent directory;
		- cat filename.txt 		===> print contents of the file to the screen
		- "^regex$" 			===> this is how you should write regexes in Linux, IN QUOTES
		- shift + insert 		===> paste into the command line (for example when SSH'ing with PUTTY)
		- ctrl + insert 		===> hot key combo for "copy" text
		- du -smh cache/* 		===> check the storage space used by all the folders in the cache folder -s for "summarize (only display the size of the top subdirectory of the directory in which the calculation is performed)" and -m (calculate in megabytes)
		- top 					===> to see the processes running and CPU utilization;
		- htop 					===> shows used system resources in a convenient form;
		- htop -d 5 			===> refresh every half a second (500 ms);
		- ps auxf - to see all running processes
		- ps auxf | grep [n]ginx - to grep nginx from the running processes
		- head -n10 <filename in the direcotry> - displays the specified number of FIRST lines of any text file into the standart output (screen)
		- tail -n10 <filename in the direcotry> - displays the specified number of LAST lines of any text file into the standart output (screen)
		- /sbin/ifconfig - to find out the ip address of the system
		- date 								===> shows the current time on a linux machine
		- date -d "yesterday" '+%Y-%m-%d' 	===> shows yesterdays date
		- ls -al | sort -k6,6M -k7,7n -k8,8 -r - the "k" flag indicates the column to start the the sorting from. To limit the "k" flag you just enter k[start],[finish], so the -k6,6 starts sorting from field 6 and stops at 6, not going to to the end of the line. "-r" for reverse, "n" for numeric sorting, "M" for sorting by dates
		- ls -lah --sort=size                                                       ===> sort by size
		- ls -lahS                                                                  ===> sort by size
		- ps -p <PID> -o etime= 													===> shows how long the process has been running for
		- ps -p `ps auxfww | grep nginx | grep master | awk '{print $2}'` -o etime= ===> similar to above
		- telnet <ip> <port> - to check whether a particular port is open on a remote machine, ping utility does not provide that luxury in linux
		- ./nginx-cache-inspector . cache/ | egrep -v 'zulu' -grep everything that does not match 'zulu' (don't do that in zulu folder though);
		- /usr/local/openresty/nginx/sbin/nginx -V :: shows modules that the nginx was compiled with
		- w<file_name> 																===> give your file a name before saving in vim;
		- grep . -c 																===> count the lines returned by some command (like another grep)
		- wc -l 																	===> count the lines returned by some command (like grep)
		- sudo lsof -i -n -P  | grep java 											===> check opened files, ports, sockets by all systems processes : -i (list ip sockets); -n (no names of hosts); -P (list ports without resolving their names). In unix, everything is a file, ( pipes, sockets, directories, devices, etc.). So by using lsof, you can get the information about any opened files, hence any of the entities;
		- lsof -u lakshmanan 														===> file for a specific user;
		- cat <list> | sort | uniq  												===> print a unique value from a list. SORT IS REQUIRED ! 
		- ZZ 																		===> vim, instead of wq!
		- cat rc.zulu.com 		| perl -pne 's/(\[msg.+?\])/\n\1\n/g' | awk '/\[msg/,/"\]/' | sort | uniq | wc  -l 			===> count all [msg xx] tags in LOGS for WAF
		- cat rc.zulu.com.conf 	| perl -pne 's/(,msg:.+?,|\")/\n\n_\1"_\n\n/g' | awk '/_,msg:/,/_/' | sort | uniq | wc -l 	===> count messages in LOGS file for WAF
		- shasum -a 256 /tmp/1.iso 													===> calculate shasums of the file
		- md5 /tmp/1.iso 															===> calculate md5 checksum of a file
		- cat /etc/lsb-release 														===> version of linux
		- sudo lsblk -o NAME,FSTYPE,SIZE,MOUNTPOINT,LABEL 							===> lsit all partitions on the linux box
		- df																		===> list all file systems
		- sudo ioping -c 10 -A /dev/vda1 											===> check the io latency (same as ping checks the network latency);
		- rm -- '??' 																===> remove directories and files with strange names;
		- tail -f ../../logs/error.log | pv -l -i1  > /dev/null 					===> monitor the pipe opened with tail -f with pv tool;
		- grep -aPo '\d{1,}' file.pcap 												===> grep from a binary file;

		IPTABLES {
			- iptables -P INPUT DROP 									===> Set the default policy of the INPUT chain to DROP
			- iptables -A INPUT -s 172.31.64.149 -m statistic --mode random --probability 0.1 -j DROP 	===>
			- iptables -nvL
			- iptables -nvL -t nat 										===> -t table
			- for table in filter nat mangle raw security; do iptables -vL -t $table; done
		}

		removing hard to remove files by their inode number {
			- ls -i 											===> get the inode numbers;
			- find -inum <#> -exec rm -i '{}' \; 								===> rm by inode number;
			- find -inum <#> -delete 									===> delete by inode number;
		}

		- sed {
			- sed -n -e 's/\[msg.\+\?\]//p' rc.zulu.com 							===> replacement with sed, note msg.\+\?
			- SED IS ALWAYS GREEDY 										===> you can't perform a non-greedy match with sed
			- sed -e '/start_pattern/,/end_pattern/!d' mindaugas2.com 					===> dot matches all does not work in grep, so use this to output multiple lines that beggin and end with some pattern
			- sed -n 16224,16482p filename 									===> display only certain lines of a file
		}

		- perl {
			- perl -pne '/\[msg/,/\]/' rc.zulu.com
			- echo [msg | perl -pne 's/(\[m)/x/'
			- echo [msg ss[ms | perl -pne 's/\[m/x/g'
			- echo "[msg xx] [id: xx]" | perl -pne 's/((?=\[msg).+?(\]))//g'
		}

		-awk {
			- printf "%s\n%s\n%s\n%s\n%s\n" RANDOM START ABCD END RANDOM | awk '/START/,/END/' 	===> only prints START ABCD END
			- awk '/start_pattern/,/end_pattern/' <file> {
				- easiest way to output multiple lines that contain the start and end patterns in them. This will not print substrings. Proof: echo -e '[msg xz]\n[id: xx]' | awk '/\[m/,/z\]/'
				- if you want to select only some substring you can combine perl / sed / with awk: 
				- cat rc.zulu.com | perl -pne 's/(\[msg.+?\])/\n\1\n/g' | awk '/\[msg/,/"\]/'
				- e.g.: awk '/\[origin_servers\]/,/\[\/origin_servers\]/' stage.zulu.net
				- awk '/\[origin.+\]/,/\[.origin.+\]/' stage.zulu.net
				- do not forget to escape some characters!
				- echo "Create" | awk '/^create/;'
				- echo "Create" | awk 'IGNORECASE = 1;/^create/;'
			}
			- awk '{print $0}' 							===> print the entire line;
			- awk '{print $1}'  							===> print the 1st col (col = 'space separated') $2, $3 are for 2nd, 3rd col;
			- awk '{print NR}'  							===> print NR = number of variables;
			- echo "a" | awk '{if ($1 == "a") print "c"; else print 'dd'}' 		===> conditional printing;
			- echo "a" | awk '{if ($1 == "a") printf("%20s\n","c"); else print "d"}'===> conditional printing w/ text pushed from beggining of line w/ printf();
			- gawk '{ t = $1; $1 = $2; $2 = t; printf "%-40s %s\n",$1,$2 }' 	===> interchange collumns in the output and print them with prepended spaces;
		}

		- sudo netstat -tulpn					===> check what application listens to what port
		- sudo cat /dev/null > file 	 			===> will elevate privileges > copy empty content into a file of your choise (meaning :: delete all contenst) > exit from root privilages;

		- Users & Groups {
			- [l|d|-|c|b]-rwx-rwx-rwx 			===> a symlink | directory | file | character device in /dev | block device in /dev - read write execute <owner> - read write execute <group> - read write execute <everyone else>;
			- cut -d: -f1 /etc/passwd 			===> list all users in linux;
			- echo 'GET aaa' | cut -d ' ' -f 1,2 		===> cut -d;
			- adduser <user_name> 				===> create a user
			- groups 					===> list all groups;
			- groups <username> 				===> list all groups the user belongs to;
			- chown -R <user_name> 				===> charnge owner of the file/directory;
			- chgrp -R <group_name> <file/directory_name> 	===> change group of the file/directory, [-R] to change all the files and subdirs as well;
			- chmod -R [u|g|o][+|-][r|w|x] <some_folder> 	===> change the permissions [add|subtract] of the folder for [user, group and others];
			- useradd -G {group-name} {user-name}; 		===> assign new user to group;
			- usermod -a -G {group-name} {user-name}; 	===> assign an existing user to a group;
			- sudo chown -R {user-name} /home/{user-name}	===> make user own all the directories in his home dire
		}

		- export PATH=$PATH:/path/to/dir1 --> add to path for current session (will be cleared when you change to root for example);
		- Permanent $PATH change {
			- [vim ~/.profile | vim /etc/profile] // edit the current users .profile file with the content below [or the system global profile - for all users]
			- PATH=$PATH:/home/me/play
			  export PATH
			- . ~/.profile
		}
		- ctrl + w 							===> delete 1 word before the cursor (space as a separator)
		- alt + backspace 						===> delete 1 word before the cursor (any non word character as a separator)
		- alt + d 							===> delete 1 word in front of the cursor (any non word character as a separator)
		- ctrl + k 							===> delete 1 word in front of the cursor (space as a separator)
		- cd - 								===> return to the previous directory;
		- watch -n 0.5 <your command> 					===> run the comman every 0.5 seconds
		- while true; do ls -alht | head -10; sleep 0.5; done 		===> this loop will not clear your screen;
		- ls -l | grep -c ^d 						===> count of directories in the current directory;
		- head\tail -10 						===> top\bottom 10 results of the command (if you pipe the ls -l output to | head -10 for example);
		- top [-P|-M] 							===> machine resource usage by cpu and by memory;
		- smem -pw 							===> system memory stats (free, kernel, ocupied);
		- date '+%A %W %Y %X' 						===> check time in linux in the format: Tuesday 29 2014 12:20:47 PM;
		- date 								===> displays date in default format;
		- mv filename1 filename2 					===> rename a file;
		- file <some_file>						===> see information about a file;
		- ctrl + D or 'exit' 						===> get back to normal user privilages;
		- export PATH=$PATH:/someNewPAth/:some/other:and/another 	===> adding a folder to the path so that the command existing in it would be called (path variable separators are ':') - SCOPE: ONLY CURENT SESSION;
		- cp -r 													===> moving the all the files from one dir to another;
		- diff -r <dir1> <dir2> 									===> compare contents of two directories, shows which files are only in dir1 and those only in dir2;
		- diff -r <dir1> <dir2> | grep <dir1> 						===> shows which files are only in dir1
		- diff <(ssh zulu@95.85.46.51 -i ~/.ssh/... cat something) <(ssh zulu@95.85.46.52 -i ~/.ssh/... ls -R /a.txt)
		- diff <(curl http://151.249.92.106/cdn.jpg -H "Host: zewaf.sslcs.cdngc.net" -D - -s -o /dev/null) <(curl http://151.249.92.112/cdn.jpg -H "Host: zewaf.sslcs.cdngc.net" -D - -s -o /dev/null)
																	===> diff using process substitution
		- sudo find / -name "[E|e]nhanced*" 						===> find a directory knowing only a fragment of it's name;
		- sudo find / -name "rc.zulu.com*" -o -name "php-*" 		===> find multiple files with "or"
		- sudo find / -type f -name 'php-mindaugasb.c9.io*' -exec rm -f {} \; 
																	===> delete all files returned by the find command;
		- cd ~ 														===> go to home directory;
		- cat /proc/cpuinfo 										===> shows CPU info for the LINUX maschine;
		- sudo service httpd restart 								===> restart apache
		- ps aux | grep -c httpd 									===> count occurances of apache sessions (normal session count is 73 after restart)
		- rpm -qa | grep -i zuldServer 								===> should check whether a programm exists on the machine;
		- sudo su 													===> elevate user to superuser level (user when using pipe);
		- which php 												===> displays path to PHP code (use when "whereis" does not work);
		- printenv 													===> Print part or all of the environment (only for environment variables);
		- set 														===> Set shell options (also lists both environemnt and shell variables (to exit the set use the command ":q!"));
		- export 													===> Export environment to subsequently executed programs;
		- alias 													===> Create an alias for a command;

		- Check the exit status of a last run command {
			>$ true
		  	>$ echo $? // this will return "1", for false it would return "0";
		}

		GNU PARALLELS {

			mycurl() {
			  TIME="$1"
			  DOMAIN="$2"
			  curl -s -u *** \
			         -XPOST 'https://es.zulu.com/_search' \
			         -d "{\"query\":{\"filtered\":{\"query\":{\"query_string\":{\"query\":\"_type:modsec_logs AND (action:ENABLED OR action:DETECTION_ONLY) AND webapp_domain:${DOMAIN}\",\"analyze_wildcard\":false}},\"filter\":{\"bool\":{\"must\":[{\"range\":{\"@timestamp\":{\"gte\":\"${TIME}T00:00:00.001Z\",\"lte\":\"${TIME}T23:59:59.999Z\"}}}],\"must_not\":[]}}}},\"size\":1}" | \
			         python -c "import sys; print unicode(sys.stdin.read(), errors='ignore')" | \
			         python -m json.tool
			}
			export -f mycurl

			printf "${DATES[@]}" | \
			perl -pne 's/_/\n/g' | \
			parallel --jobs $i --load 6 mycurl {} $DOMAIN

		}

		DIFF & PATCH tools {
			- diff -rupN first_dir second_dir > dir.patch 			===> create a diff of two directories with and all the files in them;
			- diff -u first second > dir.patch 						===> diff with unified context;
			- patch -p0 < p.patch 									===> -p0 strip 0 leading slashes. Example: *.patch file contains /usr/local/p.patch with -p0 it remains, with -p1 = /usr/local/p.patch and with -p2 = local/p.patch
		}

		NETWORKING {
			- sudo arp -s 10.0.0.2 00:0c:29:c0:94:bf 						===> add static ARP resolution;
			- ifconfig eth0 192.168.1.11 netmask 255.255.255.0 broadcast 192.168.1.255 		===> add ip address to an interface;
			- ifconfig eth0:0 192.168.0.2 netmask 255.255.255.0 					===> add ip alias / subinterface
			- ifconfig eth1:1 down									===> remove subinterface;
			- route -n 										===> list routes w/o resolving the names								===> check the routes;
			- route add -host 192.168.0.159 gw 0.0.0.0 netmask 255.255.255.0 			===> add route to a host;
			- route add -net 192.168.98.42 netmask 255.255.255.255 gw 192.168.99.1 			===> add route to a network;
			- route add [-net|-host] <Net|IP> netmask <Mask> gw <Gateway IP> dev <Int>X 		===> general template for route addition;
			- sudo route del -net 192.168.0.0/24 gw 0.0.0.0 dev eth0 				===> to delete a route.
			- ip route get 192.168.88.77 													===> get the route that will be used or a packet destined to a specific ip

			CURL {
				- curl -sI -H "User-Agent;" --trace-ascii - http://www.opera.com/ | grep "User-Agent:" 				===> to send empty request header with curl you need to terminate it with a semi;
				- curl -sI -L -H "User-Agent: Mindaugas" --trace-ascii - http://54.93.212.91/ -H "Host:trud.com" 	===> 
				- you can define the -w @curl.io flag and add the formating you want in a file curl.io like this:

					\n
					---\n
					 Size of Download Request:    %{size_download}\n
					---\n\n
					  time_namelookup:  %{time_namelookup}\n
					       time_connect:  %{time_connect}\n
					    time_appconnect:  %{time_appconnect}\n
					   time_pretransfer:  %{time_pretransfer}\n
					      time_redirect:  %{time_redirect}\n
					 time_starttransfer:  %{time_starttransfer}\n
					                    ----------\n
					         time_total:  %{time_total}\n
					\n\n
					DONE\n
					\n\n

				- domain="www.examples.com"; \
				curl -s -v -u *** \
				-XPOST 'https://es.zulu.com/_search' \
				-d '{"query":{"filtered":{"query":{"query_string":{"query":"_type:modsec_logs AND action:DETECTION_ONLY AND index_name:2015.10.18 AND NOT webapp_domain:*.zulu.net AND webapp_domain:$domain","analyze_wildcard":true}},"filter":{"bool":{"must":[{"range":{"@timestamp":{"gte":"2015-10-17T00:00:00.001Z","lte":"2015-10-17T07:59:59.999Z"}}}],"must_not":[]}}}},"size":999999}' \
				--trace-ascii /dev/stdout 																===> --trace-ascii prints the sent data and a lot of information. In this example you can check whether the "$domain" bash variable was substituted ... it was not.

				- curl --proxy http://172.16.1.26:8080  http://getcomposer.org/installer | php 			===> using CURL together with our proxy;
				- curl -s -w \
					"content_type \t%{content_type}\\n\
					filename_effective \t%{filename_effective}\\n\
					ftp_entry_path \t%{ftp_entry_path}\\n\
					http_code \t%{http_code}\\n\
					http_connect \t%{http_connect}\\n\
					local_ip \t%{local_ip}\\n\
					local_port \t%{local_port}\\n\
					num_connects \t%{num_connects}\\n\
					num_redirects \t%{num_redirects}\\n\
					redirect_url \t%{redirect_url}\\n\
					remote_ip \t%{remote_ip}\\n\
					remote_port \t%{remote_port}\\n\
					size_download \t%{size_download}\\n\
					size_header \t%{size_header}\\n\
					size_request \t%{size_request}\\n\
					size_upload \t%{size_upload}\\n\
					speed_download \t%{speed_download}\\n\
					speed_upload \t%{speed_upload}\\n\
					ssl_verify_result \t%{ssl_verify_result}\\n\
					time_appconnect \t%{time_appconnect}\\n\
					time_connect \t%{time_connect}\\n\
					time_namelookup \t%{time_namelookup}\\n\
					time_pretransfer \t%{time_pretransfer}\\n\
					time_redirect \t%{time_redirect}\\n\
					time_starttransfer \t%{time_starttransfer}\\n\
					time_total \t%{time_total}\\n\
					url_effective \t%{url_effective}\\n" \
				-o /dev/null 104.197.33.159 															===> curl displaying various options;
				- --trace-ascii /dev/stdout 															===> print what curl sends exactly;


				- Login to dojo with CURL {

					#!/bin/bash

					email="demo+admin@zulu.com"
					password="Happy#15"
					token=$(curl -s -c cookies.txt https://dojo-rc.zulu.com/accounts/login | grep -oE 'token" value=".*?"' | cut -c 15- | rev | cut -c 2- | rev)
					encoded_token=$(echo -n "$token" | perl -MURI::Escape -ne 'print uri_escape($_)')
					encoded_email=$(echo -n "$email" | perl -MURI::Escape -ne 'print uri_escape($_)')
					encoded_pass=$(echo -n "$password" | perl -MURI::Escape -ne 'print uri_escape($_)')

					curl 'https://dojo-rc.zulu.com/accounts/login' -vL -b cookies.txt -c cookies.txt \
					--data "utf8=%E2%9C%93&authenticity_token=$encoded_token&account%5Bemail%5D=$encoded_email&account%5Bpassword%5D=$encoded_pass&commit=Login" \
					--compressed

					curl 'https://dojo-rc.zulu.com/admin/dashboard' -vL -b cookies.txt -c cookies.txt

				}
			}

			TCPDUMP {
				- https://forum.ivorde.com/tcpdump-how-to-to-capture-only-icmp-ping-echo-requests-t15191.html
				- https://www.wireshark.org/tools/string-cf.html
				- sudo tcpdump -i eth0 -s 0 -nn '(src host 172.32.0.88 and dst port 9443)' or '(src host 172.32.0.43 and dst host 172.32.0.88 and src port not 80)' 	===> complex grouping example;
				- sudo tcpdump -s 0 -A 'tcp[((tcp[12:1] & 0xf0) >> 2):4] = 0x47455420' 		===> get GET headers with tcpdump;
				- sudo tcpdump -s 0 -A '(tcp[((tcp[12:1] & 0xf0) >> 2):4] = 0x504f5354)'	===> get POST headers with tcpdump; 
				- sudo tcpdump -D 															===> display network interfaces available for tcpdump;
				- tcpdump -i eth0 -nn port 80 and host <ip> -A 								===> run a tcpdump eth0 interface, -no-names, only IP's, -A:Print each packet in ASCII.
				- tcpdump -v icmp 															===> tcpdump for ICMP;
				- tcpdump -qns 0 -A -r first.pcap 											===> read pcap.files
				- tcpdump -nni eth0 icmp 													===> icmp packet capture;
				- tcpdump -nni eth0 icmp[icmptype] == 8 									===> only display ip packets that have icmp payload and icmptype 8 - ICMP Echo Request.
				- sudo tcpdump -s 0 -A 'tcp[((tcp[12:1] & 0xf0) >> 2):4] = 0x47455420' 		===>

					15:11:00.592960 IP (tos 0x0, ttl 63, id 50396, offset 0, flags [DF], proto TCP (6), length 223)
				    10.240.246.67.47967 > 172.17.110.147.8080: Flags [P.], cksum 0xfe0b (correct), seq 4118132980:4118133151, ack 2177413883, win 28, options [nop,nop,TS val 130055209 ecr 534856163], length 171
				        0x0000:  d26a ece8 f83f 0209 0275 f437 0800 4500  .j...?...u.7..E.
				        0x0010:  00df c4dc 4000 3f06 5a64 0af0 f643 ac11  ....@.?.Zd...C..
				        0x0020:  6e93 bb5f 1f90 f575 b8f4 81c8 b2fb 8018  n.._...u........
				        0x0030:  001c fe0b 0000 0101 080a 07c0 7c29 1fe1  ............|)..
				        0x0040:  41e3 4745 5420 2f57 4146 2d54 6573 7469  A.GET./WAF-Testi
				        0x0050:  6e67 2f4a 532f 6469 7370 6c61 7955 524c  ng/JS/displayURL
				        0x0060:  2e6a 7320 4854 5450 2f31 2e31 0d0a 7573  .js.HTTP/1.1..us
				        0x0070:  6572 2d61 6765 6e74 3a20 6375 726c 2f37  er-agent:.curl/7
				        0x0080:  2e32 362e 300d 0a68 6f73 743a 2070 6870  .26.0..host:.php
				        0x0090:  2d6d 696e 6461 7567 6173 622e 6339 2e69  -mindaugasb.c9.i
				        0x00a0:  6f3a 3830 0d0a 6163 6365 7074 3a20 2a2f  o:80..accept:.*/
				        0x00b0:  2a0d 0a78 2d66 6f72 7761 7264 6564 2d66  *..x-forwarded-f
				        0x00c0:  6f72 3a20 3834 2e34 362e 3234 372e 3230  or:.84.46.247.20
				        0x00d0:  320d 0a63 6f6e 6e65 6374 696f 6e3a 206b  2..connection:.k
				        0x00e0:  6565 702d 616c 6976 650d 0a0d 0a         eep-alive....


				15:13:23.613114 IP (tos 0x0, ttl 63, id 11283, offset 0, flags [DF], proto TCP (6), length 224)
				    10.240.246.67.49239 > 172.17.110.147.8080: Flags [P.], cksum 0xbfed (correct), seq 1197878214:1197878386, ack 478247388, win 28, options [nop,nop,TS val 130090964 ecr 534891918], length 172
				        0x0000:  d26a ece8 f83f 0209 0275 f437 0800 4500  .j...?...u.7..E.
				        0x0010:  00e0 2c13 4000 3f06 f32c 0af0 f643 ac11  ..,.@.?..,...C..
				        0x0020:  6e93 c057 1f90 4766 2bc6 1c81 79dc 8018  n..W..Gf+...y...
				        0x0030:  001c bfed 0000 0101 080a 07c1 07d4 1fe1  ................
				        0x0040:  cd8e 4745 5420 2f57 4146 2d54 6573 7469  ..GET./WAF-Testi
				        0x0050:  6e67 2f4a 532f 6469 7370 6c61 794e 616d  ng/JS/displayNam
				        0x0060:  652e 6a73 2048 5454 502f 312e 310d 0a75  e.js.HTTP/1.1..u
				        0x0070:  7365 722d 6167 656e 743a 2063 7572 6c2f  ser-agent:.curl/
				        0x0080:  372e 3236 2e30 0d0a 686f 7374 3a20 7068  7.26.0..host:.ph
				        0x0090:  702d 6d69 6e64 6175 6761 7362 2e63 392e  p-mindaugasb.c9.
				        0x00a0:  696f 3a38 300d 0a61 6363 6570 743a 202a  io:80..accept:.*
				        0x00b0:  2f2a 0d0a 782d 666f 7277 6172 6465 642d  /*..x-forwarded-
				        0x00c0:  666f 723a 2038 342e 3436 2e32 3437 2e32  for:.84.46.247.2
				        0x00d0:  3032 0d0a 436f 6e6e 6563 7469 6f6e 3a20  02..Connection:.
				        0x00e0:  6b65 6570 2d61 6c69 7665 0d0a 0d0a       keep-alive....

				to filter IPv6 ===> sudo tcpdump ip[] = 0800


				////////////// ARP PACKETS in ETHERNET frame

				23:13:27.593956 00:1e:31:e0:e0:e0 (oui Unknown) > 00:26:c7:be:cb:38 (oui Unknown), ethertype ARP (0x0806), length 60: Ethernet (len 6), IPv4 (len 4), Reply 192.168.1.1 is-at 00:1e:31:e0:e0:e0 (oui Unknown), length 46
				    0x0000:  0026 c7be cb38 001e 31e0 e0e0 0806 0001  .&...8..1.......
				    0x0010:  0800 0604 0002 001e 31e0 e0e0 c0a8 0101  ........1.......
				    0x0020:  0026 c7be cb38 c0a8 010a 0000 0000 0000  .&...8..........
				    0x0030:  0000 0000 0000 0000 0000 0000            ............


				23:14:04.838710 00:1e:31:e0:e0:e0 (oui Unknown) > Broadcast, ethertype ARP (0x0806), length 60: Ethernet (len 6), IPv4 (len 4), Request who-has 192.168.1.10 tell 192.168.1.1, length 46
				    0x0000:  ffff ffff ffff 001e 31e0 e0e0 0806 | 0001  ........1.......
				             Broadcast MAC  SRC MAC        ARP  | hardw type
				                                                | Ethernet 
				    0x0010:  0800 0604 0001 001e 31e0 e0e0 c0a8   0101  ........1.......
				             proto
				    0x0020:  0000 0000 0000 c0a8 010a 0000 0000   0000  ................
				    0x0030:  0000 0000 0000 0000 0000 0000              ............



				//////////////////////////////////////////////////////////////////////

				TCPdump

				proto[x:y]          : will start filtering from byte x for y bytes. ip[2:2] would filter bytes 3 and 4 (first byte begins by 0)
				proto[x:y] & z = 0  : will match bits set to 0 when applying mask z to proto[x:y]
				proto[x:y] & z !=0  : some bits are set when applying mask z to proto[x:y]
				proto[x:y] & z = z  : every bits are set to z when applying mask z to proto[x:y]
				proto[x:y] = z      : p[x:y] has exactly the bits set to z

				Network filtering :
				-------------------
				# tcpdump -i eth1 net 192.168
				-------------------
				Let's say we would like to know are IP options set ?
				--------------------

				We know a "normal" header is usually 20 bytes 
				(160 bits) long. With options set, the header is longer than that. The IP header has the header 
				length field which we will filter here to know if the header is longer than 20 bytes.

				    +-+-+-+-+-+-+-+-+
				    |Version|  IHL  |
				    +-+-+-+-+-+-+-+-+

				Usually the first byte has a value of 01000101 in binary - and this (above is the first byte).

				Anyhow, we need to divide the first byte in half...

				0100 = 4 in decimal. This is the IP version.
				0101 = 5 in decimal. This is the number of blocks of 32 bits in the headers. 5 x 32 bits = 160 bits or 20 bytes.





				///// Let's try and explain this:

				19:28:20.867400 IP 10.240.35.81.51556 > 172.17.13.201.8080: Flags [.], seq 10034757:10037573, ack 3270393558, win 28, options [nop,nop,TS val 1863926220 ecr 171514824], length 2816
				        0x0000:  1a17 8e8a a3a0 026d 627d 049c 0800 4500  .......mb}....E.
				        0x0010:  2Byt 2Byt 2Byt 2Byt 2Byt 2Byt 2Byt 2Byt  .4_.@.?.....#Q..
				        0x0020:  2Byt 2Byt 2Byt 2Byt 2Byt .... .... ....  ...d.....E..>...

				1a17    === 0001 1010 0001 0111 (in binary)     ===> 16 bits        ===> 2 bytes. 
				1a17 8e8a a3a0 026d 627d 049c 0800 4500         ===> 8 * 2 bytes    ===> 16 bytes
				0x0010  === 16 (!)

				0001    === 1   ===>
				1010    === 10  ===> 10 * 32 bits   ===> 320 bits   ===> 40 bytes
				0001    === 1   ===>
				0111    === 7   ===>


				UDP doesn't know about "hosts" - that's IP's responsibility. UDP only knows about ports. If you want to see all *UDP* traffic to and from particular hosts, use "(ip host node1 or node2 or node3) and udp".





				http://packetpushers.net/masterclass-tcpdump-interpreting-output/
				http://albanianwizard.org/how-to-read-tcpdump-output-tcpdump-advanced-use.albanianwizard

				09:27:24.130767 IP (tos 0x0, ttl 128, id 14956, offset 0, flags [none], proto ICMP (1), length 60) 
				    192.168.1.18 > 192.168.1.12: ICMP echo request, id 1, seq 159, length 40
				    0x0000:  0800 27b9 caba 0026 c7be cb38 0800 4500  ..'....&...8..E.
				    0x0010:  003c 3a6c                                <=== IP HEADER?


				                       0000 8001 7ce6 c0a8 0112 c0a8  .<:l....|.......
				    0x0020:  010c 0800 4cbc 0001 009f 6162 6364 6566  ....L.....abcdef
				    0x0030:  6768 696a 6b6c 6d6e 6f70 7172 7374 7576  ghijklmnopqrstuv
				    0x0040:  7761 6263 6465 6667 6869                 wabcdefghi 
				09:27:24.345888 ARP, Ethernet (len 6), IPv4 (len 4), Request who-has 192.168.1.1 tell 192.168.1.18, length 46
				    0x0000:  ffff ffff ffff 0026 c7be cb38 0806 0001  .......&...8....
				    0x0010:  0800 0604 0001 0026 c7be cb38 c0a8 0112  .......&...8....
				    0x0020:  0000 0000 0000 c0a8 0101 0000 0000 0000  ................
				    0x0030:  0000 0000 0000 0000 0000 0000            ............
				09:27:24.640620 IP (tos 0x0, ttl 1, id 15098, offset 0, flags [none], proto UDP (17), length 161)
				    192.168.1.18.54371 > 239.255.255.250.1900: [udp sum ok] UDP, length 133
				    0x0000:  0100 5e7f fffa 0026 c7be cb38 0800 4500  ..^....&...8..E.
				    0x0010:  00a1 3afa 0000 0111 cc9d c0a8 0112 efff  ..:.............
				    0x0020:  fffa d463 076c 008d cb65 4d2d 5345 4152  ...c.l...eM-SEAR
				    0x0030:  4348 202a 2048 5454 502f 312e 310d 0a48  CH.*.HTTP/1.1..H
				    0x0040:  6f73 743a 3233 392e 3235 352e 3235 352e  ost:239.255.255.
				    0x0050:  3235 303a 3139 3030 0d0a 5354 3a75 726e  250:1900..ST:urn
				    0x0060:  3a73 6368 656d 6173 2d75 706e 702d 6f72  :schemas-upnp-or
				    0x0070:  673a 6465 7669 6365 3a49 6e74 6572 6e65  g:device:Interne
				    0x0080:  7447 6174 6577 6179 4465 7669 6365 3a31  tGatewayDevice:1
				    0x0090:  0d0a 4d61 6e3a 2273 7364 703a 6469 7363  ..Man:"ssdp:disc
				    0x00a0:  6f76 6572 220d 0a4d 583a 330d 0a0d 0a    over"..MX:3....

				'tcp[((tcp[12:1] & 0xf0) >> 2):4] = 0x47455420'
				    1. Lets convert the 0x47455420 to ascii 
				        ===> GET 
				        ===> 'tcp[((tcp[12:1] & 0xf0) >> 2):4] = GET'
				    2. Examine the inner tcp filter: (tcp[12:1] & 0xf0) 
				        ===> the 0xf0 == 0000 0000 1111 0000;
				        ===> tcp[12:1] == 08 (start filtering from byte 13 (0 based indexing, so you could also say start with the byte that has index 12) for 1 byte, so only 13th byte);
				        ===> 08 == 0000 1000
				        ===> 0000 1000 & 0000 0000 1111 0000 (bitwise and = if both are 1 then end result is one)
				        ===> 
				19:10:30.091065 IP (tos 0x0, ttl 63, id 40127, offset 0, flags [DF], proto TCP (6), length 2786)
				    10.240.35.81.47856 > 172.17.13.201.8080: Flags [P.], cksum 0xf2ef (incorrect -> 0xb8f8), seq 2263020471:2263023205, ack 4187927811, win 28, options [nop,nop,TS val 1906863883 ecr 214445688], length 2734
				    0x0000:  1a17 8e8a a3a0 026d 627d 049c 0800 4500  .......mb}....E.
				             0,1  2,3  ...  ...  ...  ...  12,13 ...                    <=== byte indexes
				             1,2  3,4  ...  ...  ...  ...  13,14 ...                    <=== counting how many bytes
				    0x0010:  0ae2 9cbf 4000 3f06 ac3b 0af0 2351 ac11  ....@.?..;..#Q..  <=== 0x0010 number correctly identifies that the first two diggits are the 16th byte
				             16,17 ... ...
				    0x0020:  0d c9 ba f0 1f 90 86 e2 f3 b7 f9 9e b5 03 80 18  ................
				    0x0030:  001c f2ef 0000 0101 080a 71a8 6f0b 0cc8  ..........q.o...
				    0x0040:  2e78 4745 5420 2f69 636f 6e73 2f75 6e6b  .xGET./icons/unk
				    0x0050:  6e6f 776e 2e67 6966 2048 5454 502f 312e  nown.gif.HTTP/1.
				    0x0060:  310d 0a68 6f73 743a 2070 6870 2d6d 696e  1..host:.php-min
				    0x0070:  6461 7567 6173 622e 6339 2e69 6f3a 3830  daugasb.c9.io:80
				    0x0080:  0d0a 6163 6365 7074 3a20 696d 6167 652f  ..accept:.image/
				    0x0090:  7765 6270 2c2a 2f2a 3b71 3d30 2e38 0d0a  webp,*/*;q=0.8..
				    0x00a0:  7573 6572 2d61 6765 6e74 3a20 4d6f 7a69  user-agent:.Mozi
				    0x00b0:  6c6c 612f 352e 3020 2857 696e 646f 7773  lla/5.0.(Windows
				    0x00c0:  204e 5420 362e 313b 2057 4f57 3634 2920  .NT.6.1;.WOW64).
				    0x00d0:  4170 706c 6557 6562 4b69 742f 3533 372e  AppleWebKit/537.
				    0x00e0:  3336 2028 4b48 544d 4c2c 206c 696b 6520  36.(KHTML,.like.
				    0x00f0:  4765 636b 6f29 2043 6872 6f6d 652f 3430  Gecko).Chrome/40
				    0x0100:  2e30 2e32 3231 342e 3933 2053 6166 6172  .0.2214.93.Safar
				    0x0110:  692f 3533 372e 3336 0d0a 7265 6665 7265  i/537.36..refere
				    0x0120:  723a 2068 7474 703a 2f2f 7068 702d 6d69  r:.http://php-mi
				    0x0130:  6e64 6175 6761 7362 2e63 392e 696f 2f0d  ndaugasb.c9.io/.
				    0x0140:  0a61 6363 6570 742d 6c61 6e67 7561 6765  .accept-language
				    0x0150:  3a20 656e 2d55 532c 656e 3b71 3d30 2e38  :.en-US,en;q=0.8
				    0x0160:  2c72 753b 713d 302e 362c 6c74 3b71 3d30  ,ru;q=0.6,lt;q=0
				    0x0170:  2e34 2c65 733b 713d 302e 320d 0a63 6f6f  .4,es;q=0.2..coo
				    0x0180:  6b69 653a 2061 6a73 5f61 6e6f 6e79 6d6f  kie:.ajs_anonymo
				    0x0190:  7573 5f69 643d 2532 3266 3134 3237 3036  us_id=%22f142706
				    0x01a0:  382d 6339 3266 2d34 3138 632d 6266 3666  8-c92f-418c-bf6f
				    0x01b0:  2d36 3561 6663 3037 6233 3964 6525 3232  -65afc07b39de%22
				    0x01c0:  3b20 4d69 6e64 6175 6761 735f 7365 7373  ;.Mindaugas_sess
				    0x01d0:  696f 6e5f 7465 7374 3d35 6639 346e 7565  ion_test=5f94nue
				    0x01e0:  736e 3537 3370 6d66 7468 6638 6933 6861  sn573pmfthf8i3ha
				    0x01f0:  3463 3133 6971 3167 6631 6962 3263 7134  4c13iq1gf1ib2cq4
				    0x0200:  3538 6632 6667 7267 3037 3634 7268 6639  58f2fgrg0764rhf9
				    0x0210:  346d 7072 3736 7630 6735 6174 6130 7669  4mpr76v0g5ata0vi
				    0x0220:  3175 6934 6536 3763 7430 6d71 6334 6973  1ui4e67ct0mqc4is
				    0x0230:  7468 3134 3772 6a6e 6836 3765 6c6b 7033  th147rjnh67elkp3
				    0x0240:  3b20 5f5f 7a5f 613d 3332 3039 3730 3339  ;.__z_a=32097039
				    0x0250:  3436 3b20 5f5f 7a6a 6332 3839 353d 3434  46;.__zjc2895=44
				    0x0260:  3639 3534 3930 3630 2e32 3339 353b 205f  69549060.2395;._
				    0x0270:  5f7a 6a63 3534 3133 3d34 3436 3936 3533  _zjc5413=4469653
				    0x0280:  3733 352e 3031 3935 3b20 5f5f 7a6a 6334  735.0195;.__zjc4
				    0x0290:  3730 353d 3434 3639 3635 3338 3133 2e35  705=4469653813.5
				    0x02a0:  3537 303b 205f 5f7a 6a63 3535 3738 3d34  570;.__zjc5578=4
				    0x02b0:  3437 3038 3731 3131 332e 3339 3230 3b20  470871113.3920;.
				    0x02c0:  5f5f 7a6a 6338 3031 393d 3434 3730 3837  __zjc8019=447087
				    0x02d0:  3132 3130 2e37 3738 353b 205f 6369 6f69  1210.7785;._cioi
				    0x02e0:  643d 3534 3438 3734 3b20 5f63 696f 3d62  d=544874;._cio=b
				    0x02f0:  3166 3836 6563 372d 3334 3738 2d37 6130  1f86ec7-3478-7a0
				    0x0300:  612d 3361 6262 2d37 6665 6464 3566 6538  a-3abb-7fedd5fe8
				    0x0310:  6135 353b 206f 7074 696d 697a 656c 7942  a55;.optimizelyB
				    0x0320:  7563 6b65 7473 3d25 3742 2537 443b 2061  uckets=%7B%7D;.a
				    0x0330:  6a73 5f75 7365 725f 6964 3d25 3232 3534  js_user_id=%2254
				    0x0340:  3438 3734 2532 323b 2061 6a73 5f67 726f  4874%22;.ajs_gro
				    0x0350:  7570 5f69 643d 6e75 6c6c 3b20 5f67 613d  up_id=null;._ga=
				    0x0360:  4741 312e 322e 3134 3434 3235 3632 3639  GA1.2.1444256269
				    0x0370:  2e31 3431 3835 3835 3036 353b 206d 705f  .1418585065;.mp_
				    0x0380:  6233 6339 6338 6136 3933 3830 6663 3432  b3c9c8a69380fc42
				    0x0390:  6334 6338 6263 6633 3735 3566 3438 3738  c4c8bcf3755f4878
				    0x03a0:  5f6d 6978 7061 6e65 6c3d 2537 4225 3232  _mixpanel=%7B%22
				    0x03b0:  6469 7374 696e 6374 5f69 6425 3232 2533  distinct_id%22%3
				    0x03c0:  4125 3230 2532 3231 3439 3836 6531 3934  A%20%2214986e194
				    0x03d0:  3835 3165 652d 3032 3731 3434 6135 362d  851ee-027144a56-
				    0x03e0:  3436 3466 3033 3231 2d31 3030 3230 302d  464f0321-100200-
				    0x03f0:  3134 3938 3665 3139 3438 3631 3839 2532  14986e19486189%2
				    0x0400:  3225 3243 2532 3225 3234 7365 6172 6368  2%2C%22%24search
				    0x0410:  5f65 6e67 696e 6525 3232 2533 4125 3230  _engine%22%3A%20
				    0x0420:  2532 3267 6f6f 676c 6525 3232 2532 4325  %22google%22%2C%
				    0x0430:  3232 2532 3469 6e69 7469 616c 5f72 6566  22%24initial_ref
				    0x0440:  6572 7265 7225 3232 2533 4125 3230 2532  errer%22%3A%20%2
				    0x0450:  3268 7474 7073 2533 4125 3246 2532 4677  2https%3A%2F%2Fw
				    0x0460:  7777 2e67 6f6f 676c 652e 6c74 2532 4625  ww.google.lt%2F%
				    0x0470:  3232 2532 4325 3232 2532 3469 6e69 7469  22%2C%22%24initi
				    0x0480:  616c 5f72 6566 6572 7269 6e67 5f64 6f6d  al_referring_dom
				    0x0490:  6169 6e25 3232 2533 4125 3230 2532 3277  ain%22%3A%20%22w
				    0x04a0:  7777 2e67 6f6f 676c 652e 6c74 2532 3225  ww.google.lt%22%
				    0x04b0:  3243 2532 3275 6964 2532 3225 3341 2532  2C%22uid%22%3A%2
				    0x04c0:  3025 3232 3534 3438 3734 2532 3225 3243  0%22544874%22%2C
				    0x04d0:  2532 3265 7665 6e74 2532 3225 3341 2532  %22event%22%3A%2
				    0x04e0:  3025 3232 4964 656e 7469 6679 2532 3225  0%22Identify%22%
				    0x04f0:  3243 2532 325f 5f6d 7073 2532 3225 3341  2C%22__mps%22%3A
				    0x0500:  2532 3025 3742 2537 4425 3243 2532 325f  %20%7B%7D%2C%22_
				    0x0510:  5f6d 7073 6f25 3232 2533 4125 3230 2537  _mpso%22%3A%20%7
				    0x0520:  4225 3744 2532 4325 3232 5f5f 6d70 6125  B%7D%2C%22__mpa%
				    0x0530:  3232 2533 4125 3230 2537 4225 3744 2532  22%3A%20%7B%7D%2
				    0x0540:  4325 3232 5f5f 6d70 6170 2532 3225 3341  C%22__mpap%22%3A
				    0x0550:  2532 3025 3542 2535 4425 3243 2532 3274  %20%5B%5D%2C%22t
				    0x0560:  645f 636c 6965 6e74 5f69 6425 3232 2533  d_client_id%22%3
				    0x0570:  4125 3230 2532 3232 3462 6362 3333 662d  A%20%2224bcb33f-
				    0x0580:  3461 3132 2d34 3961 312d 3861 6631 2d37  4a12-49a1-8af1-7
				    0x0590:  3362 6638 3938 3130 3238 3025 3232 2532  3bf89810280%22%2
				    0x05a0:  4325 3232 7464 5f63 6861 7273 6574 2532  C%22td_charset%2
				    0x05b0:  3225 3341 2532 3025 3232 7574 662d 3825  2%3A%20%22utf-8%
				    0x05c0:  3232 2532 4325 3232 7464 5f6c 616e 6775  22%2C%22td_langu
				    0x05d0:  6167 6525 3232 2533 4125 3230 2532 326c  age%22%3A%20%22l
				    0x05e0:  7425 3232 2532 4325 3232 7464 5f63 6f6c  t%22%2C%22td_col
				    0x05f0:  6f72 2532 3225 3341 2532 3025 3232 3234  or%22%3A%20%2224
				    0x0600:  2d62 6974 2532 3225 3243 2532 3274 645f  -bit%22%2C%22td_
				    0x0610:  7363 7265 656e 2532 3225 3341 2532 3025  screen%22%3A%20%
				    0x0620:  3232 3133 3636 7837 3638 2532 3225 3243  221366x768%22%2C
				    0x0630:  2532 3274 645f 7669 6577 706f 7274 2532  %22td_viewport%2
				    0x0640:  3225 3341 2532 3025 3232 3133 3636 7836  2%3A%20%221366x6
				    0x0650:  3331 2532 3225 3243 2532 3274 645f 7469  31%22%2C%22td_ti
				    0x0660:  746c 6525 3232 2533 4125 3230 2532 3243  tle%22%3A%20%22C
				    0x0670:  6c6f 7564 3925 3230 2537 4325 3230 4c6f  loud9%20%7C%20Lo
				    0x0680:  6769 6e25 3232 2532 4325 3232 7464 5f75  gin%22%2C%22td_u
				    0x0690:  726c 2532 3225 3341 2532 3025 3232 6874  rl%22%3A%20%22ht
				    0x06a0:  7470 7325 3341 2532 4625 3246 6339 2e69  tps%3A%2F%2Fc9.i
				    0x06b0:  6f25 3246 7765 6225 3246 6c6f 6769 6e25  o%2Fweb%2Flogin%
				    0x06c0:  3232 2532 4325 3232 7464 5f68 6f73 7425  22%2C%22td_host%
				    0x06d0:  3232 2533 4125 3230 2532 3263 392e 696f  22%3A%20%22c9.io
				    0x06e0:  2532 3225 3243 2532 3274 645f 7061 7468  %22%2C%22td_path
				    0x06f0:  2532 3225 3341 2532 3025 3232 2532 4677  %22%3A%20%22%2Fw
				    0x0700:  6562 2532 466c 6f67 696e 2532 3225 3243  eb%2Flogin%22%2C
				    0x0710:  2532 3274 645f 7265 6665 7272 6572 2532  %22td_referrer%2
				    0x0720:  3225 3341 2532 3025 3232 6874 7470 7325  2%3A%20%22https%
				    0x0730:  3341 2532 4625 3246 6339 2e69 6f25 3246  3A%2F%2Fc9.io%2F
				    0x0740:  2532 3225 3243 2532 3274 645f 6970 2532  %22%2C%22td_ip%2
				    0x0750:  3225 3341 2532 3025 3232 7464 5f69 7025  2%3A%20%22td_ip%
				    0x0760:  3232 2532 4325 3232 7464 5f62 726f 7773  22%2C%22td_brows
				    0x0770:  6572 2532 3225 3341 2532 3025 3232 7464  er%22%3A%20%22td
				    0x0780:  5f62 726f 7773 6572 2532 3225 3243 2532  _browser%22%2C%2
				    0x0790:  3274 645f 6272 6f77 7365 725f 7665 7273  2td_browser_vers
				    0x07a0:  696f 6e25 3232 2533 4125 3230 2532 3274  ion%22%3A%20%22t
				    0x07b0:  645f 6272 6f77 7365 725f 7665 7273 696f  d_browser_versio
				    0x07c0:  6e25 3232 2532 4325 3232 7464 5f6f 7325  n%22%2C%22td_os%
				    0x07d0:  3232 2533 4125 3230 2532 3274 645f 6f73  22%3A%20%22td_os
				    0x07e0:  2532 3225 3243 2532 3274 645f 6f73 5f76  %22%2C%22td_os_v
				    0x07f0:  6572 7369 6f6e 2532 3225 3341 2532 3025  ersion%22%3A%20%
				    0x0800:  3232 7464 5f6f 735f 7665 7273 696f 6e25  22td_os_version%
				    0x0810:  3232 2532 4325 3232 5f5f 616c 6961 7325  22%2C%22__alias%
				    0x0820:  3232 2533 4125 3230 2532 3235 3434 3837  22%3A%20%2254487
				    0x0830:  3425 3232 2532 4325 3232 6d70 5f6e 616d  4%22%2C%22mp_nam
				    0x0840:  655f 7461 6725 3232 2533 4125 3230 2532  e_tag%22%3A%20%2
				    0x0850:  3264 6172 6261 732e 6d69 6e64 6175 6761  2darbas.mindauga
				    0x0860:  7325 3430 676d 6169 6c2e 636f 6d25 3232  s%40gmail.com%22
				    0x0870:  2532 4325 3232 6372 6561 7465 6441 7425  %2C%22createdAt%
				    0x0880:  3232 2533 4125 3230 6e75 6c6c 2532 4325  22%3A%20null%2C%
				    0x0890:  3232 6163 7469 7665 2532 3225 3341 2532  22active%22%3A%2
				    0x08a0:  3066 616c 7365 2532 4325 3232 616c 7068  0false%2C%22alph
				    0x08b0:  6125 3232 2533 4125 3230 6661 6c73 6525  a%22%3A%20false%
				    0x08c0:  3243 2532 3262 6574 6125 3232 2533 4125  2C%22beta%22%3A%
				    0x08d0:  3230 6661 6c73 6525 3243 2532 326e 6f5f  20false%2C%22no_
				    0x08e0:  6e65 7773 6c65 7474 6572 2532 3225 3341  newsletter%22%3A
				    0x08f0:  2532 3066 616c 7365 2532 4325 3232 7375  %20false%2C%22su
				    0x0900:  6273 6372 6970 7469 6f6e 5f6f 6e5f 7369  bscription_on_si
				    0x0910:  676e 7570 2532 3225 3341 2532 3025 3232  gnup%22%3A%20%22
				    0x0920:  2532 3225 3243 2532 3270 7269 6369 6e67  %22%2C%22pricing
				    0x0930:  506c 616e 2532 3225 3341 2532 3025 3232  Plan%22%3A%20%22
				    0x0940:  4672 6565 2532 3225 3243 2532 3269 6425  Free%22%2C%22id%
				    0x0950:  3232 2533 4125 3230 2532 3235 3434 3837  22%3A%20%2254487
				    0x0960:  3425 3232 2532 4325 3232 2532 3465 6d61  4%22%2C%22%24ema
				    0x0970:  696c 2532 3225 3341 2532 3025 3232 6461  il%22%3A%20%22da
				    0x0980:  7262 6173 2e6d 696e 6461 7567 6173 2534  rbas.mindaugas%4
				    0x0990:  3067 6d61 696c 2e63 6f6d 2532 3225 3243  0gmail.com%22%2C
				    0x09a0:  2532 3225 3234 7573 6572 6e61 6d65 2532  %22%24username%2
				    0x09b0:  3225 3341 2532 3025 3232 6d69 6e64 6175  2%3A%20%22mindau
				    0x09c0:  6761 7362 2532 3225 3243 2532 3263 3976  gasb%22%2C%22c9v
				    0x09d0:  6572 7369 6f6e 2532 3225 3341 2532 3025  ersion%22%3A%20%
				    0x09e0:  3232 7633 2532 3225 3243 2532 3272 6567  22v3%22%2C%22reg
				    0x09f0:  696f 6e25 3232 2533 4125 3230 2532 3265  ion%22%3A%20%22e
				    0x0a00:  7525 3232 2532 4325 3232 2532 3463 7265  u%22%2C%22%24cre
				    0x0a10:  6174 6564 2532 3225 3341 2532 3025 3232  ated%22%3A%20%22
				    0x0a20:  3230 3134 2d31 312d 3139 5431 3925 3341  2014-11-19T19%3A
				    0x0a30:  3030 2533 4133 322e 3638 315a 2532 3225  00%3A32.681Z%22%
				    0x0a40:  3243 2532 3225 3234 6669 7273 745f 6e61  2C%22%24first_na
				    0x0a50:  6d65 2532 3225 3341 2532 3025 3232 6d69  me%22%3A%20%22mi
				    0x0a60:  6e64 6175 6761 7362 2532 3225 3243 2532  ndaugasb%22%2C%2
				    0x0a70:  3225 3234 6e61 6d65 2532 3225 3341 2532  2%24name%22%3A%2
				    0x0a80:  3025 3232 6d69 6e64 6175 6761 7362 2532  0%22mindaugasb%2
				    0x0a90:  3225 3243 2532 3225 3234 6c61 7374 5f6e  2%2C%22%24last_n
				    0x0aa0:  616d 6525 3232 2533 4125 3230 2532 3225  ame%22%3A%20%22%
				    0x0ab0:  3232 2537 440d 0a78 2d66 6f72 7761 7264  22%7D..x-forward
				    0x0ac0:  6564 2d66 6f72 3a20 3834 2e34 362e 3234  ed-for:.84.46.24
				    0x0ad0:  302e 3532 0d0a 436f 6e6e 6563 7469 6f6e  0.52..Connection
				    0x0ae0:  3a20 6b65 6570 2d61 6c69 7665 0d0a 0d0a  :.keep-alive....
				............... 

				09:27:24.130767     ===> timestamp
				IP/ARP              ===> protocol suite (everything involving the IP protocol will have the IP mark (like ICMP and UDP))
				tos 0x0             ===> 
				ttl 128             ===> ttl in hops
				id 14956            ===>
				offset 0            ===> 
				flags [none], [DF]  ===> 
				proto ICMP (1)      ===>
				length 60           ===>


				------------------
				echo -n "GE" | hexdump -C

			}

			BITTWIST {
				- bittwiste -I first.pcap -O first_edited.pcap -T ip -s 172.31.2.102 			===> -T ip -s <IP> - type=ip, srouce=<IP>, meaning change the source ip
				- bittwiste -I es.pcap -O fake-es.pcap -T ip -s 193.219.39.1 -d 207.244.92.137 	===>
				- bittwist -i eth1 fake-es.pcap 
			}
			
			NETSTAT {
			    - (sudo) netstat -ant 	===> -a {all interfaces}, -n {numeric addresses, no names}, -t {tcp};

			      Proto Recv-Q Send-Q Local Address           Foreign Address         State
				tcp        0      0 0.0.0.0:22              0.0.0.0:*             LISTEN
				tcp        0      0 0.0.0.0:25              0.0.0.0:*             LISTEN

			    - (sudo) netstat -tulpn 	===> -t {tcp}, -u {udp}, -l {}, -p{}, -n {numeric addresses, no names};

				Proto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program name
				tcp        0      0 0.0.0.0:22              0.0.0.0:*               LISTEN      -
				tcp        0      0 0.0.0.0:8443            0.0.0.0:*               LISTEN      21318/nginx: worker

			      When sudo is used, way more information is displayed:
				Active Internet connections (only servers)
				Proto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program name
				tcp        0      0 0.0.0.0:22              0.0.0.0:*               LISTEN      4006/sshd
				tcp        0      0 0.0.0.0:8443            0.0.0.0:*               LISTEN      9589/nginx.conf
		  	}
			
			  - arp -a 				===> display (all) hosts in alternative (BSD) style
			  - ping -f -l 1472 www.dslreports.com  ===> find the MTU by experiment (windows), mine is 1272+28 bytes in VAIO win7 (+28 for the ping header);
			  - ping -s 1472 www.dslreports.com     ===> MTU (maximum transmission unit) for LINUX is ... ?
			  - ngrep -q -d eth1 -W byline host stackoverflow.com and port 80 ===> host = filter, 
				      -W=dump format (normal, byline, single, none),  
				      -d=use specified device instead of the pcap default, 
				      -q=quiet (don't print packet reception hash marks)
			
		}

		- echo "/a/b/c " | cut -d / -f 1-3 							===> prints "/a/b"
		- cut -d: -f1 /etc/passwd {
			- list all users in linux';
			- cut is used for text processing - like printing some range of characters ---> cut -c2-5 text.txt;
			- d - for "delimiter" in this case ":"
			- f - for "field that I want to retrieve" - first one in this case, meaning it will print the first field that is de limited by ":"
		}
		- su - ciuser -c <command> 									===> run command as another user;
		- curl ip.kis.lt 											===> to find out your external ip addr from linux console;
		- du -ch | grep total 										===> one line that displays the total size of current directory including all the subdirectories;
		- sudo du -Sh 2>/dev/null | sort -rh | head -n 15 			===> find 15 biggest directories or files on your linux machine (the stderr redirect is for proc direcotries that come and go out of existence to not showup in the output);
		- sudo find . -type f -exec du -Sh {} + 2>/dev/null | sort -rh | head -n 15 																	===> find 15 largest files on your linux machine;
		- for i in `sudo find / -type d 2>/dev/null`; do COUNT=$(sudo ls -a $i 2>/dev/null | wc -l) && printf "$COUNT\t$i\n" ; done | sort -k1,1 -n 	===> print the count of files in each directory (with the . and .. );
		- FILES=$(for i in `sudo find / -type d  2>/dev/null`; do COUNT=$(sudo ls -a $i 2>/dev/null | wc -l) && printf "$COUNT\t$i\n" ; done | sort -k1,1 -n) && TOTAL=$(echo "$FILES" | awk '{print $1}' | paste -sd+ | bc) && printf "$FILES\n\n$TOTAL\n"

		- cat <textfile> | sed G 									===> prints the file inserting an empty ling after each line
		- echo "abv" | sed -r -e 's/(v)/\1\1/g'						===> -r regex extended, -n do not default to printing each matched line only chars matched (like grep -o);
		- esc + 0 													===> simulates the F10 in mac when it is not available;
		- (($a++)) 													===> arithmetic evaluation and C-style evaluation. This is also used for a recursive call :: NaiveFibonacciNthTermGenerator $(($1 - 2))
		- (($1)) || echo "2nd" 										===> passing anything to the script as the $1 argument other than 0 will cause <echo "2nd"> to never get executed;
		- (($a)) && echo "2nd" 										===> "2nd" will be printed only if (($a)) returns 0;
		- $? 														===> shell parameter,  not a variable;
		- -eq / -ne / -le 											===> equals / not-equals / less-than;
		- pkill -f <pattern> 										===> kill the precess by string pattern;
		- curl -G -v "http://php2-mindaugasb.c9.io/WAF-Testing/" --data-urlencode "?a=<?php >" ===> -G for "GET", if not specified, then POST will be used. You must use -G, because othervise GET request with data in the BODY will be sent (good case to remember)!
		- curl -G http://178.62.131.40:80/ -b "cookie=a" 			===> send a cookie with CURL;
	    - cd "$(dirname "$(sudo find / -type f -name "unicorn.log" | head -1)")"
	    - ls -alhtR | grep "\(rails-tutorial-mindaugasb.c9.io\|php2-mindaugasb.c9.io\)" 

		- install a program in LINUX {
			- The best way is to donwloand and install it with USC (Ubuntu Software Center), but if you can't here is what you do (since there is no "install.exe" in Linux as in windows that does the job for you).
			- 1. Download a package using "axel" or some other command line download manager;
			- 2. Place it into the /opt/ folder or /usr/local/ ffolder - (remember "/" is the root folder, "opt" is for optional - the programms that are not necessary for the system to run). You can use either but be consistent;
			- 3. Extract it there using "tar xvf" (remember to use "sudo");
			- Another option is sudo apt-get install <package>;
		}

		- install bittwist rom sourceforge {
			- wget 'http://downloads.sourceforge.net/project/bittwist/Linux/Bit-Twist%202.0/bittwist-linux-2.0.tar.gz?r=http%3A%2F%2Fbittwist.sourceforge.net%2Findex.html&ts=1434609074&use_mirror=kent' -O bttw-linux.2.0.tar.gz 	===> you ahve to get the 'direct link' and place into quoutes;
			- tar xvfz bttw-linux.2.0.tar.gz
			- make 																												===> src/def.h:44:18: fatal error: pcap.h: No such file or directory;
			- wget 'http://www.tcpdump.org/release/libpcap-1.7.3.tar.gz' && tar xfv libpcap-1.7.3.tar.gz & cd libpcap-1.7.3 	===> download the libcap library;
			- ./configure 																										===> checking for capable lex... insufficient ERROR, need to download flex;
			- sudo apt-get install flex bison 
			- ./configure && make && sudo make install
			- sudo apt-get install libpcap0.8-dev 																				===> possible alternative
			- cd bittw && make CFLAGS='-O2 -Wall -g' 																			===> -O2=performance optimization; -Wall=all warnings; -g=include debug signs into the binary
			- sudo make install
		}

		- executable bash script from a text file {
			1. Using vim enter a command to enable syntax highlighting: :syntax enable -- You can add this setting to your .vimrc file to make it permanent.
			2. Write it;
			3. :w <filename>.sh :: Save it with as <name>.sh to prevent confusion;
			4. chmod +x filename.sh :: Give executable permisions to it as initialy it will be: -rw-rw-r-- it will change to this: <?>
			5. Execute (depends on your bash version): ./<script_name> <arg1> <arg2> 
			6. Debug: bash -x <script_name> <arg1> <arg2>
		}

		- transfering file from Linux to MAC with SCP {
			1. tar -cvf name.tar /path/to/directory 																	===> create an archive of a directory (if it's a file, then no problem should be dowloading it directly) and place it inside the current working directory;
			2. scp user@remote.server.fi:/path/location/file_name file_name 											===> download from remote to local {
				- sudo scp -i ~/.ssh/priv.key -rp zulu@104.131.103.33:/usr/local/openresty/nginx/conf/ /usr/local/openresty/nginx/conf/ 	===> from 104.131.103.33 to some local (SRC ---> DST)
			}
			- scp file_to_copy user@remote.server.fi:/path/to/location 													===> upload from local to remote {
				sudo scp -i /Users/Mindaugas/.ssh/private_keys/ssh-private-key /Users/Mindaugas/Google\ Drive/Darbas/zulu/MISS-requests-generator.sh zulu@178.62.131.40:/usr/local/openresty/nginx/
				sudo scp -i /home/zulu/.ssh/authorized_keys /usr/local/openresty/nginx/conf/ zulu@178.62.131.40:/usr/local/openresty/nginx/conf/
				sudo scp -i ~/.ssh/private_keys/ssh-private-key -r rc-node-1/nginx/conf/websites/ zulu@178.62.131.40:/usr/local/openresty/nginx/conf/ ===> upload configs to rc-node-1
			}
		}

		ARCHLINUX INSTALL {

			- if using a keyborad with non-US keymap you need to specify the keymap:
				- ls /usr/share/kbd/keymaps 			===> directory for machine type ;
				- directory for keyboard type :: /usr/share/kbd/keymaps/i368/qwerty/ ;
				- loadkeys uk (for uk keys);

			- Label type: GUID Partition Table (GPT) is a standard for the layout of the partition table on a physical hard disk, using globally unique identifiers (GUID).
			- it is recomended to use GPT with SSD rather than MBR - choose apropriatelly
			- GPT ==> cgdisk (GPT is only necessary when there are many partitions) : allows many partitions and is a newer standard replacing the MBR
			- MBR ==> cfdisk ;
			- the first sector alignment should be 2048;
			- cfdisk /dev/sda

			- create:
				- root (remaining space) 	===> Root partition is the partition containing root directory an on which all paritions are mounted at boot time.
				- boot (200 MB max) 
				- swap (if RAM 512 			===> 1024 MB; if RAM 1024 ==> 1024; if RAM 2048 ==> might not be needed) partitions (can be on the same disk).

			- format the written partitions to specific file systems:
				- mkfs + tab 				===> list available file systems;
				- mkswap /dev/sda2 			===> format the swap partition;
				- swapon /dev/sda2 			===> turn on the swaping for the swap partition;
				- swapon -s 				===> get the swap paritions;
				- mkfs.ext2 /dev/sda1
				- mkfs.ext4 /dev/sda1
				- mkfs.jfs 	/dev/sda1

			- check if partition is aligned: # blockdev --getalignoff /dev/<partition> ==> 0 if alligned (most partitioning tools align them by default)
		} Synonyms: arch, arch linux, archlinux;
		KALI LINUX INSTALL {
			VirtualBox Guest Additions{
				- sudo apt-get update && sudo apt-get install -y linux-headers-$(uname -r);
				- cp /media/cd-rom/VBoxLinuxAdditions.run /root/
				- chmod 755 /root/VBoxLinuxAdditions.run
				- cd /root
				- ./VBoxLinuxAdditions.run
			}
		}
	}
}

REGEX {
	- abcdefghijklmnopqrstuvwxyz 	===> all lowercase letters;
	- ABCDEFGHIJKLMNOPQRSTUVWXYZ 	===> all uppercase letters;
	- (?i:[a-d|f-t|v-z]) 			===> match character ranges (skip matching some letters by removing them from the sets matched);

	PERFORMANCE {
		- (?:) 						===> use non-capturing groups;
		- SECRULE - most specific	===> prefiltering based on cardinallity of sets. Can be extended to every chaned filters based on regex (or SQL or JAVA or whatever);
			chain
				SECRULE - most specific from the rest of the possibilities.
		- 
	}
}


NGINX {
	Module development {
		- There are four contexts (called main, server, upstream, and location) which can contain directives with one or more arguments. 
		- Directives in the main context apply to everything; directives in the server context apply to a particular host/port; directives in the upstream context refer to a set of backend servers; and directives in a location context apply only to matching web locations (e.g., "/", "/images", etc.) 
		- A location context inherits from the surrounding server context, and a server context inherits from the main context. 
		- The upstream context neither inherits nor imparts its properties; it has its own special directives that don't really apply elsewhere.
		- Nginx modules have three roles we'll cover:
			- handlers process a request and produce output. whenever Nginx serves a file or proxies a request to another server, there's a handler module doing the work
			- filters manipulate the output produced by a handler. when Nginx gzips the output or executes a server-side include, it's using filter modules.
			- load-balancers choose a backend server to send a request to, when more than one backend server is eligible
		- Apache's modules are dynamically linked, nginx's are not.
		- "Core" of Nginx simply takes care of all the network and application protocols and sets up the sequence of modules that are eligible to process a request.
		- Nginx ships with two load-balancing modules: round-robin, and "IP hash" method;
		- Handler attaches to a location;

			Client sends HTTP request 
				Nginx chooses the appropriate handler based on the location config
					(if applicable) load-balancer picks a backend server
					Handler does its thing and passes each output buffer to the first filter
						First filter passes the output to the second filter
							Second to third
								Third to fourth
									...
										Final response sent to client

				Handler { can return (success, failure, or pass to default handler)}
				Filter {CHAIN OF RESPONSIBILITY, operate on buffers, operate synchronously on the buffer (buffers are ussually the size of a page (4K))}

		- typedef uintptr_t ngx_uint_t; 					===> types declared with typedef end with '_t' by C convention. So here a typedef just renames one type to another;
		- ngx_http_<module name>_(main|srv|loc)_conf_t 		===> A module can defined up to 3 configuration structs. The elements in the configuration structs are populated by module directives.

		// the definition of struct holding modules directives
		struct ngx_command_t {
		    ngx_str_t             	name; 	//
		    ngx_uint_t            	type; 	//
		    char               		*(*set)(ngx_conf_t *cf, ngx_command_t *cmd, void *conf); //
		    ngx_uint_t           	conf; 	// 
		    ngx_uint_t            	offset; //
		    void                 	*post; 	//
		};

		// the declaration of the struct for a particular morule
		static ngx_command_t ngx_http_circle_gif_commands[] = {
		    { ngx_string("circle_gif"),
		      NGX_HTTP_LOC_CONF|NGX_CONF_NOARGS,
		      ngx_http_circle_gif,
		      NGX_HTTP_LOC_CONF_OFFSET,
		      0,
		      NULL },

		    { ngx_string("circle_gif_min_radius"),
		      NGX_HTTP_MAIN_CONF|NGX_HTTP_SRV_CONF|NGX_HTTP_LOC_CONF|NGX_CONF_TAKE1,
		      ngx_conf_set_num_slot,
		      NGX_HTTP_LOC_CONF_OFFSET,
		      offsetof(ngx_http_circle_gif_loc_conf_t, min_radius),
		      NULL },
		      ...
		      ngx_null_command
		};

		// another example - Lourivals fix for All Headers
		static ngx_command_t ngx_http_modsecurity_commands[] =  {
		  { ngx_string("ModSecurityConfig"),
		    NGX_HTTP_MAIN_CONF|NGX_HTTP_SRV_CONF|NGX_HTTP_LOC_CONF|NGX_CONF_TAKE1,
		    ngx_http_modsecurity_config,
		    NGX_HTTP_LOC_CONF_OFFSET,
		    0,
		    NULL },

		  { ngx_string("ModSecurityEnabled"),
		    NGX_HTTP_MAIN_CONF|NGX_HTTP_SRV_CONF|NGX_HTTP_SIF_CONF|NGX_HTTP_LOC_CONF|NGX_HTTP_LIF_CONF|NGX_CONF_TAKE1,
		    ngx_http_modsecurity_enable,
		    NGX_HTTP_LOC_CONF_OFFSET,
		    offsetof(ngx_http_modsecurity_loc_conf_t, enable),
		    NULL },

		  { ngx_string("ModSecurityXHeaders"),
		    NGX_HTTP_MAIN_CONF|NGX_HTTP_SRV_CONF|NGX_HTTP_SIF_CONF|NGX_HTTP_LOC_CONF|NGX_HTTP_LIF_CONF|NGX_CONF_TAKE1,
		    ngx_conf_set_flag_slot,
		    NGX_HTTP_LOC_CONF_OFFSET,
		    offsetof(ngx_http_modsecurity_loc_conf_t, x_headers),
		    NULL },

		  { ngx_string("ModSecurityAllHeaders"),
		    NGX_HTTP_MAIN_CONF|NGX_HTTP_SRV_CONF|NGX_HTTP_SIF_CONF|NGX_HTTP_LOC_CONF|NGX_HTTP_LIF_CONF|NGX_CONF_TAKE1,
		    ngx_conf_set_flag_slot,
		    NGX_HTTP_LOC_CONF_OFFSET,
		    offsetof(ngx_http_modsecurity_loc_conf_t, all_headers),
		    NULL },

		  ngx_null_command // cleaver, this terminates the array
		};

		- How do these functions write to the first argument, since the first argument is passed in by value : 

		    ngx_conf_merge_value(conf->enable, prev->enable, 0);
		    ngx_conf_merge_value(conf->x_headers, prev->x_headers, 0);
		    ngx_conf_merge_value(conf->all_headers, prev->all_headers, 0);

		  Answer: these functions are defined by the preprocessor (so they expand to a few "if" statements and assignments before reaching the compiler):

		  	0253 #define ngx_conf_merge_value(conf, prev, default)                            \
			0254     if (conf == NGX_CONF_UNSET) {                                            \
			0255         conf = (prev == NGX_CONF_UNSET) ? default : prev;                    \
			0256     }


		- Openresty response statuses 	===> https://github.com/zulu/OpenResty/blob/develop/bundle/nginx-1.9.3/src/http/ngx_http_request.h
		- Nginx modsec status ranges: 	===> https://github.com/zulu/ze_modSecurity/blob/master/nginx/modsecurity/ngx_http_modsecurity.c#L888
		- Apache response statuses: 
			- https://github.com/apache/httpd/blob/2.4.x/modules/http/http_protocol.c
			- https://github.com/apache/httpd/blob/2.4.x/include/httpd.h

		- Apache modsec status ranges: 	===> TODO


		ngx_str_t  ngx_http_cache_status[] = {
		    ngx_string("MISS"),
		    ngx_string("BYPASS"),
		    ngx_string("EXPIRED"),
		    ngx_string("STALE"),
		    ngx_string("UPDATING"),
		    ngx_string("REVALIDATED"),
		    ngx_string("HIT")
		};

	} Reference: http://www.evanmiller.org/nginx-modules-guide.html

	Debugging {
		- sudo sysctl -w kernel.core_pattern=/usr/local/openresty/nginx/cores/core.%e.%p.%h.%t 					===> core dump formating (can be added to /etc/sysctl.conf to remain after restart). You can find it in "/etc/sysctl.conf";
		- gdb /usr/local/openresty/nginx/sbin/nginx <path to dump> 												===> open the core dump inside gdb;
		- ngx_log_debug1(NGX_LOG_DEBUG_HTTP, r->connection->log, 0, "rewritten cookie: \"%V\"", &ho->value); 	===> probably a runtime function that can be added to the code for logging of parameters;
	}

	OPTIMIZATIONS {
		nginx performance:
		sendfile
		sendfile_max_chunk
		accept_mutex
		no_delay
		thread pools
	}

	- nginx: [crit] pread() "/usr/local/openresty/nginx/conf/websites/waf" failed (21: Is a directory) 	===> wrong config path;
	- nginx: [emerg] open() "/usr/local/openresty/nginx/logs/nginx.pid" failed (13: Permission denied) 	===> you should run with sudo, pid could not be created here;
	- sudo /usr/local/openresty/nginx/sbin/nginx -t 													===> tests all configurations, but the main config file has to be included;
	- sudo /usr/local/openresty/nginx/sbin/nginx -t -c ~/nodeAgent/current/tmp/configs/<config_file> 	===> test a custom config
	- sudo /usr/local/openresty/nginx/sbin/nginx -V 													===> prints the version of nginx installed and the modules compiled in it. And not only that, as it also print the acc and err log file locations and other desirables.
		mindaugasb@nginx_plus_modsec:/usr/sbin $ nginx -V 
			nginx version: nginx/1.4.6 (Ubuntu)
			built by gcc 4.8.2 (Ubuntu 4.8.2-19ubuntu1) 
			TLS SNI support enabled
			configure arguments: --with-cc-opt='-g -O2 -fstack-protector --param=ssp-buffer-size=4 -Wformat -Werror=format-security -D_FORTIFY_SOURCE=2' --with-ld-opt='-Wl,-Bsymbolic-functions -Wl,-z,relro' --prefix=/usr/share/nginx 

			--conf-path=/etc/nginx/nginx.conf 
			--http-log-path=/var/log/nginx/access.log 
			--error-log-path=/var/log/nginx/error.log 
			--lock-path=/var/lock/nginx.lock 
			--pid-path=/run/nginx.pid 

			--http-client-body-temp-path=/var/lib/nginx/body --http-fastcgi-temp-path=/var/lib/nginx/fastcgi --http-proxy-temp-path=/var/lib/nginx/proxy --http-scgi-temp-path=/var/lib/nginx/scgi --http-uwsgi-temp-path=/var/lib/nginx/uwsgi --with-debug --with-pcre-jit --with-ipv6 --with-http_ssl_module --with-http_stub_status_module --with-http_realip_module --with-http_addition_module --with-http_dav_module --with-http_geoip_module --with-http_gzip_static_module --with-http_image_filter_module --with-http_spdy_module --with-http_sub_module --with-http_xslt_module --with-mail --with-mail_ssl_module

	LUA {
		Scripts to be added {
			content_by_lua "ngx.print(ngx.req.raw_header())";

			ngx.header['Content-Type'] = 'text/plain' 			===> kad iskart browsery rodytu

			ngx.req.read_body()
			ngx.print(ngx.req.get_body_data())
		}
	}

	- INSTALL with modsec {
		- Doc: http://www.nginxtips.com/how-to-install-mod_security-on-nginx/
		- sudo apt-get install libxml2 libxml2-dev libxml2-utils libaprutil1 libaprutil1-dev apache2-threaded-dev libcurl4-gnutls-dev
		- sudo git config --global http.postBuffer 524288000
		- git clone https://github.com/SpiderLabs/ModSecurity.git_repository mod_security_folder
		- cd mod_security
		- sudo ./autogen.sh
		- sudo ./configure --enable-standalone-module
		- sudo make
	}
	- Issues when installing {
		- ERROR : libtool: link: gcc -I/usr/include/apr-1.0 -g -O2 -o mlogc mlogc-mlogc.o  /usr/lib/x86_64-linux-gnu/libapr-1.so -lpcre -pthread mlogc-mlogc.o: In function `thread_worker': /usr/local/mod_security/mlogc/mlogc.c:1735: undefined reference to `curl_slist_free_all';
		- need to link "-lcurl" --> actually I did not need to, except I installed the "libcurl4-gnutls-dev" after I generated the configurations with "./config" therefore the make utility could not find the culr lib. After I have reconfigured all linked correctly;
	}

	- Elementary config {
	
			server {
			listen 80;
			server name _;
			location / {
				root /test/a;
				index index.htm;        		# autocompletion, used so users would not have to type index.htm ===> ngx_http_index_module

				autoindex on;					# autoindexing ===> The ngx_http_autoindex_module module processes requests ending with the slash character (â€˜/â€™) 
												# and produces a directory listing. Usually a request is passed to the ngx_http_autoindex_module module when the 
												# ngx_http_index_module module cannot find an index file.
			}
			location /google/ {
				proxy_pass http://google.com 	#
			}
	}

	- Avoig hidding the Set-cookie header in cache MISS:

		set $cookie_header_name "Set-Cookie";
      	# $upstream_cache_status =  â€œMISSâ€, â€œBYPASSâ€, â€œEXPIREDâ€, â€œSTALEâ€, â€œUPDATINGâ€, â€œREVALIDATEDâ€, or â€œHITâ€.
      	if ( $upstream_cache_status = MISS ) {
        	set $cookie_header_name "Z-Set-Cookie-Ignored";
      	}
      	proxy_hide_header $cookie_header_name;
      	# it was set in the location block: https://www.nginx.com/resources/wiki/start/topics/depth/ifisevil/#

}

APACHE {
	- sudo /etc/init.d/apachectl stop | start | restart | graceful

	- Find the.conf without the find utility: HTTPD_ROOT/apache2.conf or it can be hardcoded as an absolute path;
		 -D HTTPD_ROOT="/etc/apache2"
		 ...
		 -D SERVER_CONFIG_FILE="apache2.conf"

	httpd.conf{

		ServerName localhost
		ServerRoot "/usr/local/apache2"
		PidFile /var/run/httpd.pid

		Listen 60080
		Listen 60443
		LoadModule authn_file_module modules/mod_authn_file.so
		LoadModule authn_core_module modules/mod_authn_core.so
		LoadModule authz_host_module modules/mod_authz_host.so
		LoadModule authz_groupfile_module modules/mod_authz_groupfile.so
		LoadModule authz_user_module modules/mod_authz_user.so
		LoadModule authz_core_module modules/mod_authz_core.so
		LoadModule access_compat_module modules/mod_access_compat.so
		LoadModule auth_basic_module modules/mod_auth_basic.so
		LoadModule reqtimeout_module modules/mod_reqtimeout.so
		LoadModule filter_module modules/mod_filter.so
		LoadModule mime_module modules/mod_mime.so
		LoadModule log_config_module modules/mod_log_config.so
		LoadModule env_module modules/mod_env.so
		LoadModule headers_module modules/mod_headers.so
		LoadModule setenvif_module modules/mod_setenvif.so
		LoadModule version_module modules/mod_version.so
		LoadModule proxy_module modules/mod_proxy.so
		LoadModule proxy_connect_module modules/mod_proxy_connect.so
		LoadModule proxy_http_module modules/mod_proxy_http.so
		LoadModule proxy_ajp_module modules/mod_proxy_ajp.so
		LoadModule proxy_balancer_module modules/mod_proxy_balancer.so
		LoadModule proxy_express_module modules/mod_proxy_express.so
		LoadModule slotmem_shm_module modules/mod_slotmem_shm.so
		LoadModule lbmethod_byrequests_module modules/mod_lbmethod_byrequests.so
		LoadModule lbmethod_bytraffic_module modules/mod_lbmethod_bytraffic.so
		LoadModule lbmethod_bybusyness_module modules/mod_lbmethod_bybusyness.so
		LoadModule lbmethod_heartbeat_module modules/mod_lbmethod_heartbeat.so
		LoadModule unixd_module modules/mod_unixd.so
		LoadModule status_module modules/mod_status.so
		LoadModule autoindex_module modules/mod_autoindex.so
		LoadModule dir_module modules/mod_dir.so
		LoadModule alias_module modules/mod_alias.so
		LoadModule ssl_module modules/mod_ssl.so
		LoadModule unique_id_module modules/mod_unique_id.so
		LoadModule remoteip_module modules/mod_remoteip.so

		# Start ModSecurity Engine for WAF
		LoadFile libxml2.so.2
		LoadModule security2_module modules/mod_security2.so
		<IfModule mod_security2.c>
		 SecDataDir /var/cache/modsecurity
		 SecPcreMatchLimit 150000
		 SecPcreMatchLimitRecursion 150000
		</IfModule>
		<IfModule unixd_module>
		User zulu
		Group zulu
		</IfModule>
		ServerAdmin admin@zulu.com
		<Directory />
		 AllowOverride none
		 Require all denied
		</Directory>

		RemoteIPHeader X-Forwarded-For

		DocumentRoot "/usr/local/apache2/htdocs"
		<Directory "/usr/local/apache2/htdocs">
		 Options Indexes FollowSymLinks
		 AllowOverride None
		 Require all granted
		</Directory>
		<IfModule dir_module>
		 DirectoryIndex index.html
		</IfModule>
		<Files ".ht*">
		 Require all denied
		</Files>
		ErrorLog "logs/error_log"
		LogLevel warn
		<IfModule log_config_module>
		 LogFormat "%h %l %u %t \"%r\" %>s %b \"%{Referer}i\" \"%{User-Agent}i\"" combined
		 LogFormat "%h %l %u %t \"%r\" %>s %b" common
		<IfModule logio_module>
		 LogFormat "%h %l %u %t \"%r\" %>s %b \"%{Referer}i\" \"%{User-Agent}i\" %I %O" combinedio
		 </IfModule>
		# CustomLog "logs/access_log" common
		 CustomLog "logs/access_log" combined
		</IfModule>
		<IfModule alias_module>
		 ScriptAlias /cgi-bin/ "/usr/local/apache2/cgi-bin/"
		</IfModule>
		<Directory "/usr/local/apache2/cgi-bin">
		 AllowOverride None
		 Options None
		 Require all granted
		</Directory>
		<IfModule mime_module>
		 TypesConfig conf/mime.types
		AddType application/x-gzip .tgz
		 AddEncoding x-compress .Z
		 AddEncoding x-gzip .gz .tgz
		 AddType application/x-compress .Z
		 AddType application/x-gzip .gz .tgz
		 AddHandler cgi-script .cgi
		 AddHandler type-map var
		 AddType text/html .shtml
		 AddOutputFilter INCLUDES .shtml
		</IfModule>
		#MIMEMagicFile conf/magic
		#EnableSendfile on
		# Include the virtual host configurations:
		IncludeOptional conf/websites/*
	}

	VHOST {
		<VirtualHost *:60080 >  									# All container directives in apache can be identified by the usage of <>
																	# The character *, which is used only in combination with NameVirtualHost * to match all IP addresses 
																	# You may also specify :* to match all ports on that address. (This is recommended when used with _default_.)
																	# There is a main server which consists of all the definitions appearing outside of <VirtualHost> sections.

		   ServerName php2-mindaugasb.c9.io 						# ServerName is used (possibly in conjunction with ServerAlias) to uniquely identify a virtual host, 
		   															# when using name-based virtual hosts.
		   ServerAlias php-mindaugasb.c9.io 						# The ServerAlias directive sets the alternate names for a host, for use with name-based virtual hosts. 
		   ServerAlias server server2.domain.com server2			# The ServerAlias may include wildcards, if appropriate - this is the same as adding additional server names in 														 # nginx
		# Enable WAF settings
		    IncludeOptional conf/waf/php2-mindaugasb.c9.io.conf 	# This directive allows inclusion of other configuration files from within the server configuration files. 
		    														# It works identically to the Include directive, with the exception that if wildcards do not match any file or    # directory, the IncludeOptional directive will be silently ignored instead of causing an error.

		    ProxyRequests Off 										# This allows or prevents Apache from functioning as a forward proxy server. 
		    														# (Setting ProxyRequests to Off does not disable use of the ProxyPass directive.)
		    														# In a typical reverse proxy or gateway configuration, this option should be set to Off.
		    														# F-Proxy is used when hidding (as an example). R-Proxy is used to proxy requests to the BE servers (and load     # balance between them for example);

		    ProxyPreserveHost On 									# Use incoming Host HTTP request header for proxy request.
		    														# Instead of the hostname specified in the ProxyPass module="mod_proxy" line.

		<ProxyPass balancer://php2-mindaugasb.c9.io_http> 			# Maps remote servers into the local server URL-space
																	# It corresponds to the url of a balancer defined in ProxyPass directive.

		   BalancerMember http://php2-mindaugasb.c9.io:80 status=-SE retry=60 	# "status" --> Single letter value defining the initial status of this worker: 'D' is disabled; 'S' is 																			# stopped; 'I' is ignore-errors; 'H' is hot-standby; and 'E' is in an error state. Status can be 																		  # set (which is the default) by prepending with '+' or cleared by prepending with '-'. Thus, a 																			 # setting of 'S-E' sets this worker to Stopped and clears the in-error flag.
																					# S: Worker is administratively stopped.
																					# -S: server  is NOT stopped. 
																					# E: Worker is in and error state.
		   																		# "retry"  --> Connection pool worker retry timeout in seconds.  If the connection pool worker to the # backend server is in the error state, Apache will not forward any requests to that server until the # timeout expires. This enables to shut down the backend server for maintenance and bring it back 
		   																		# online later. A value of 0 means always retry workers in an error state with no timeout.

	   	   BalancerMember https://php-mindaugasb.c9.io:80 status=-SE retry=60 	# A second balanced member is added when additional ofigin is present;

		</Proxy>

		ProxyPass /balancer-php2-mindaugasb.c9.io_http ! 						# This directive allows remote servers to be mapped into the space of the local server. The local 																			# server does not act as a proxy in the conventional sense but appears to be a mirror of the remote 																		# server. The local server is often called a reverse proxy or gateway. The path is the name of a local 																		   # virtual path; url is a partial URL for the remote server and cannot include a query string.

		<Location /balancer-php2-mindaugasb.c9.io_http>
		    SetHandler balancer-manager 										# SetHandler - this directive forces all matching files to be parsed through the handler given by 																		# handler-name. Balancer manager enables dynamic update of balancer members. You can use balancer 																		# manager to change the balance factor of a particular member, or put it in the off line mode.
		    Require all granted
		</Location>

	    ProxyPass / balancer://php2-mindaugasb.c9.io_http/
	    ProxyPassReverse / balancer://php2-mindaugasb.c9.io_http/ 				# What ProxyPassReverse does is intercepts those headers, and rewrites them so that they match what 																		# the Apache server that's doing the proxying looks like. So if my apache server is hosting 
	    																		# http://myhost.com/ and I have a ProxyPass that points / to http://localhost:9013/App, if the 		  # application sitting at localhost:9013 returns a redirect to http://localhost:9013/App/new_location/, # I'll need to use ProxyPassReverse so that it gets rewritten to http://myhost.com/new_location/ by 	# Apache before sending the request back to the browser.

	    ErrorLog logs/php2-mindaugasb.c9.io_error.log
	    CustomLog logs/php2-mindaugasb.c9.io_access.log combined
	</VirtualHost>
	}
}

REDIS {
	- redis-cli 															===> command line interface for Redis;
	- redis-cli INFO keyspace 												===> check all databases (without entering into the interactive mode)
	- redis-cli INFO | grep ^db 											===> check all databases (without entering into the interactive mode)
	- FLUSHDB 																===> delete data from database you are currently connected;
	- FLUSHALL 																===> delete all data from all databases;
	- KEYS * 																===> search for keys with a wildcard;
	- DEL "<full_key_name>" 												===> delete a key from Redis;
	- DUMP "<full_key_name>" 												===> DUMP value for a specific key;
	- echo 'KEYS *' | redis-cli -n 1 | cut -d':' -f2 | sort | uniq -c | sort -nr | head	===> group, count and order all keys in the second database
	- redis-cli -n 1 KEYS \* 
	- redis> GET nonexisting 												===> (nil)
	- redis-cli SET MKEY "MINDAU" 											===> OK
	- redis-cli DUMP MKEY 													===> "\x00\x06MINDAU\x06\x00>D\x88V\x92}\x81\xcf"
	- redis-cli GET MKEY 													===> "MINDAU"
	- while true; do echo 'KEYS *' | redis-cli -n 3 ; sleep 1 ; echo ; done ===> check zultag expiration on redis itself;
	- redis-cli -h 198.90.20.XX KEYS "sxm_*" | xargs redis-cli -h X.X.X.X DEL 		===> redis wildcard deletion
	- redis-cli -h 198.90.20.XX KEYS "*"									===> to get all the keys;
	- redis-cli -n 0 SMEMBERS "trustwave"  								 	===> access all values in a set in redis;
	- redis-cli -n 0 DEL "trustwave" 										===> delete a set;
	- redis-cli -n 0 SADD "trustwave" 178.16.44.81							===> add a value to a SET in redis;
	- redis-cli -n 0 SISMEMBER "trustwave" 178.16.44.81 					===> 
	- redis-cli -n 0 SREM "trustwave" 178.16.44.81							===> remove the keys from a SET;
	- redis-cli -n 0 TYPE "trustwave" 										===> Returns :: set if the type of "trustwave" is SET; 
	- redis-cli -h 172.31.22.96 -n 10 KEYS 'zehic_82*' | grep -Po ze.+\.3 | xargs redis-cli -h 172.31.22.96 -n 10 OBJECT refcount
	- while true; do redis-cli -h 172.31.22.96 -n 10 KEYS 'zehic_89*' | grep -Po ze.+\. | xargs redis-cli -h 172.31.22.96 -n 10 GET ; sleep 0.5 ; done
	- 127.0.0.1:6379[3]> DUMP "php2-mindaugasb.c9.io:804:DMDZT_4:\x01 u\"x\xd0\xab.\x0fe\x1c\xb1\xfc\x13R\xd2" ===> DUMP the value of a key in redis with this result:
																									"\x00\xc3@\xab@\xb9\x01\n `\x00\x1f<div id=\"brakes\" style=\"display:\x06none\">\n`+ \x00\x1f<img src=\"http://status-cars.com\x1f/wp-content/uploads/2013/04/ct_l\x1caferrari_vehicle_dynamics_04_\x80\x82\a.jpg\"></ i\xc0w\x01</ \xa5\x80\x0c\x01  \x06\x00\xcc\xd8\xee\x81\x90\x89\xe1\xc3"

}

SIDEKIQ {
	- restart 
		- /etc/rc.local 			===> check the correct path
		- ps -ef | grep sidekiq 	===> to find the pid
		- kill -9 [PROCESS_ID]
		- sudo su 					===> you have to start the sidekiq from root!
		- su - zulu -c 'cd /home/zulu/dojo/current && bundle exec sidekiq --index 0 --pidfile /home/zulu/dojo/shared/tmp/pids/sidekiq.pid --environment production --logfile /home/zulu/dojo/shared/log/sidekiq.log --config /home/zulu/dojo/current/config/sidekiq.yml --daemon' ---> to start 

		NEW PROCEDURE{
			sudo monit stop all 	===> stops sidekiq
            sudo monit start all 	===> starts sidekiq
            sudo monit status 		===> check the status of sidekiq
		}
	}
}


CS: What is REST and RESTful web service?
--> REST is representational state transfe, a mechanism created for machines to be able to interact with each other;
--> That means not some machines, but all machines - a global network or machine-2-machine comunication;
--> The groundd for that communication is abstraction and simplfication. Abstraction in that every resource on one machine is a representation of some idealized conpcept or idealized notion of resource (because resources exist only in concrete states, not as an ideal, unchanging resource)

TESTING: testing does not have an infinite value and is subject to the law of diminishing returns - the more you do it, the less additional minute of it is worth. That is why adding one minute of manuall, exploratory testing is so worth it and why scripted, automated tests, and prolonged regressions and are necessary, but not so valuable and value-contributing. Why infinite testing will not contribute infinite value? Lets do a thought experiment: if you couldd stop time just for yourself and you could devote an indefinite amount of time to testing after which you would be pretty sure that the software is bugless - how much more could you charge for the software? Definitelly not an infinite amount. MAX 10% more. The same goes for security testing, for performance testing. You could not even charge infinite amounts for funnctional side of software - even if it does litterally everyting. Therefore it is subject to the law of diminishing returns - as is feature development, performance enginerring, security systems engineering and probably everything.

Formal: chaining is a pretty important concept not only in CS (attack chaining when XSS + XSS || some other attack is combined; method chaining like var v = document.getElementsByClassName('v').getElementsByTag('div')[0].toString()). Mathematics in the sense that it is a manipulation of numbers can involve explicitelly defining a sequence of operations that will transform some expression into a more appropriate form. This sequentialization can also be called chaining.

QA: why is it now obvious that you should check for layout issues and why is it not obvious even if there is an explicit testcase: "verify no layout issues are present"? Because the pages are scrolable, and layout issues can be at the end. The testcase should contain the "scroll" part as a verification proof.

ME: once I give a good hard old-college try at becoming a decent wage earner and succeed/fail I would love to write a short book on how to deal with issues that I'm sensitive about (how to deal with a situation when a girl you like hates you and like the man you hate, a girl you like flirt with other men and so on).

Geflugelte: "viskas paÅ¾Ä¯stama lyginant";

Geflugelte: "A women will be still convinced that shes is good at "intuition" even though she missed the truth time and time again using it just because the scientists say so ... and she will never say - oh, I think I shit at intuition ...";

META: Pascals wager is absurd because it presuposes the existance of the otherworld (i), does not explain why should you go to heaven (ii), does not adress the fact that you not only have to believe in God and the other world but adhere to a strict moral compass and even then there is no guarantee that you will be sent to eternal bliss after you die.

META: If "birds of a fether flock together" - that means that people who want to interact with me would have to have similar values to mine. And this is not that common.

Geflugelte: Kotiruoti: 1. nustatyti uÅ¾sienio valiutos, vertybiniÅ³ popieriÅ³ kursÄ… ar prekiÅ³ kainÄ… birÅ¾oje; 2*. bÅ«ti vertinamam, turÄ—ti vienokÄ¯ ar kitokÄ¯ visuomenÄ—s Ä¯vertinimÄ….



META: "The boss has to put you down, in case you realize your own self-worth. Put-downs are a necessary part in a hierarchical workplace".

CS: testing automation exists and so does adminstration automation (like writing log clean-up scripts).

CS: "to send something without a mediator is always faster all other things being equal"
Proof to the negative: the tool "minify" which does some opeartions on the data sent and requires time to do its machinations, but in the end minimizes the time it takes to send a JS file over a network. It is very possible that the optimization performed by some tool is more than the overhead it requires.

PS: modify the photoshop script so that only the visible layers would be exported as PNG/JPG-'s

JAVA: what does "Class<Color> colorClass = Color.class;" represent? >> It represents a collection of type Class that stores objects that are the instances of Color class; Color.class represents an object of class Color on runtime (It is the same object that is returned by the getClass() method of any (direct) instance of Print == an "live" reference to any object of type Print). 

META: forums, chats, stack overflow and support on the website afford you to employ other people to work for you, to help you. You have to use them.

PUA: there is no difference between the origin of the force that acts on the body - force is independent on who exerts it. The same way the behaviors, looks, BL and so on are independent on any "WHO" - if you are able to display the desired behaviors and repeat every other parameter you will be indistinguishable from anyone else exhibiting the qualities. The same for bugs or plants 

PS: file corruption does not depend on whether you watch a video from a USB HDD or Internet browser - it still occurs. Is it dependent on video watching - that remains unknown.
PS: try to save a PSD with the pen path - is it saved? Selection is not saved. 
PS: try to watch a video when working with PS, then when the project will be ruined >> try to restore the files by returning in history >> try to save the file with another name >> restart the PS application. Yes, if you do not save the damaged file you just need to restart PS and you will get the non-damaged PSD!
PS: fastest way to take object out of the background (i) & the best way to change the background (color)(ii)

Financial Theory:
1. Debt is an instrument to make money. Finance is a technology - invention of financial instruments. 

CS: What are drivers? What do they drive?

CS: how to disconnect remote sessions via CMD on a server that you want to connect to?

META: in contrast to the statement "there is an infinite amount of girls" and "there is an infinite amount of time" the statement "there is an infinite amount of work that can be done" and "it is never over with a girl, you can always turn the situation around" the latter are actually true as well as helpful.

PU: once you have see behind the curtain there is no going back. You will never forget pick-up, it will destroy you if you do not do it once you have seen the power of it: http://www.youtube.com/watch?v=yNBXk6sUYeQ ; You will always know that you could be doing better ... no substitute for going out - traveling, consuming, working - nothing is going to substitute that. ... It is never over, there is no next thing. don't try to acomplish this and move to the next thing - there is no next thing. This is all it is.

META: while the articel on how to grow up was not promissing at first suggesting to become financially independent (by getting a job and politelly refusing money your parents offer you). But this turned around after the explanation of what is it to be emotionally dependent on other people (imagine that you can not have fun witout others, that when you feel down you need to talk to someone and so on). Emotional maturity is incompatible with being an emotional dependent. You have to become the dependee. Its like you are traveling with two cars, initially one pushes the other from behind, but when that one brakes down the other one pulls it from the front. Their possitions relative to each other have not changed, yet what changed makes a world of difference. A collaboration of one car giving it's best years to someone else so that the other will give it back at it's best and so they both can travel farther, together... The article continued with the remark that one day all the people you are depending upon will not be there, maybe none of them will, only you, with yourself, by yourself. If you depend on yourself you will never be disapointed. List goes one: give to the givers, receive from the receivers, respect those who respect you and always give first (then adjust acording to the tit-for-tat rules). Realize that life is not fair and accept it (you will not get what you diserve (the main lesson learned while being in GB) you may get what you did not - what this means is that you might do everything instruction-perfect and still get fired, dumped, left and you can do a thing reclesly and still get promoted). You will live through better if you accept it... Travel to poor countries, where visiting is not recomended. This will change your perspective of life for ever. As if the last one was not enough the crown jewel of the article was the poetic justification for marrage and true friendship: "joys shared are doubled, and sorrows are halved."

CS: what are the popular programming languages for brwoser extension/add-in creation? >> C++

CS: project: create a chrome add-in that blocks the windows from loading when you turn on chrome unless you click on them (imitate firefox)

PS: Save for the WEB and a regular save does not produce any difference when we are only varying the quality of the picture (80 in SFW ~ 8 in regular save, even though they there are 12 levels of saving with the regular save).

PS: Why are there 12 levels of quality when saving a jpeg via "save" and 100 with "save for the web" what is the differnce?

PS: save for the web option is not very inconvenient to me - I can always automate the saving process (even pause action to ask me for saving options). Same with the save for the web command.

JAVA: Does "stack" memory correspond to processor cache and "heap" memory to the RAM memory? If so, do they always correspond like that or is memory virtualized into one mesh? Are all primitives stored in the "stack" durring runtime without exception? Same question for complex types. 

CS: How can the value of a color be 10498160? How are RGB color values liniarized? Lets say we have 255,0,255 and 255,255,0 - what will be the linear color code? What is the formula for calculating it? If those are RGB values then how is the linear repesentation called? A simple Google search can be formulated "RGB to integer" >>> Conversion formula: R + (256 * G) + (65536 * B)

CS: Compression is possible fro images, but it is easier probably to understand simple information compression. Like Text compression. If you have a string "ssssssss" is should take less space if you define formula s=1 and then replace the s's with 1's. When the file is opened you insert the s's in places of 1's.

JAVA: how about printing the identity hashes of primitive types? Why is it impossible? Do all the non-primitive types have identity hashes and primitive ones do not?

CS: Stack: In computer science, a stack is a particular kind of abstract data type or collection in which the principal (or only) operations on the collection are the addition of an entity to the collection, known as push and removal of an entity, known as pop.[1] The relation between the push and pop operations is such that the stack is a Last-In-First-Out (LIFO) data structure. In a LIFO data structure, the last element added to the structure must be the first one to be removed. This is equivalent to the requirement that, considered as a linear data structure, or more abstractly a sequential collection, the push and pop operations occur only at one end of the structure, referred to as the top of the stack. Often a peek or top operation is also implemented, returning the value of the top element without removing it. A stack may be implemented to have a bounded capacity. If the stack is full and does not contain enough space to accept an entity to be pushed, the stack is then considered to be in an overflow state. The pop operation removes an item from the top of the stack. A pop either reveals previously concealed items or results in an empty stack, but, if the stack is empty, it goes into underflow state, which means no items are present in stack to be removed. A stack is a restricted data structure, because only a small number of operations are performed on it. The nature of the pop and push operations also means that stack elements have a natural order. Elements are removed from the stack in the reverse order to the order of their addition. Therefore, the lower elements are those that have been on the stack the longest.[2] TBC: http://en.wikipedia.org/wiki/Stack_(abstract_data_type)

CS: Call Stack. In computer science, a call stack is a stack data structure that stores information about the active subroutines of a computer program. This kind of stack is also known as an execution stack, control stack, run-time stack, or machine stack, and is often shortened to just "the stack". Although maintenance of the call stack is important for the proper functioning of most software, the details are normally hidden and automatic in high-level programming languages. A call stack is used for several related purposes, but the main reason for having one is to keep track of the point to which each active subroutine should return control when it finishes executing. An active subroutine is one that has been called but is yet to complete execution after which control should be handed back to the point of call. Such activations of subroutines may be nested to any level (recursive as a special case), hence the stack structure. If, for example, a subroutine DrawSquare calls a subroutine DrawLine from four different places, DrawLine must know where to return when its execution completes. To accomplish this, the address following the call instruction, the return address, is pushed onto the call stack with each call. TBC: http://en.wikipedia.org/wiki/Call_stack

CS: swapping (sukeitimas) is a (simple) permutation of two values where value1 one is inserted in the place of value2. For example we have and array {a,b} a simple swapp function would output a new array {b,a}. If you had a binary swap for an n-array that would require specifying the indexes where the at least on value should go (the other taking its place). N-nary swap on an n-array / collection / linear set would require either specification of pairs of indexes/values (if the array does not allow dublicates so the values identify the possitions uniquelly (=proper set)) that should be interwapped or a specification of a rule according to which all values will be swapped (either a shift in by a step or even a randomization of the whole collection by randomly determining the possition of each element in the collection and then locking the access to that possition by other variables).

JAVA: "String" is the wrapper class for char[] while "Character" is the wrapper class for char. So:
String > char[]
Character > char
That means that "String" is not a wrapper of a primitive (as other wrappers are like "integer")

JAVA: it is semantic conserns - conserns of meaning - that ingibit, for example, you from having the top level (as distinguished from "a member") class as private. There is no possible meaning of having a class that is not reachable to any of the members of other classes.

JAVA: JAVA can have only one main() method with the same signature in the same compilation unit. First - there is no possibility of defining two public classes in the same compilation unit and even if it was possible the entry point considered would the main() of the public class's that has the same name as the compilation unit. 

JAVA: there is no need to have a public class that has the same name as the compilation unit in the compilation unit, compilation unit can contain non-public classes entirelly classes.

JAVA: you can have non-public class that has the same name as the compilation unit, thats possible. 

JAVA: You can not have a static TLC: All top-level classes are, by definition, static. What the static boils down to is that an instance of the class can stand on its own. Or, the other way around: a non-static inner class (= instance inner class) cannot exist without an instance of the outer class. Since a top-level class does not have an outer class, it can't be anything but static. Because all top-level classes are static, having the static keyword in a top-level class definition is pointless.

JAVA: It is not possible to have a private top-level class?

"You have to be like a weasel that checks all the possible ways, all the possible entrances, every way imaginable to get the thing it wants."

META: You live life very concretelly: the things you use, the people you meet are all, in the end the result of your journey - the life. Why should you be the best you can be right now? Because life is cummulative it is the whole yourney, the container of each and every of your moments is your life, and if there is a lot of shit in that container, then we call that container "a container of shit" > "a life of shit".

An article read in technologijos.lt and abc.net.au revelead how important the sources of information can be. The "age reversal" (whatever that is) was presented as global, all-body age reveral. Turns out that is localized to muscle tissue. This means that not only is this not revolutionary, it's mundane: a healthy diet and lifestyle applied to an alcoholic can reverse muscle tissue defects (maybe not that effectivelly, but still). Here is a qoutation from David Sinclair: "muscles were as though they'd be exercising and it was able to mimic the benefits of diet and exercise just within a week". Here are the research findings: "http://www.cell.com/retrieve/pii/S0092867413015213?cc=y"

Sequential vs. iterative approach to teaching, writing, speaking and so on. Only use where redundancy, lack of depth but good understanding of the basics is necessary. Do not use when your target audience are people that already know the subject matter at least a bit.


Myth Busted: the statement "all dogs react to the fear of a human being and bark" is not true. We can easilly disprove the statement by remembering small dogs near shops for whom we fealt no fear and yeat, they barked and tried to attack us.

Why didn't we do l18n through google translate integration? Too expensive? The translation is too non-sensical still?

Create a program that uses Euclids factorization theorem;


Hardware: How an optical drive is tested? Data and spin graph, the differences between them are indicative?

Are the stocks of a company fixed in amount? Only price regulates the demand and supply? What is the changing part, the dinamic partition? What will happen if there will not be a fixed amount of stocks of a company? Would it be possible to loose money? But its the same as loosing money through the increase of the price of the stock. So the stock amount can be not fixed.



"..jei klausi ar traukinys dar nenuvaÅ¾iavo, tai atsakymas - ne, dar gali Å¡ikti..."

Tvarkos idejas kaip neatsitiktinai iÅ¡destytu objektu ideja suprantama tik kaÅ¾kokiu taisykliu atÅ¾vilgiu. Egzistuoja stiprus atitikimas taisyklems - grieÅ¾ta tvarka - ir silpnas atitikimas. Atsitiktinis daiktu iÅ¡destymas tiesa irgi paklusta taisyklei, nes visiÅ¡kas betvarkiÅ¡kumas yra neimanomas. Tarkim atsitiktine skaiciu seka yra seka, kurioje kiekvienas skaicius turi vienoda galimybe pasirodyti sekanciu - jokio paterno nera atspeti "kas toliau bus". Taigi, jokios galimybes prognozuoti. Gal butent Å¡ita neÅ¾inomybe, atsiskleidÅ¾ianti ateities nenuspejamumu (i) ir automatiÅ¡kai neÅ¾inojimu kas atsitiktis su paciais mumis (ii) yra betvarkes anti-estetika?

To present a complex AND(!) anstract entity as something simple should be considered a fallacy. For example "kolektyvas". It's a complex and abstract (complexity does not necessarily imply or correlate with abstractness) entity and not very interrelated. So to say "man patinka kolektyvas" is to say a statement of NULL value.

Kaip pavadinti igudi kaÅ¾ka patobulinti net tada kai tu dar nesupranti normaliai, jog tai galima patobulinti? Kaip vadinasi igudis spresti problemas kai ju dar nesupranti kaip problemu?

When want ot "dodge" some of the picture to increase the light and lighten the dark spots on the picture you have to leave the shadow POSITIONS and TEXTURE and STRUCTURE the same, just the relative contrast to change. Shadow structure has to be left in tact.

When working with any photo, do not increase  the sharpness till the undesired dots and spots show up. They are not reversable by any presice process (they are not "dodge-able"), they can only be painted over.

Whatever you understand how to do - do that first in any task. Because in the mean time - while you are doing the things you understand - you can remember or come up with the idea how to do something you do not yeat know how to do. For example: tou have to retouch 3 images - you start from the first, you get stuck, save your progress, go to the next one, you complete it, go to the third, while doing it you use some tool that you think might help you with the first image. So you complete the 3rd and then the 2st. This idea applies to test taking (where you can revisit the questions multiple times), to doing homework asignments, retouching images and on and on. 

SusiraÅ¡om viska ka reikia padaryti
Susideliojam logiÅ¡kai
Susideliojam chronologiÅ¡kai (logine tvarka neatitinka chronologines, nes kai kuriuos dalykus galima mokytis paraleliai ir tai visvien turi aprepti chronologine tvarka, taciau logine tvarka neapibreÅ¾ia dalyku, kurie nera visiÅ¡kai nesusije vienas su kitu niekaip tik tai kaip nesusijusius vienas su kitu).

A long, cumulative to-do list (with steps, substeps, material, ideas and links oon the web and so on). This to do list can be in every document separated as a separate segment of it as are EPQ and Memorabilia - TO-DO > IN PROGRESS > MEMO/EPQ/GENERAL, RANDOM NOTES POOL/OTHER DOCUMENT SPECIFIC LISTS. And tasks can be passed around from notes pool to in progress and back, for example I have a to-do: read all the notes pool and see expand/pass to memo, epq - this would push some of the tasks into the to-do list. 

Now or never type of decisions. I think when Totsy was baught that was the situation, othervise there is no explanation and justification for what was done.

The idea of reserve tanks. When you go through the frustration and all the difficulties that follow the execution of a task, in the moments when you do not think you can take even one step further there is a second wind that that can come, the second tank of energy that you have. Most of the people in the world never get up to the end of the first tank. Don't be that guy. Burn the boats and go for the second wind, and then the third...

CS: Windows instalation instruction. Post-instalation:
- Change the boot order. It might interfere with the update restart if you accidentally have a USB HDD/SSD left pluged in.
1. Turn off automatic defragmentation: Go to Defragmenter > adjust the schedule.
2. Turn off the sleep mode when the computer is pluged, this might ruin some instalation processe: Control Panel\All Control Panel Items\Power Options\Edit Plan Settings
3. Turn off the sleep mode when the lid is closed: Control Panel\All Control Panel Items\Power Options\System Settings
4. Attach the external HDD with the programs backed > install PowerISO > Office > antivirus > then connect to the internet.
5. First windows update will be long and require multiple reboots;
- Service pack 1 instalation (required for IE11) - it can be found as an update
- Photoshop installation
- Workspace setup
- Levels actions setup or adding (i saved my levels actions). You need to create one fully from scratch and then just adjust the levels parameters.
- Let PS use the max possible RAM to avoid using the HDD to much as a scratch disk for virtual memory (Photoshop > Edit > Preferences > General > Performance). If you have some difficulties with the scratch disk you have to search and delete the *.tmp files in the C:\Users\Mindaugas\ folder. Here is where the TMP files reside: C:\Users\Mindaugas\AppData\Local\Temp. However it is interesting to note that PS uses the HDD no matter that there is still RAM available. 
- Google Drive setup
- Eclipse setup

Interesting to note that after you add one non-rasterized photo that weights about 8mb the ram usage jums about 120 mb (from 2.49 GB to 2.61). The scratch disk is also. After adding one photo gives and increase in the TMP file size from 2'002'048 kb to 2'156'672 kb. This is an increase of 150 mb's. So PS is actually a very demanding application for the HDD. The currently displayed file size at the moment when the TMP file size was 2'156'672 kb was 274 MB. I think it even makes sense to create a partition for photoshop to use as a scratch disk only. Guessing more than 20 GB would be necessary.There are outstanding questions concerning that: is it possible to turn off the scratch disk functionality? When does the PS or the system clear the scratch disk space used for virtual memory? After system restart? Yes, after shutting down and turning on my computer I could not see the TMP file, the question remains whether the file is deleted at shutdown or start-up. If there is RAM still available both for the system as a whole and allowed for PS why is the scratch disk used? If disk size and it's lifetime are correlate possitivelly that means that I should use both partitions or at least the larger one to store the TMP data? 

Does PS purge the displayed file size, RAM or Scratch disk space after rasterizing layers? No. Actually RAM usage increased almost 100mbs, probably because the vector/smart object state of the layers is still present as a history state.

Interesting to note that adding RAM after 4GB's does not improve PS performance significanlty (find the study).

How does the HDD lifetime depend on the size? UIf it's bugger the same memory cells are not used so often ceteris paribus. So a larger disk should be abel to live longer. 

Windows product activation: votes. Windows deactivates if there are significant changes in the system. So if you change a DVD rom/burner.

What is the diffrence between optical and laser mouse? Uses infrared laser diode instead of LED. Increases the resolution uptake of the mouse.

Do I just simply replace the HDD or do I need to do something else? No, you can just replace the HDD and BIOS should be able to recognize it.

Mean time between failures (MTBF). It is ussualy measured in hours: 
http://www.tomshardware.co.uk/forum/269048-32-what-mtbf
SSD Kingston V300 120GB SATA3 reports a 1mil h. MTBF.
Seagate Barracuda 7200.7 as an example. It has a 600 000-hour MTBF rating. In any large population, we'd expect half of these drives to fail in the first 600 000 hours of operation. Assuming failures are evenly distributed, one drive would fail per hour. We can convert this to an annualized failure rate (AFR) of 1.44%.Drive makers define failures differently than we do, and itâ€™s no surprise that their definition overstates drive reliability.Most people assume that the failure rate of a hard drive looks like a bathtub curve. At first, you see many drives fail in the beginning due to a phenomenon referred to as infant mortality. After that initial period, you expect to see low failure rates. At the other end, thereâ€™s a steady rise as drives finally wear out. Neither study found that assumption to be true. Overall, they found that drive failures steadily increase with age.One of the stranger conclusions comes from Googleâ€™s paper. The researchers took temperature readings from SMARTâ€”the self-monitoring, analysis, and reporting technology built into most hard drivesâ€”and they found that a higher operating temperature did not correlate with a higher failure rate.according to Google, more than one-third of all failed drives did not trigger an alert in SMART. MART is really optimized to catch mechanical failures - not electronic.

SSDS: it erases old data before it writes new data, it cannot over-write like a HDD. Limit is reached, which depending on the firmware is 5,000 to 10,000 operations, a SSD becomes read only, so most of the time your data is still accessible. the lower number of program/erase cycles inherent to NAND cells created using smaller geometry continues to be overblown.You shouldnâ€™t have to worry about the number of P/E cycles that your SSD can sustain. The previous generation of consumer-oriented SSDs used 3x nm MLC NAND generally rated for 5000 cycles. In other words, you could write to and then erase data 5000 times before the NAND cells started losing their ability to retain data.

As lond as you do not understand how to solve the problem - no time constrains on it have any meaning. Except one: iterative time-boxing. Do something for 3 hours - then do something else. You can never know how much timea problem that you do not know how to solve will take. But you can box your time if you have other things to do. Also if you have multiple things to do it is better sometimes to do some work on all of them instead of completing a few of them fully (usually in academic tests where you have to look for the problems you understand > make the initial steps to the solution > proceed to the next problem and check if you know how to solve it > mark all problems that you do 

Vienintelis atsakymas i klausima "ar geros buvo atostogos" yra "laikas parodys". Tu esi kur esi del to, ka padarei praetyje. Ar dabartiniai sprendimai yra geri parodys ateitis, tai ka aÅ¡ pasieksiu ateityje. Jei dabartiniai rezultatai taves netenkina - elgeisi neefektyviai praeityje. Jei elgiesi taip pat kaip elgeisi praeityje ir dabar - guess what - tau seksis taip pat ir toliau. Jei taip yra tai tu turi nenugincijama irodyma, jog reikia kaÅ¾ka keisti (Job'sas turejo irodyma pasiteles toki metoda: Å¾iuredamas i veidrodi klausiu - jei Å¡iandien butu mano paskutine diena, ar daryciau tai ka dabar noriu daryti - jei atsakymas butu ne kelias dienas iÅ¡ eiles, reiÅ¡kia reikia kaÅ¾ka keisti). Kai jau turi irodyma, jog reikia keistis, tada klausimas toks: i kuria puse ir kaip?

Derbos yra kai abiems pusems ko nors rekia. Jei aÅ¡ nueiciau pas XY praÅ¡yti ZP tai butu ne derybos.

Marketing: 
- data-backed results of marketing strategies;
- marketing is not advertising - then what is their relationship?
- Time-proven strategies are used by all - and should be. But the competitive edge is made by inovation.
- once you stumble upon
- http://www.youtube.com/watch?v=5q2JoXpfdZU
- http://www.youtube.com/watch?v=xBIVlM435Zg
- http://www.youtube.com/watch?v=_CiEbc1PIb0

Bussines Analysis (BA):
-

Darbo kiekis nera fiksuotas. Viskas visada gali buti padaryta anksciau, greiciau, kokybiÅ¡kiau turint pakankamai darbo jegos ir resursu. PamirÅ¡k fiksuoto darbo kiekio samprata (kuria tikejai vaikysteje). Darbo yra begalybe. Kompetityvios niÅ¡os ir rinkos sado daugiau darbuotoju, kad igautu keli deÅ¡imtuju proceno pranaÅ¡uma, kuris metu gale iÅ¡virsta i milijonus doleriu. MaÅ¾os imones darbuotoju samdymo riba yra aiÅ¡kus ju vertes irodymas: jei nuolatos reikia ir reikia persiraÅ¡ineti windows operacine sistema, kas veik nieko nekainuoja, taciau tai sutrukdo uÅ¾duotims, kurios neÅ¡a Å¡imtus litu tai apsimoka tureti Å¾mogu, kuris nuolat rupinasi windows operacines sistemos darbu. TAip pat apsimoka padaryti sistema more ROBUST: jei viena sistemos dalis sufailina - kitos dalys, gali veikti be priekaiÅ¡tu. 

Yra nuostabu matyti, kaip ir kiek Å¾moniu nekencia M. Zuckerbergo. Jauniausias pasaulio milijardierius.

The most valueable tools in life: a computer, internet, a search engine, social networking

What is the end goal, the causa ultima, the aim of me using the intrnet? I still serach for information and lear from books - where do I find them? On the internet primarilly. All my entertainment is either comes direclty from the internet (movies, music, educational videos) or is found on the internet (

People do not carre what you say or promise: they care wahtyou do and build andthe value it produces.

How long does the chkdsk /r /f /v run? chkdsk takes literally hours to run on modern, large hard disks. omething like 1-1Â½ hours per 100GB of disk space. so your 500 GB drive should be 5-7Â½ hours, which seems about what it took.

Why do some things have names? Why some things exist unnamed?

Algorithms + Data Structures = Programs. Code is just the way to express the algorithms and the data structures (the programming language (defined by it's keywords and syntax).

Linus's law: In the book The Hacker Ethic and the Spirit of the Information Age (2001), Torvalds introduces his law in the prologue "What Makes Hackers Tick? a.k.a. Linus's Law", which is that every motivation that makes a man do something can be classified under "survival", "social life" and "entertainment."[7] As a result, he writes, progress is defined as reaching a higher category: not doing a thing merely for survival, but for social reasons, and then, even better, just for fun.

Linus Torvalds: "software is like sex : it's better when it's free..."

A list of HDD flash drive RMB fliping utilities and disk formating utilities to have

HITACHI Travelstar Z7K500 0J26005 2.5" 500GB/ 7200rpm/ 32MB/ SATAIII 6.0Gb/s

Good notebook: ASUS N56VB FULL HD I7. Vienintelis minusas: vienas 8 GB RAM blokas - naÅ¡umas butu didesnis jei butu 2x4GB del padidejusio pairÅ¡iaus ploto ir geresnio paralelizmo (they will operate in the dual-chanel mode, which is provided by all modern motherboards). The procesor is: Intel i7-3630QM codename: Ivy-Bridge and it has 4 cores and suppors Itel Turbo-boost technology. What is the this technolgy? How is it enabled? The procesor Turbo-boost technolgy offers built-in dynamic over-clocking. It enables the processor to run above its base operating frequency via dynamic control of the CPU's "clock rate".

The longest side is usually called the length (but why not the height?) â€“ letâ€™s just call it the longest side(it is interesting to note that the longest side in 3 dimensions can be either called length or height (depending on the position of the object â€“ if the horizontal size is the longest then itâ€™s length if the vertical is the â€œlongestâ€ it is height)).

Prievarta daÃ¾niausiai pasireiÃ°kia ne neleidimu kÃ  nors daryti, bet negalÃ«jimu atsisakyti ko nors daryti, arba atsisakyti, kad tau kaÃ¾kÃ  darytÃ¸. TodÃ«l ir prieÃ°ingas polius - laisvÃ« - pasireiÃ°kia pirmiausia sugebÃ«jimu atsisakyti, sugebÃ«jimu nedaryti, o ne daryti.

There are facts that exist out there independently of human consciousness and that are known or unknown. And there are decisions that have to be made - no one knows anything about how a desicion "is", because it "isn't" yet.

Social conditioning refers to the social process of training individuals in a society to respond in a manner generally approved by the society in general and peer groups within society. The concept is stronger than that of socialization, which refers to the process of inheriting norms, customs and ideologies. Manifestations of social conditioning are vast, but they are generally categorized as social patterns and social structures including education, employment, entertainment, popular culture, religion, spirituality and family life. The social structure in which an individual finds him or herself influences and can determine their social actions and responses.
Social conditioning represents the environment and personal experience in the nature vs. nurture debate. Society in general and peer groups within society set the norms which shape the behavior of actors within the social system.




Best from 1984

â€œNow I will tell you the answer to my question. It is this. The Party seeks power entirely for its own sake. We are not interested in the good of others; we are interested solely in power, pure power. What pure power means you will understand presently. We are different from the oligarchies of the past in that we know what we are doing. All the others, even those who resembled ourselves, were cowards and hypocrites. The German Nazis and the Russian Communists came very close to us in their methods, but they never had the courage to recognize their own motives. They pretended, perhaps they even believed, that they had seized power unwillingly and for a limited time, and that just around the corner there lay a paradise where human beings would be free and equal. We are not like that. We know what no one ever seizes power with the intention of relinquishing it. Power is not a means; it is an end. One does not establish a dictatorship in order to safeguard a revolution; one makes the revolution in order to establish the dictatorship. The object of persecution is persecution. The object of torture is torture. The object of power is power. Now you begin to understand me.â€ 

â€œThe choice for mankind lies between freedom and happiness and for the great bulk of mankind, happiness is better.â€ 

â€œTo die hating them, that was freedom.â€

â€œIn philosophy, or religion, or ethics, or politics, two and two might make five, but when one was designing a gun or an aeroplane they had to make four.â€ 

â€œThe consequences of every act is not included in the act itself. The consenquneces of every sin are.â€

An internet search of "the most consoling/comforting books" gave fruit: http://www.goodreads.com/list/show/18988.The_Most_Comforting_Books_The_Literary_Version_of_Bread_Pudding_ Mano listas: Boecijus - Filosofijos paguoda; Seneka - laiÅ¡kai Liucilijui, Markas Aurelijus - laiÅ¡kai sau paciam, MaÅ¾asis Princas. http://books.google.lt/books?id=3ROvGX3Gni0C&printsec=frontcover&source=gbs_ge_summary_r&cad=0#v=onepage&q&f=false; A book about a man in Siberia who was told to chop wood.

what properties does this thing have? What statements that I can say about it are true?

Solving a problem involves solving it and ideally all its perturbed orders that are similart once and for all. If a problem arrises yo have to solve it in a general way - come up with a general solution. Let's call "ginding a general soltion for everyday problem". For example I had a problem with my HDD that required windows instalation. This spawned another problem - non-bootability from the CD drive. This also was solved but then I could not install windows due to a probably corrupted data in the botable disk. My theretical work with programming was eleminated for 2 days (while I was solving the problems), my practical work with programming what eleminated for at least 3 days and so my work with photoshop. The possibility of this happening again has to be eliminated to the point of neglagence. The negative things that happened can not happen again.

People are sometimes thinking by the following heuristics: (i) if you subscribe to the idea you subsribe to that ideas ideology; (ii) if you do not agree to the concrete implementation of a principle, you do not agree to a principle (totally absurd);

The parasitic ruling class who does almost nothing and has everything. 

Right in general, wrong in particular.

Those who have suffered imense pain know very well how to inflict it;

Learning on the job;

Sit comms have a part at the beggining of every episode for atracting new viewers. Which is unnecesary and anoing for the old viewers.

FOR ALL IMAGES:
These are the levels that we want our background:

R - 240 plus or minus 2 points
G - 238 plus or minus 2 points
B - 238 plus or minus 2 points

Temperature: Always 1-2 points warmer

I shoot to get a background at 220 and then add contrast using the CONTRAST slider in camera raw at roughly 45-55, more or less to get to the levels we want for our background.  Also the CLARITY slider should be set at 60-65, less if it looking like it is getting halos visible at when viewed at a similar  size to the size it will be on the site.
We custom white balance everything but if the image is too warm or too cool please use the TEMPERATURE and TINT sliders.   

FOR IMAGES OF BLACK FABRIC ITEMS
Some items like black suede shoes or bags or dark velvet shoes or bags really tend to suck up light and look like a silhouette of the item.  To fix this you can use the FILL LIGHT  but most the time a small amount is enough but not always.  If you find that you need to run up the FILL LIGHT to 50-60 you can use the BLACK slider to bring the shadows back to black. 


Detaliu deimantui prarasti neleidÅ¾ia ir panaudotas vietoje ir laiku "burn" tool'as. Ne tik paÅ¡viesindamas gali iÅ¡gauti optimalia deimanto iÅ¡vaizda, bet ir atitinkamas vietas patamsindamas. Tamsios vietos turi buti tamsios, Å¡viesios - Å¡viesios. Ir tos "vietos" turi buti stambios, kad deimanto raÅ¡tas matytusi net ir neprizoomintoje nuotraukoje.

Sulygiuoti nuotraukas tik jei noresiu ir liks laiko - Kundrotas nelygiuoja nei nuotrauku su ranka, nei su deÅ¾utemis. Vadinasi nekreips demesio i mano lygiavimus.

Jei aibeje nuotrauku kurias turi padaryti yra vienoda profili turinciu nuotrauku poaibiai - daryk kiekvienam poaibiui priklausancias nuotraukas vienu ypu. Taip pritaikysi pirmoje nuotraukoje suprastus dalykus iÅ¡karto kitoje ir t.t. Galiausiai pirma, o gal ir antra nuotrauka visvien teks kiek padailinti - darydamas poaibiais - iÅ¡karto Å¾inosi kaip tai padaryti.

Ne visada Saulius K. desaturatina deimantu remeli. Tada, kai Å¾iedas auksinis - gerai pagalvok ar reikia tai daryti. Kai deimantai graÅ¾iai atspindi pagrindinio akmens spalva - gerai pagalvok prieÅ¡ desaturatindamas.

PS: visiÅ¡kai sumaÅ¾inus brush hardness ir opacity galima pasiekti puiku deimanto aureoles efekta.

Trafaretas - pieÅ¡iniu dauginimo forma. Prasme identiÅ¡ka Å¾odÅ¾io "Å¡ablonas" ir vis labiau populerejancio Å¾odÅ¾io "templeitas" prasmems. 

What is a data wharehouse? In computing, a data warehouse or enterprise data warehouse (DW, DWH, or EDW) is a database used for reporting and data analysis. It is a central repository of data which is created by integrating data from one or more disparate sources. Data warehouses store current as well as historical data and are used for creating trending reports for senior management reporting such as annual and quarterly comparisons.

Concurency - In computer science, concurrency is a property of systems in which several computations are executing simultaneously, and potentially interacting with each other. The computations may be executing on multiple cores in the same chip, preemptively time-shared threads on the same processor, or executed on physically separated processors. A number of mathematical models have been developed for general concurrent computation including Petri nets, process calculi, the Parallel Random Access Machine model, the Actor model and the Reo Coordination Language. 

Kaip atskirti kuris daiktas yra pagindinis fotografijoje:
1. Ar daikto, kuris yra nepagrindinis nera daugiau su kitais daiktais (kelnes prie skirtingu megztiniu - tuomet megztiniai pagrindinia, kelnes Å¡alutiniai, pagalbiniai ir t.t.).
2. Jei daiktas pasirodo tik viena karta, kaip ir kitas, su juo esantis tai reikia paÅ¾iureti ar bent vienas iÅ¡ ju nera nukirptas kurioje nors iÅ¡ 2-5 foto (konkretus pavyzdys: pimoje foto megztinis su kelnemis, manekene visu kunu. Antroje, kad ir iÅ¡ galo - megztinio dalis nukirpta, kelnes reliatyviai priartintos - tai Å¾inoma, jog kelnes yra pagrindines tuomet);
3. Jei daikto pavadinime nurodyta spalva ir tik vienas daiktas nuotraukoje tokia turi.

Hormones that make you happy - seratonin. Biochemically derived from tryptophan, serotonin is primarily found in the gastrointestinal (GI) tract, platelets, and in the central nervous system (CNS) of animals including humans. It is popularly thought to be a contributor to feelings of well-being and happiness.Approximately 90% of the human body's total serotonin is located in the enterochromaffin cells in the alimentary canal (gut), where it is used to regulate intestinal movements.[6][7] The remainder is synthesized in serotonergic neurons of the CNS, where it has various functions. These include the regulation of mood, appetite, and sleep. Serotonin also has some cognitive functions, including memory and learning. Modulation of serotonin at synapses is thought to be a major action of several classes of pharmacological antidepressants.Serotonin secreted from the enterochromaffin cells eventually finds its way out of tissues into the blood. There, it is actively taken up by blood platelets, which store it. When the platelets bind to a clot, they disgorge serotonin, where it serves as a vasoconstrictor (vasoconstriction and pre-oragasm symphathetic and parasympathetic nervous systems - ar gali buti taip, jog mano pagrindine problema, gal net vienintele yra seratonino trukumas?) and helps to regulate hemostasis and blood clotting. Serotonin also is a growth factor for some types of cells, which may give it a role in wound healing. Seratonin is used by plants to cause diarrhea thus in turn causing the excretion of plants seeds. Serotonin can be released by getting exposed to sunlight, by eating foods rich in carbohydrates and by exercising.

Endorphins: Endorphins can make you feel good, reduce your anxiety and your sensitivity to pain. Endorphins are released by exercising.

Dopamine: Dopamine helps you to feel mentally alert. The lack of it might cause lack of attention, lack of concentration and bad moods. Dopamine can be released by eating foods that are rich in protein.

Phenylethamine: Phenylethamine is the hormone that results in the feelings we get in the early stages of a relationship. Cocoa beans contain Phenylethamine. eating chocolate might be helpful too.

Ghrelin: Gherlin is a hormone that reduces stress and can help you become more relaxed. Ghrelin is released when we become Hungary that's why eating too much is not always a good idea. Just eat according to your bodyâ€™s needs and never fill your stomach completely in order to maintain good Ghrelin levels.

The logical structure of medicine: Because of serotonin's growth-promoting effect on cardiac myocytes, persons with serotonin-secreting carcinoid may suffer a right heart (tricuspid) valve disease syndrome, caused by proliferation of myocytes onto the valve.

Laisvai galejai sugalvoti: Å¡tai, matau eile. Kokia matematine Å¾moniu laukianciu valgykloje struktura? Kaip galima butu optimizuoti eile taip, kad visa eile greiciau praeitu - Å¾inoti iÅ¡ anksto kiek kiekvienas eiles dalyvis (kiekvienas eiles dalyvas is much more general than "Å¾mogus") uÅ¾truks. Bet juk laikas prie kurio uÅ¾truks individai yra, bent jau tokia prielaida, konstanta - o kaip bemanipuliuotum konstantas visien ju suma bus vienoda. 

doubly-efficient solution: when two resources are simultaniously saved/increased with one change (in a way of acting, thinking etc.). E.g. search engines allow you to do more with less brain power. 

How to suppress warnings with @SuppressWarnings("deadCode") annotation?

Import images as layers - Bridge;

Managers think that billiant ideas is what is the most important, not work - this is how you recognize a manager. The signs of overmanaging are: (i) sophisticated report requirements (like the graphs and drawings in callcredit); (ii) all time spent in meetings (like in CC as well) where only the manager is doing his job, everyone else  is wasting time;

Agile {
	- knowledge is distributed, not centralized. So at some level, everyone in the team knows how something works / was implemented / where the challanges lie in the functionality. In ZU we have Dmitry, what, if he's hit by a bus would completelly ruine the whole project;
	- 
}





Peer programming {
	Against {
		- http://techcrunch.com/2012/03/03/pair-programming-considered-harmful/
		- Despite managersâ€™ dreams of programmers as fungible units (property of a good or a commodity whose individual units are capable of mutual substitution. For example, since one ounce of gold is equivalent to any other ounce of gold, gold is fungible.), itâ€™s nearly universally accepted that a great developer is ten times as productive as a mediocre one, and/or that a small team of the software equivalent of the Special Forces can code rings around an army of hundreds of grunts. The flip side is that one cowboy coderâ€™s bad decisions can cripple you â€” maybe immediately, or maybe next year, when you suddenly discover that your organization has quietly racked up so much technical debt that it has become the software equivalent of Greece.
		- The pit crew is probably the best example of highly efficient tem wor: https://www.youtube.com/watch?v=LOJbM0aXZp0
		- Legendary development shops like San Franciscoâ€™s Pivotal Labs and Torontoâ€™s Xtreme Labs(1) have adopted a 100 percent pair programming mindset, with considerable success.
		- â€œResearch strongly suggests that people are more creative when they enjoy privacy and freedom from interruption â€¦ What distinguished programmers at the top-performing companies wasnâ€™t greater experience or better pay. It was how much privacy, personal workspace and freedom from interruption they enjoyed,â€ says a New York Times article castigating â€œthe new groupthink.â€ It also quotes Steve Wozniak: â€œWork aloneâ€¦ Not on a committee. Not on a team.â€
		- â€œMost modern office layouts seem to be designed to screw with peopleâ€™s fight or flight instincts all day.â€ 
		- done extraordinary work on their own: Marco Arment of Instapaper, Gabriel Weinberg of DuckDuckGo, Notch of Minecraft. 

		- http://blog.codinghorror.com/pair-programming-vs-code-reviews/
		- Some say that code review, if done efficiently, is equivalnet to peer programming and that most of the benefits can be obtained.
		- Code reviews: One of the problems seems to be that nobody wants to spend the time to really understand new code that does anything non-trivial, so the feedback is usually very general. But later, when someone is working on the code to either add functionality or fix bugs, they usually have lots of feedback (sometimes involving large hammers), but then it may be too late to be effective; the programmer may not even be around. The advantage of pair programming is its gripping immediacy: it is impossible to ignore the reviewer when he or she is sitting right next to you. Most people will passively opt out if given the choice. With pair programming, that's not possible. Each half of the pair has to understand the code, right then and there, as it's being written. 
		- One reviewer/accepter model (like in Linux).
		- Make sure seniors let juniors program too when pairing
		- Don't let people pair on small tasks, usually wastes time
		- Watch how pairs get along (don't force a pair together)
		- Remeber to reshuffle the pairs every now and then
		- Don't let reviews bee an ego match - don't let people crush others
	}
}

TDD{
	- Against{
		- http://david.heinemeierhansson.com/2014/tdd-is-dead-long-live-testing.html
		- http://www.infoq.com/news/2014/06/tdd-dead-controversy
	}
}

Unit testing{
	- Against{
		- http://www.rbcs-us.com/documents/Why-Most-Unit-Testing-is-Waste.pdf
	}
}



XPATH {
	xs:date(current-dateTime()) - xs:dayTimeDuration("P90D");
	<Result>{fn:current-dateTime()}</Result>
	<foo>abc</foo> //foo/text()
	return data(//velocityread_warning_last_seen_cardnumber/text())

	TEST XML{
		<?xml version="1.0" encoding="UTF-8"?>

		<Results>

		  <Result PID="LTJ--2485-51403-24687-5" RID="">
		    <Displays>
		      <velocitywrite_completed>yes</velocitywrite_completed>
		      <velocitywrite_record_id>12</velocitywrite_record_id>
		      <velocitywrite_record_input_count>8</velocitywrite_record_input_count>
		      <velocitywrite_record_matched_count>8</velocitywrite_record_matched_count>

		    </Displays>
		  </Result>

		  <Result PID="LTJ--2485-51403-24687-5" RID="">
		    <Displays>
		      <velocitywrite_completed>yes</velocitywrite_completed>
		      <velocitywrite_record_id>12</velocitywrite_record_id>
		      <velocitywrite_record_input_count>8</velocitywrite_record_input_count>
		      <velocitywrite_record_matched_count>8</velocitywrite_record_matched_count>
		      <zodiac_starsign>Aquarius</zodiac_starsign>
		    </Displays>
		  </Result>

		</Results>
	}

	- //Displays
	- count(//Displays) -- count all 
	- count(//Results/Result/Displays/child::*) -- get the count of children nodes of Displays node
	- /root/foo:singers/* -- select all the children of the 'singers' node.
	- someElement/@id/string() -- get the string value from the ATTRIBUTE (@) (with xpath 2.0)

	- how to count the nodes of the response in a differet testcase
}

Goovy{
	General {
		- duck typing and the elvis operator (null coallescing version of ternary oerator "?:" ) is supported;
		- Groovy has list processing and regular expressions directly build into the language;
		- JAVA BEANS: They are serializable, have a 0-argument constructor, and allow access to properties using getter and setter methods. In Groovy all fields of a class have by default the access modifier "private" and Groovy provides automatically getter and setter methods for the fields. Therefore all Groovy classes are per default JavaBeans (Plain Old Java Objects).
		- You can use the getter and setter directly or use the name of the variable for access. Groovy will convert this to the getter and setter method.
	}

	Example {
		// get current time in groovy
		TimeZone.setDefault(TimeZone.getTimeZone('UTC'))
		def now = new Date()
		log.info now.format("yyyy-MM-dd HH:mm:ss")
		log.info now.format("yyyy/MM/dd-HH.mm.ss")

		//get substring from a particular char in groovy


		// get current London/Leeds time - script will be executed immediatelly after the test step
		def timeZone = TimeZone.getTimeZone('Europe/London');
		def dateFormat = 'yyyy-MM-dd HH:mm:ss';
		def date = Calendar.instance.time;
		def timeOfTheAssertion = date.format(dateFormat, timeZone);


		/*Generate account_number [6-10] diggits*/
			long account_number = (100_000 + ((long)Math.random() * 10_000_000_000 % 9_000_000_000));

		/*Generate year of birth*/
			String dateofbirth = Integer.toString(1900 + ((int)Math.random() * 1000 % 114));

		/*Generate emailaddress*/
			String validCharacters = "abcdefghijklmnopqrstuvwxyz";
			int validCharactersLength = validCharacters.length(); //26, so [0-25]

			//Random int 0 - 25 for beginIndex 
			int beginIndexForLocalPart = ((long)Math.random() * 100 % validCharactersLength - 1); // random number from [0-25]

			//Random int 0 - 25 for endIndex 
			int endIndexForLocalPart = (validCharactersLength + (long)Math.random() * 100 % (validCharactersLength - 1 - beginIndex));

			int beginIndexForDomainPart = ((long)Math.random() * 100 % validCharactersLength - 1); // random number from [0-25]
			int endIndexForDomainPart = (validCharactersLength + (long)Math.random() * 100 % (validCharactersLength - 1 - beginIndex));

			String localPart = validCharacters.substring(beginIndex,endIndex);
			String domainPart = validCharacters.substring(beginIndexForDomainPart,endIndexForDomainPart);
			String emailaddress = localPart + '@' + domainPart + '.com'


		/*get properties from testCase, testSuite and project*/
			def testCaseProperty = testRunner.testCase.getPropertyValue( "MyProp" )
			def testSuiteProperty = testRunner.testCase.testSuite.getPropertyValue( "MyProp" ) 
			def projectProperty = testRunner.testCase.testSuite.project.getPropertyValue( "MyProp" ) 
			def globalProperty = com.eviware.soapui.SoapUI.globalProperties.getPropertyValue( "MyProp" ) 

		/*accesing tescase properties inside scripted assertion*/

		/*setting values is equally straigh forward*/
			testRunner.testCase.setPropertyValue( "MyProp", someValue ) 
			testRunner.testCase.testSuite.setPropertyValue( "MyProp", someValue ) 
			testRunner.testCase.testSuite.project.setPropertyValue( "MyProp", someValue ) 
			com.eviware.soapui.SoapUI.globalProperties.setPropertyValue( "MyProp", someValue ) 

		/*getting a property from response XML/*
			def groovyUtils = new com.eviware.soapui.support.GroovyUtils(context)
			def response = context.expand('Check_That_Tables_Are_Populated_Correctly#Response')
			//def response = context.expand('${Check_That_Tables_Are_Populated_Correctly#Response}') //also works
			log.info ("response ::" + response)
			
			def holder = groovyUtils.getXmlHolder("response")
			log.info (holder)

		/*getting the name of the current step*/
			def tstep = testRunner.runContext.currentStep.name
			log.info(tstep)

		/*getting the reposonse XML inside a test step Script Assertion & TestStep*/
			log.info(context.getProperty("response"));


		/**/
			log.info(testRunner.testCase.testSuite.project.name);
			log.info(testRunner.testCase.testSuite.name);
			log.info(testRunner.testCase.name);
			log.info(testRunner.testCase.getName());
			log.info(context.getCurrentStep().getLabel());
	}
}




////////////////////////////////////// WAF, modsec, modsecurity, mod_security,

Contact for technical support: 
felipe@zimmerle.org

# Mod security
	ModSecurityEnabled on;
	ModSecurityConfig waf/php2-mindaugasb.c9.io.conf;
	ModSecurityXHeaders on;
	ModSecurityAllHeaders on;

# Debug log
  SecDebugLog /usr/local/openresty/nginx/logs/waf/mindaugas/debug.log
  SecDebugLogLevel 3 # can be up to 9 - for very verbose logging

[emerg] ModSecurity: No action id present within the rule
	add the id parameter 
	SecRule ARGS "MMM|mmm" "log,ctl:ruleEngine=On,id:1,status:402,phase:4"

##### Init config
	SecRuleEngine On
  
	SecRequestBodyAccess On
	SecRequestBodyLimit 1
	SecRequestBodyLimitAction ProcessPartial

	SecResponseBodyAccess Off
	SecResponseBodyMimeType (null) text/html text/plain text/xml
	SecResponseBodyLimit 2
	SecResponseBodyLimitAction ProcessPartial

	SecComponentSignature 200911012341
	SecUploadDir /var/asl/data/suspicious
	SecUploadKeepFiles Off
	SecAuditEngine RelevantOnly
	SecAuditLogRelevantStatus "^(?:5|4(?!04))"
	SecAuditLogType Serial
	SecAuditLog /usr/local/openresty/nginx/logs/waf/php2-mindaugasb.c9.io
	SecAuditLogParts ABH
	SecTmpDir /tmp
	SecAuditLogStorageDir /var/asl/data/audit

	SecServerSignature zulu-waf
	SecPcreMatchLimit 150000
	SecPcreMatchLimitRecursion 150000
	SecDataDir /var/asl/data/msa

##### Adding the simplest possible rule:
	SecRuleEngine On
	SecRequestBodyAccess Off
	SecResponseBodyAccess Off
	SecResponseBodyMimeType (null) text/html text/plain text/xml
	SecResponseBodyLimit 2621440
	SecServerSignature zulu-waf
	SecComponentSignature 200911012341
	SecUploadDir /var/asl/data/suspicious
	SecUploadKeepFiles Off
	SecAuditEngine On

	#RelevantOnly

	SecAuditLogRelevantStatus "^(?:5|4(?!04))"
	SecAuditLogType Serial
	SecAuditLog /usr/local/openresty/nginx/logs/waf/php-mindaugasb.c9.io
	SecAuditLogParts ABH
	SecDataDir /var/asl/data/msa
	SecTmpDir /tmp
	SecAuditLogStorageDir /var/asl/data/audit
	SecResponseBodyLimitAction Reject

	# Debug log
	SecDebugLog /usr/local/openresty/nginx/logs/waf/mindaugas/debug.log
	SecDebugLogLevel 9

	SecRule ARGS "MMM" "phase:1, log, ctl:ruleEngine=On, id:1, status:403, logdata:'Mindaugas Test logdata', msg:'Mindaugas Test msg'"


# With this layout I get interesting results:
	SecRule ARGS "M\d{1,2}" "phase:1, log, id:1, status:401, logdata:'Mindaugas Test logdata', msg:'Mindaugas Test msg'"
	SecRule ARGS "M\d{1,2}" "phase:1, log, deny, id:2, status:402, logdata:'Mindaugas Test logdata', msg:'Mindaugas Test msg'"

	# both id=1 and id=2 errors are logged - as they should be - but in one log record. It is probably the same in Core Rule Set (CRS) - but need to check.
	Message: Warning. Pattern match "M\\d{1,2}" at ARGS:a. [file "/usr/local/openresty/nginx/conf/waf/php-mindaugasb.c9.io.conf"] [line "22"] [id "1"] [msg "Mindaugas Test msg"] [data "Mindaugas Test logdata"]
	Message: Access denied with code 402 (phase 1). Pattern match "M\\d{1,2}" at ARGS:a. [file "/usr/local/openresty/nginx/conf/waf/php-mindaugasb.c9.io.conf"] [line "23"] [id "2"] [msg "Mindaugas Test msg"] [data "Mindaugas Test logdata"]


# With this layout I get this:
	Message: Warning. Pattern match "M\\d{1,2}" at ARGS:a. [file "/usr/local/openresty/nginx/conf/waf/php-mindaugasb.c9.io.conf"] [line "22"] [id "1"] [msg "Mindaugas Test msg id1"] [data "Mindaugas Test logdata id1"]
	Message: Access denied with code 402 (phase 1). Pattern match "M\\d{1,2}" at ARGS:a. [file "/usr/local/openresty/nginx/conf/waf/php-mindaugasb.c9.io.conf"] [line "23"] [id "2"] [msg "Mindaugas Test msg id2"] [data "Mindaugas Test logdata id2"]


# Collaborative Detection a.k.a. Delayed Blocking a.k.a. Decoupling inspection and blocking

	SecAction "id:55,phase:1,t:none,nolog,pass,setvar:tx.critical_anomaly_score=5,setvar:tx.error_anomaly_score=4,setvar:tx.warning_anomaly_score=3,setvar:tx.notice_anomaly_score=2"

	SecRule ARGS "M\d{1,2}" "phase:1, log, pass, id:1, severity:'1', setvar:tx.score_1=+%{tx.critical_anomaly_score}, setvar:tx.score_2=+%{tx.critical_anomaly_score}, logdata:'Mindaugas Test logdata id1', msg:'Mindaugas Test msg id1'"
	SecRule ARGS "M\d{1,2}" "phase:1, log, pass, id:2, severity:'1', setvar:tx.score_1=+%{tx.critical_anomaly_score}, setvar:tx.score_2=+%{tx.critical_anomaly_score}, logdata:'Mindaugas Test logdata id2', msg:'Mindaugas Test msg id2'"
	SecRule ARGS "M\d{1,2}" "phase:1, log, pass, id:3, severity:'1', setvar:tx.score_1=+%{tx.critical_anomaly_score}, setvar:tx.score_2=+%{tx.critical_anomaly_score}, logdata:'Mindaugas Test logdata id3', msg:'Mindaugas Test msg id3'"


# This is the result with
	Message: Warning. Pattern match "M\\d{1,2}" at ARGS:a. [file "/usr/local/openresty/nginx/conf/waf/php-mindaugasb.c9.io.conf"] [line "29"] [id "1"] [msg "Mindaugas Test msg id1"] [data "Mindaugas Test logdata id1"] [severity "ALERT"]
	Message: Warning. Pattern match "M\\d{1,2}" at ARGS:a. [file "/usr/local/openresty/nginx/conf/waf/php-mindaugasb.c9.io.conf"] [line "30"] [id "2"] [msg "Mindaugas Test msg id2"] [data "Mindaugas Test logdata id2"] [severity "ALERT"]
	Message: Warning. Pattern match "M\\d{1,2}" at ARGS:a. [file "/usr/local/openresty/nginx/conf/waf/php-mindaugasb.c9.io.conf"] [line "31"] [id "3"] [msg "Mindaugas Test msg id3"] [data "Mindaugas Test logdata id3"] [severity "ALERT"]


# severity levels
	0 EMERGENCY
	1 ALERT
	2 CRITICAL
	3 ERROR
	4 WARNING
	5 NOTICE
	6 INFO
	7 DEBUG


# Blocking in Collaborative Detection a.k.a. Delayed Blocking a.k.a. Decoupling inspection and blocking
	We have two different anomaly scoring thresholds to set - one for the inbound request (which is evaluated at the end of phase:2 in the modsecurity_crs_49_inbound_blocking.conf file) 
	and one for outbound information leakages (which is evaluated at the end of phase:4 in the modsecurity_crs_50_outbound_blocking.conf file)


# My setup

	# modSecurity conf file, generated at waf/<website>.conf. Include custom waf rules template.

	SecRuleEngine On
	SecRequestBodyAccess Off
	SecResponseBodyAccess Off
	SecResponseBodyMimeType (null) text/html text/plain text/xml
	SecResponseBodyLimit 2621440
	SecServerSignature zulu-waf
	SecComponentSignature 200911012341
	SecUploadDir /var/asl/data/suspicious
	SecUploadKeepFiles Off
	SecAuditEngine RelevantOnly
	SecAuditLogRelevantStatus "^(?:5|4(?!04))"
	SecAuditLogType Serial
	SecAuditLog /usr/local/openresty/nginx/logs/waf/php-mindaugasb.c9.io
	SecAuditLogParts ABH
	SecDataDir /var/asl/data/msa
	SecTmpDir /tmp
	SecAuditLogStorageDir /var/asl/data/audit
	SecResponseBodyLimitAction Reject

	# Debug log
		SecDebugLog /usr/local/openresty/nginx/logs/waf/mindaugas/debug.log
		SecDebugLogLevel 9

	# Unconditional rule to set the necessary variables
	SecAction "id:101, phase:1,t:none,nolog,pass,setvar:tx.critical_anomaly_score=5,setvar:tx.error_anomaly_score=4,setvar:tx.warning_anomaly_score=3,setvar:tx.notice_anomaly_score=2"

	# Setting Scoring Threshold Levels
		# SecAction "id:102, phase:1,t:none,nolog,pass,setvar:tx.inbound_anomaly_score_level=2"
		# SecAction "id:103, phase:1,t:none,nolog,pass,setvar:tx.outbound_anomaly_score_level=4"

	# Enabling blocking based on anomaly score
		# SecAction "id:104, phase:1,t:none,nolog,pass,setvar:tx.anomaly_score_blocking=on"

	# Alert and Block based on anomaly scores
		# SecRule TX:SCORE_1 "@ge 10" "id:105, phase:2,t:none,log,ctl:ruleEngine={{mode}},status:402, msg:'Mindaugas direct injection detected with (score %{TX.score_1}): %{tx.msg} and score %{TX.score_2}'"


	# Collaborative Detection a.k.a. Delayed Blocking a.k.a. Decoupling inspection and blocking
	# SecRule ARGS "M\d{1,2}" "phase:2, log, ctl:ruleEngine=DetectionOnly, id:1, severity:'1', setvar:tx.score_1=+%{tx.critical_anomaly_score}, setvar:tx.score_2=+%{tx.critical_anomaly_score}, logdata:'Mindaugas Test logdata id1', msg:'Mindaugas Test msg id1'"
	SecRule ARGS "M\d{1,2}" "phase:2, log, pass, id:1, severity:'1', setvar:tx.score_1=+%{tx.critical_anomaly_score}, setvar:tx.score_2=+%{tx.critical_anomaly_score}, logdata:'Mindaugas Test logdata id1', msg:'Mindaugas Test msg id1'"
	#SecRule ARGS "M\d{1,2}" "phase:2, log, ctl:ruleEngine=On,deny, id:2, severity:'1', setvar:tx.score_1=+%{tx.critical_anomaly_score}, setvar:tx.score_2=+%{tx.critical_anomaly_score}, logdata:'Mindaugas Test logdata id2', msg:'Mindaugas Test msg id2'"
	SecRule ARGS "M\d{1,2}" "phase:2, log, pass, id:3, severity:'1', setvar:tx.score_1=+%{tx.critical_anomaly_score}, setvar:tx.score_2=+%{tx.critical_anomaly_score}, logdata:'Mindaugas Test logdata id3', msg:'Mindaugas Test msg id3'"

	# Alert and Block based on anomaly scores
	SecRule TX:SCORE_1 "@ge 10" "id:105, phase:2,t:none,log,deny, status:402, msg:'Mindaugas direct injection detected with (score %{TX.score_1}): %{tx.msg} and score %{TX.score_2}'"

	# Test that rules are processed till block is reached
	#SecRule ARGS "M\d{1,2}"	"phase:1, log, id:1, logdata:'Mindaugas Test logdata id1', msg:'Mindaugas Test msg id1'"
	#SecRule ARGS "M\d{1,2}"	"phase:1, log, deny, id:2, status:402, logdata:'Mindaugas Test logdata id2', msg:'Mindaugas Test msg id2'"
	#SecRule ARGS "M\d{1,2}" 	"phase:1, log, id:3, logdata:'Mindaugas Test logdata id3', msg:'Mindaugas Test msg id3'"

	# IP rate limiting rule - no buffering, no sliding window, dumb rule.
	SecAction initcol:ip=%{REMOTE_ADDR},phase:1,id:101,nolog,pass
		SecRule REQUEST_URI "^/js" "phase:1,id:102,t:none,pass,setvar:IP.access=+1,expirevar:IP.access=10"
		SecRule IP:access "@gt 3" "phase:1,id:103,deny"

	SKIPAFTER EXAMPLE {

		SecRule REQUEST_COOKIES|!REQUEST_COOKIES:/__utm/|!REQUEST_COOKIES:/_pk_ref/|REQUEST_COOKIES_NAMES|ARGS_NAMES|ARGS|XML:/* "@pm jscript onsubmit copyparentfolder document javascript meta onchange onmove onkeydown onkeyup activexobject onerror onmouseup ecmascript bexpression onmouseover vbscript: <![cdata[ http: .innerhtml settimeout shell: onabort asfunction: onkeypress onmousedown onclick .fromcharcode background-image: x-javascript ondragdrop onblur mocha: javascript: onfocus lowsrc getparentfolder onresize @import alert script onselect onmouseout application onmousemove background .execscript livescript: vbscript getspecialfolder .addimport iframe onunload createtextrange <input onload" \
		       "phase:2,id:'981136',rev:'2',ver:'OWASP_CRS/2.2.9',maturity:'8',accuracy:'8',t:none,t:htmlEntityDecode,t:compressWhiteSpace,t:lowercase,pass,nolog,setvar:tx.pm_xss_score=+%{tx.critical_anomaly_score},setvar:'tx.xss_anomaly_matches=%{tx.xss_anomaly_matches} keyword: [%{matched_var}] in [%{matched_var_name}];',\
		       logdata:'XSS'"
		SecRule &TX:PM_XSS_SCORE "@eq 0" "phase:2,id:'981018',t:none,pass,skipAfter:END_XSS_CHECK,nolog"
		SecRule ARGS "MMM" "phase:2, log, id:1, pass, logdata:'Mindaugas Test logdata', msg:'Mindaugas Test msg'"	

	} take note the skipAfter applies only to the phase specified in the rule that controls the skipping, in this case 981018.

	PCRE LIMITS ERROR PROBLEM {

		- http://www.pret.com/pret/content/font-awesome?v=QqiES8bMVFD1YGmU_C7h6nsgr358Xu-gbi4VJ0NwJNs1 	===> req
		- SecPcreMatchLimit 15 // SecPcreMatchLimitRecursion 15 										===> triggers the flag 4 times!
		- Other rules also trigger the issue, like this one: 981256 	

			# SecRule TX:MSC_PCRE_LIMITS_EXCEEDED "!@streq 0" "id:'200005',phase:4,t:none,deny,msg:'ModSecurity internal error flagged: %{MATCHED_VAR_NAME}'"
			SecRule TX:/^MSC_/ "!@streq 0" "id:'2000052',phase:4,t:none,deny,msg:'ModSecurity internal error flagged: %{MATCHED_VAR_NAME}'"
			SecRule !REQUEST_COOKIES:/^appl1_.*/" 														===> mathing args with regex;

	}

	NEW FORMAT {	
		-- add a new line separating regexes and actions
		" "
		" \\\n"

		-- add a new line for all the actions of a WAF rule
		(?<!\.|:),(?=[^\d\s}-])
		, \\\n

		-- select many spaces (some rules have them)
		^\s{2,}

		-- select all lines to be indented with tabs (have to be case sensitive)
		(?=^[^S|#]|^s)
		\t
	}

	WAF QUICK TOOL {

		Rules:
		- SecRule REQUEST_HEADERS:Content-Type "boundary=\S{2048,}" "phase:1,id:2,t:none,msg:'Content-type header exceeded the allowed lenght',log,deny,status:401"  ===> block by header size;
		- 


		# curl -s -D - -o /dev/null http://php2-mindaugasb.c9.io?A=C

		SecRule REQUEST_HEADERS:User-Agent \
			"@rx ^(?:Mozilla/5.0 examples AlertSite Monitor|Mozilla/5.0 Moovweb Platform)$" \
		    "phase:1,t:none,pass,log, \
		    ctl:ruleRemoveTargetById=2;ARGS:A, \
		    ctl:ruleEngine=On, \
		    id:1"

		SecRule ARGS "C" \
			"phase:1,t:none,log, \
			ctl:ruleEngine=On, \
			id:2" 
		#SecRuleUpdateTargetById 2 !ARGS:E,!ARGS:B,!ARGS:A

		# SecRule ARGS "D" \
		#    "phase:1,t:none,log, \
		#    ctl:ruleEngine=On, \
		#    id:3"
		# SecRuleUpdateTargetById 3 !ARGS:E,!ARGS:B,!ARGS:A

		# SecRule ARGS "E" \
		#      "phase:1, \
		#      id:4, \
		#      ctl:ruleEngine=On, \
		#      chain"
		#  SecRule REQUEST_METHOD "GET"
		# SecRuleUpdateTargetById 4 !ARGS:E,!ARGS:B,!ARGS:A

		# SecRule REQUEST_METHOD "GET" \
		#      "phase:1, \
		#      id:5, \
		#      ctl:ruleEngine=On, \
		#      chain"
		#   SecRule ARGS "E"    
		# SecRuleUpdateTargetById 5 !ARGS:P
	}

	PROFILING RULE BY RULE {
		SecRulePerfTime 5 						===> the only profiling one needs, outputs this result (in microseconds): \
															Rules-Performance-Info: "900018=10", "973300=38", "973302=25139966".
		SecRule PERF_PHASE2 "@gt 10" "id:1234,phase:3"
		SecRule PERF_RULES "@gt 10" "id:1,phase:3"
	}

	GET ALL WAF RULE ID'S {
		-- (?<=id:')\d+
		-- find . -type f -name "*.conf" -exec cat '{}' + > ~/Desktop/commercial_rules.txt 							===> get all rules from commercial rule repo;
	}

	LUA with MODSEC {

		- SecRuleScript "/home/zulu/Mindaugas_Scripts/Lua/test-lua-with-waf.lua" "ctl:ruleEngine=DetectionOnly" 	===> logs this: "--1fbf7338-H-- Message: Hello world! ..."
		- http://www.modsecurity.org/developers/#UseLua 															===> references 
		- https://github.com/SpiderLabs/owasp-modsecurity-crs/tree/v2.2/master/lua 									===> many scripts
	
	}

	Client provisioning {
		- All rules IBL {
			https://dojo.zulu.com/www-isotoner-com/waf_logs?utf8=âœ“&rule_ids[]=981078&rule_ids[]=920019&rule_ids[]=920005&rule_ids[]=920007&rule_ids[]=920009&rule_ids[]=920011&rule_ids[]=920013&rule_ids[]=920015&rule_ids[]=920017&rule_ids[]=981080&rule_ids[]=920020&rule_ids[]=920006&rule_ids[]=920008&rule_ids[]=920010&rule_ids[]=920012&rule_ids[]=920014&rule_ids[]=920016&rule_ids[]=920018&rule_ids[]=920021&rule_ids[]=920022&rule_ids[]=920023&rule_ids[]=960011&rule_ids[]=960017&rule_ids[]=950012&rule_ids[]=950910&rule_ids[]=950911&rule_ids[]=960015&rule_ids[]=960021&rule_ids[]=960904&rule_ids[]=960007&rule_ids[]=960008&rule_ids[]=960009&rule_ids[]=960006&rule_ids[]=960034&rule_ids[]=960014&rule_ids[]=950006&rule_ids[]=950907&rule_ids[]=950011&rule_ids[]=950002&rule_ids[]=950005&rule_ids[]=2250117&rule_ids[]=2250118&rule_ids[]=2250119&rule_ids[]=2250120&rule_ids[]=2250121&rule_ids[]=950117&rule_ids[]=950120&rule_ids[]=958000&rule_ids[]=958416&rule_ids[]=958005&rule_ids[]=973300&rule_ids[]=973301&rule_ids[]=973302&rule_ids[]=958001&rule_ids[]=973310&rule_ids[]=973337&rule_ids[]=973303&rule_ids[]=973307&rule_ids[]=973338&rule_ids[]=973304&rule_ids[]=973305&rule_ids[]=973306&rule_ids[]=973336&rule_ids[]=958002&rule_ids[]=981136&rule_ids[]=958018&rule_ids[]=958019&rule_ids[]=958057&rule_ids[]=958009&rule_ids[]=958031&rule_ids[]=958051&rule_ids[]=958032&rule_ids[]=958045&rule_ids[]=958046&rule_ids[]=950007&rule_ids[]=950001&rule_ids[]=959070&rule_ids[]=959071&rule_ids[]=959072&rule_ids[]=950908&rule_ids[]=959073&rule_ids[]=981256&rule_ids[]=981244&rule_ids[]=981245&rule_ids[]=981246&rule_ids[]=981250&rule_ids[]=981260&rule_ids[]=981318&domains[]=&ips[]=&time=30_d&period[from]=Jul 10, 2015 23:59&period[to]=Jun 18, 2015 00:00&per_page=250
		}
	}

//////////////////////////////////////

Pagespeed testing {
	- How to check the pagespeed version? 			---> /usr/local/openresty/nginx/logs/error.log will indicate
	- How to enable pagespeed admin 				---> https://developers.google.com/speed/pagespeed/module/admin
	- https://www.youtube.com/watch?v=z8FH5inqAe8 	---> and check the youtube for movies
	- sudo touch /var/cache/pagespeed/cache.flush 	---> does not work (seems like it);
	- you can delete the folder in the server with rm -r <> and > check what happened and whether the same happens when purging by regular means;

	- curl 'http://stage2zulu.net/pagespeed_admin/cache?purge=*'

	- https://developers.google.com/speed/pagespeed/module/system#purge_cache
	- Caution: Flushing or purging the cache does not delete the old files from the directory, the memcached server, or PageSpeed's in-memory cache, but it tells PageSpeed to ignore those files. Note: After flushing or purging the cache, the stale files will eventually be replaced with fresh copies or removed by the normal file cache cleaning process (see FileCacheCleanIntervalMs above).
	}

	- TO DO {
		- global admin;
		- real time stats;
		- understand the structure of cacheing;
		- create a scenario of how to prove that resources are purged one by one;
		- answer the questions I wrote down on paper;
	}

}

///////////////////////


# Begin Mindaugas Adds global admin 1

pagespeed Statistics on;
pagespeed StatisticsLogging on;
StatisticsLoggingIntervalMs 1000;

pagespeed LogDir /usr/local/openresty/nginx/logs/pagespeed;

pagespeed AdminPath /pagespeed_global_admin;
  

location /ngx_pagespeed_statistics { allow 127.0.0.1; deny all; }
location /ngx_pagespeed_global_statistics { allow 127.0.0.1; deny all; }
location /ngx_pagespeed_message { allow 127.0.0.1; deny all; }
location /pagespeed_console { allow 127.0.0.1; deny all; }
location ~ ^/pagespeed_admin { allow 127.0.0.1; deny all; }

# End Mindaugas Adds global admin 1


Two files:
http://stage2.zulu.net/wp-content/themes/twentyfourteen/js/functions.js?ver=20140616
http://stage2.zulu.net/wp-includes/js/jquery/jquery-migrate.min.js?ver=1.2.1

Result in this one file:
http://stage2.zulu.net/wp-includes,_js,_jquery,_jquery-migrate.min.js,qver==1.2.1+wp-content,_themes,_twentyfourteen,_js,_functions.js,qver==20140616.pagespeed.jc.CCiFTdevip.js


Purge all: curl 'http://stage2.zulu.net/pagespeed_admin/cache?purge=*'
Purge one: curl 'http://stage2.zulu.net/pagespeed_admin/cache?purge=/wp-includes/js/jquery/jquery-migrate.min.js?ver=1.2.1'

Count all lines in pagespeed_cache/website dir: ls -lahtR stage2.zulu.net/ | grep . -c
Check total size of the cache directory: du -ch stage2.zulu.net/ | grep total ---> all the same after purge all is done;

# Begin Mindaugas Adds admin --> GLOBAL --> pagespeed.conf --> there is no such file --> ???
	## Pagespeed in nginx.conf 
	## genreal configuration
	pagespeed on;
	pagespeed Statistics on; # collects cross-process statistics. Not recomended to turn them off as impact on perf. minimal
	pagespeed StatisticsLogging on;
	pagespeed StatisticsLoggingIntervalMs 1000;
	pagespeed LogDir /usr/local/openresty/nginx/logs/pagespeed;
	# pagespeed LRUCacheKbPerProcess     8192;
	# pagespeed LRUCacheByteLimit        16384;
	pagespeed UsePerVhostStatistics on; # GLOBAL --> stats per v-host, aggregates can still be seen in /pagespeed_global_admin
	pagespeed MessageBufferSize 100000; # buffer for page speed log messages, default is zero
	pagespeed CreateSharedMemoryMetadataCache "/usr/local/openresty/nginx/pagespeed_cache" 51200;
	# pagespeed FetchHttps enable;  # 

	## Pagespeed tools
	pagespeed StatisticsPath /ngx_pagespeed_statistics;
	pagespeed GlobalStatisticsPath /ngx_pagespeed_global_statistics;
	pagespeed MessagesPath /ngx_pagespeed_message;
	pagespeed ConsolePath /pagespeed_console;
	pagespeed AdminPath /pagespeed_admin;
	pagespeed GlobalAdminPath /pagespeed_global_admin;
# End Mindaugas Adds admin --> LGLOBALOCAL 




# Begin Mindaugas Adds admin --> LOCAL
	## Pagespeed in server scope
	pagespeed MaxCombinedJsBytes 1000000; #Default 92160 (90K)
	pagespeed EnableCachePurge on;

	## Pagespeed filters - Core & non-core
	pagespeed DisableFilters rewrite_images;
	pagespeed DisableFilters add_head;
	pagespeed DisableFilters inline_images,jpeg_subsampling;
	pagespeed EnableFilters combine_javascript;
	pagespeed DisableFilters add_instrumentation; # injects two small js's which report time of each page load back to the server
	pagespeed DisableFilters recompress_images; # group filter
	pagespeed DisableFilters remove_comments;
	pagespeed DisableFilters collapse_whitespace;
	pagespeed DisableFilters trim_urls;
	pagespeed DisableFilters insert_dns_prefetch;
	pagespeed DisableFilters dedup_inlined_images;

	# pagespeed CacheFlushFilename <path_to_cache_file>
	# pagespeed CacheFlushPollIntervalSec <number_of_seconds>;

	location ~ ^/pagespeed_admin {
	  allow 127.0.0.1;
	  deny all;
	}

	# inside the location / {} block; ---> PageSpeed servers for downstream caching
	pagespeed DownstreamCachePurgeLocationPrefix http://localhost:80;
	pagespeed DownstreamCachePurgeMethod PURGE;
	pagespeed DownstreamCacheRewrittenPercentageThreshold 95;

# End Mindaugas Adds admin --> LOCAL



zulTAG TESTING {

	1. Static ZT
	2. Dynamic ZT
	3. Static with JS callback
	4. Dynamic with JS callback
	
	<!--zulTAG:BEGIN:MB_TEST_1-->
	<p style=â€padding-left: 30px;â€><strong>zulTag content</strong></p>
	<p style=â€padding-left: 30px;â€><em> This is dynamic content, that is generated separately for each user and is not be globally cached, but is loaded via zultags instead.</em>
	</p>

	[insert_php]
	echo "Your session is: <br>";
	print_r($_COOKIE["__zulu_session"]);
	[/insert_php]

	<!--zulTAG:END:MB_TEST_1-->



	<div class"div_1" id="div_1_1" style="display:none">
          <img src="watch_1.jpg"></img>
      </div>

	<script src="//ajax.googleapis.com/ajax/libs/jquery/2.1.1/jquery.min.js"></script>
	<script>
	// function to show the initially hidden DIV
	function show_div_by_id(div_id){
		var id = '#' + div_id;
		$(id).show();
	}

	show_div_by_id("div_1_1");
	</script>

	- for i in {1..100}; do curl -s -D - rc.zulu.com -o /dev/null | grep . ; done;
}

- add a newer cache rule that would exclude most / all content from being cached (constains "wp")
- add a rule to cache all content ---> /

- inspect Redis DB {
	- select 2 	---> the database that contains ZT) by process of guessing;
	- KEYS * 	---> get all the keys;
	- GET <KEY> ---> get the value for the key;
} 



//////////////// Rollbar RQL


SELECT *
FROM item_occurrence
WHERE server.host like '%RC%'
ORDER BY timestamp DESC

/////////////////////// Simple webapp (virtual host) set up

upstream php1-mindaugasb.c9.io_http {
    # Origin servers
    server php-mindaugasb.c9.io:80 weight=1;
}

#server {
#  listen 80 default_server;
#  server_name _ "" ; 
#  return 402;
#}

server {
  listen 127.0.0.31:80;
  server_name m.com;
  #access_log logs/php2-mindaugasb.c9.io_access.log cache;
  #error_log logs/php2-mindaugasb.c9.io_error.log;

  # Mod security 
  ModSecurityEnabled on;
  ModSecurityConfig waf/php2-mindaugasb.c9.io.conf;
  ModSecurityXHeaders on;
  ModSecurityAllHeaders on;

  location /a {
    proxy_pass http://php2-mindaugasb.c9.io_http;
    proxy_set_header Host 'php-mindaugasb.c9.io';
  }

   location / {
    # root /usr/local/openresty/nginx;
    # proxy_set_header Accept-Encoding "";
  }
}

/////////////////// stub_status

	location /first_nginx_status {
		stub_status on;
	}

	location /second_nginx_status {
		stub_status on;
	}

	location /third_nginx_status {
		stub_status on;
	}

/////////////////////// Multi-server-block configuration file


	# Template: sys_template_basic_v10
	# Regenerated at: 2015-09-23 14:28:52 UTC
	# Web app name: php2-mindaugasb.c9.io
	proxy_cache_path cache/php2-mindaugasb.c9.io levels=2:2 keys_zone=php2-mindaugasb.c9.io:100m inactive=60d max_size=10g;
	upstream php2-mindaugasb.c9.io_http {
	  # Origin servers
	  server php2-mindaugasb.c9.io:80 weight=1;
	  # Backup servers
	  # Health check
	  # keepalive 16;
	}

	# upstream php2-mindaugasb.c9.io_https {
	#   # HTTPS Origin servers
	#   server php2-mindaugasb.c9.io:443 weight=1;
	#   # HTTPS Backup servers
	#   # Health check
	#   keepalive 16;
	# }

	server {

	  # TRIGGERS ERROR LOG IN WEEBAPP_ERROR.LOG FILE
	  # access_by_lua '
	  #   if ngx.var.remote_addr ~= "84.46.239.180" then
	  #      ngx.log(ngx.ERR, "ZZZZZZZZZZZZZZZZZZZZ")
	  #      ngx.exit(ngx.HTTP_INTERNAL_SERVER_ERROR)
	  #   end  
	  # ';

	  listen 80;
	  listen 8000 proxy_protocol;
	  listen 443 ssl;
	  listen 8443 ssl proxy_protocol;
	  listen 9443 ssl proxy_protocol;
	  listen 9000 proxy_protocol;
	  server_name php2-mindaugasb.c9.io php-mindaugasb.c9.io;
	  access_log logs/php2-mindaugasb.c9.io_access.log cache;
	  error_log logs/php2-mindaugasb.c9.io_error.log;

	  # Mod security
	  ModSecurityEnabled on;
	  ModSecurityConfig waf/php2-mindaugasb.c9.io.conf;
	  ModSecurityXHeaders on;
	  ModSecurityAllHeaders on;
	  set $PassScheme $scheme;
	  set $CDNheader "Served-By-zulu";

	  # Caching rules
	  # location ~* .(js|jpg)$ {
	  #   proxy_pass $PassScheme://php2-mindaugasb.c9.io_$PassScheme;
	  #   proxy_set_header Host $host;
	  #   proxy_cache php2-mindaugasb.c9.io;
	  #   proxy_cache_key "$scheme://$host$request_uri";
	  #   proxy_cache_valid 200 5m;
	  #   proxy_cache_use_stale error timeout invalid_header updating http_500 http_502 http_503 http_504;
	  #   more_set_headers "X-Cache-Status: $upstream_cache_status";
	  #   proxy_set_header X-Forwarded-For $remote_addr;
	  #   proxy_hide_header Set-Cookie;
	  #   proxy_hide_header Vary;
	  #   proxy_set_header Accept-Encoding "";
	  #   add_header X-Cdn $CDNheader;
	  # }

	  location / {
	    proxy_pass $PassScheme://php2-mindaugasb.c9.io_$PassScheme;
	    proxy_set_header Host $host;
	    proxy_set_header X-Forwarded-For $remote_addr;
	    add_header X-Cdn $CDNheader;
	    proxy_hide_header Vary;
	    proxy_set_header Accept-Encoding "";
	    add_header X-Cache-Status "NOTCACHED";
	    proxy_http_version 1.1;
	    proxy_set_header Connection "";
	  }
	}

	server {
	  listen 80;
	  listen 8000 proxy_protocol;
	  listen 443 ssl;
	  listen 8443 ssl proxy_protocol;
	  listen 9443 ssl proxy_protocol;
	  listen 9000 proxy_protocol;
	  server_name b.c9.io;
	  access_log logs/php2-mindaugasb.c9.io_access.log cache;
	  error_log logs/php2-mindaugasb.c9.io_error.log;
	  rewrite ^(.*) $scheme://php2-mindaugasb.c9.io$1 last;
	}



	# # Template: sys_template_lua_v9
	# # Regenerated at: 2015-09-23 12:02:26 UTC
	# # Web app name: php2-mindaugasb.c9.io
	# proxy_cache_path cache/php2-mindaugasb.c9.io levels=2:2 keys_zone=php2-mindaugasb.c9.io:100m inactive=60d max_size=10g;
	# upstream php2-mindaugasb.c9.io_zultags_http {
	#   server 127.0.0.1:804;
	# }

	# upstream php2-mindaugasb.c9.io_cache_http {
	#   server 127.0.0.1:803;
	# }

	# upstream php2-mindaugasb.c9.io_http {
	#   server 127.0.0.1:60080;
	# }

	# # DDoS (1)
	# server {
	#   listen 80;
	#   listen 8000 proxy_protocol;
	#   server_name php2-mindaugasb.c9.io php-mindaugasb.c9.io;
	#   access_log logs/php2-mindaugasb.c9.io_access.log cache_with_fingerprint if=$loggable;
	#   error_log logs/php2-mindaugasb.c9.io_error.log;
	#   set $PassScheme "http";
	#   set $zul_upstream "zultags";
	#   # global variables.
	#   set $zul_fingerprint '';
	#   set $CDNheader "Served-By-zulu";
	#   set $zul_cache_type "file";
	#   set $zul_headers "";
	#   location / {
	#     try_files $uri @access_ddos;
	#   }
	#   location @access_ddos {
	#     # Specifies that a given location can only be used for internal (nginx) requests.
	#     # For external requests, the client error 404 (Not Found) is returned.
	#     internal;
	#     add_header X-Cdn $CDNheader;
	#     log_by_lua_file ../lua-zulu/handlers/src/log.lua;
	#     rewrite_by_lua_file ../lua-zulu/handlers/src/rewrite.lua;
	#     access_by_lua_file ../lua-zulu/handlers/src/access.lua;
	#     content_by_lua_file ../lua-zulu/handlers/src/content.lua;
	#   }
	# }

	# # zultags (2)
	# server {
	#   listen 127.0.0.1:804;
	#   set_real_ip_from 127.0.0.1;
	#   real_ip_header X-Forwarded-For;
	#   # Domains
	#   server_name php2-mindaugasb.c9.io php-mindaugasb.c9.io;
	#   error_log logs/php2-mindaugasb.c9.io_error.log;
	#   set $PassScheme "http";
	#   set $zul_upstream "cache";
	#   # zulTags configuration
	#   set $session_name '__zulu_session';
	#   set $session_secret '//cq02gVYBYIYPJ8m8YwC/qtE4UH+dBcE41Fg0xwMxA=';
	#   # Run lua processing. Except if a matching static file is found in node nginx server html root,
	#   # in which case we directly serve that file.
	#   location / {
	#     try_files $uri @process;
	#   }
	#   # This rule replaces zultag placeholders with zultag fetching javascript in cached upstream content
	#   location @process {
	#     # Specifies that a given location can only be used for internal (nginx) requests.
	#     # For external requests, the client error 404 (Not Found) is returned.
	#     internal;
	#     content_by_lua_file ../lua-zulu/zultags/src/zt_request_gateway.lua;
	#   }
	#   # This is a proxy rule that fetches cached upstream content
	#   location = /@upstream {
	#     # Specifies that a given location can only be used for internal (nginx) requests.
	#     # For external requests, the client error 404 (Not Found) is returned.
	#     internal;
	#     set $upstream_uri $upstream_uri;
	#     # Proxy to upstream, caching the result
	#     proxy_pass $PassScheme://php2-mindaugasb.c9.io_cache_$PassScheme$upstream_uri;
	#     proxy_set_header Host $host;
	#     proxy_set_header X-Forwarded-For $remote_addr;
	#     proxy_hide_header Server;
	#     proxy_hide_header Vary;
	#     proxy_set_header Accept-Encoding "";
	#   }
	#   # zultag dynamic content data fetcher
	#   location /__zulu/zultags/fetch_tags {
	#     default_type 'application/json';
	#     content_by_lua_file ../lua-zulu/zultags/src/zt_fetch_tags.lua;
	#   }
	# }

	# # Caching (3)
	# server {
	#   listen 127.0.0.1:803;
	#   set_real_ip_from 127.0.0.1;
	#   real_ip_header X-Forwarded-For;
	#   server_name php2-mindaugasb.c9.io php-mindaugasb.c9.io;
	#   error_log logs/php2-mindaugasb.c9.io_error.log;
	#   set $PassScheme "http";
	#   set $zul_upstream "origin";
	#   set $CDNheader "Served-By-zulu";
	#   # Caching rules
	#   location / {
	#     proxy_pass $PassScheme://php2-mindaugasb.c9.io_$PassScheme;
	#     proxy_set_header Host $host;
	#     proxy_set_header X-Forwarded-For $remote_addr;
	#     proxy_hide_header Server;
	#     proxy_hide_header Vary;
	#     proxy_set_header Accept-Encoding "";
	#     more_set_headers "X-Cache-Status: NOTCACHED";
	#   }
	# }

	# server {
	#   listen 80;
	#   listen 8000 proxy_protocol;
	#   server_name b.c9.io;
	#   access_log logs/php2-mindaugasb.c9.io_access.log cache;
	#   error_log logs/php2-mindaugasb.c9.io_error.log;
	#   rewrite ^(.*) $scheme://php2-mindaugasb.c9.io$1 last;
	# }


	# # Template: sys_template_basic_v8
	# # Regenerated at: 2015-09-23 15:39:32 UTC
	# # Web app name: php2-mindaugasb.c9.io
	# proxy_cache_path cache/php2-mindaugasb.c9.io levels=2:2 keys_zone=php2-mindaugasb.c9.io:100m inactive=60d max_size=10g;
	# upstream php2-mindaugasb.c9.io_http {
	#   # Origin servers
	#   server php2-mindaugasb.c9.io:80 weight=1;
	#   # Backup servers
	#   # Health check
	# }

	# upstream php2-mindaugasb.c9.io_https {
	#   # HTTPS Origin servers
	#   server php2-mindaugasb.c9.io:443 weight=1;
	#   # HTTPS Backup servers
	#   # Health check
	# }

	# server {
	#   listen 80;
	#   listen 8000 proxy_protocol;
	#   listen 443 ssl;
	#   listen 8443 ssl proxy_protocol;
	#   listen 9443 ssl proxy_protocol;
	#   listen 9000 proxy_protocol;
	#   server_name php2-mindaugasb.c9.io php-mindaugasb.c9.io;
	#   access_log logs/php2-mindaugasb.c9.io_access.log cache;
	#   error_log logs/php2-mindaugasb.c9.io_error.log;
	#   # Mod security
	#   ModSecurityEnabled on;
	#   ModSecurityConfig waf/php2-mindaugasb.c9.io.conf;
	#   ModSecurityXHeaders on;
	#   ModSecurityAllHeaders on;
	#   set $PassScheme $scheme;
	#   set $CDNheader "Served-By-zulu";
	#   # Caching rules
	#   location / {
	#     proxy_pass $PassScheme://php2-mindaugasb.c9.io_$PassScheme;
	#     proxy_set_header Host $host;
	#     proxy_set_header X-Forwarded-For $remote_addr;
	#     add_header X-Cdn $CDNheader;
	#     proxy_hide_header Vary;
	#     proxy_set_header Accept-Encoding "";
	#     add_header X-Cache-Status "NOTCACHED";
	#   }
	# }

	# server {
	#   listen 80;
	#   listen 8000 proxy_protocol;
	#   listen 443 ssl;
	#   listen 8443 ssl proxy_protocol;
	#   listen 9443 ssl proxy_protocol;
	#   listen 9000 proxy_protocol;
	#   server_name b.c9.io;
	#   access_log logs/php2-mindaugasb.c9.io_access.log cache;
	#   error_log logs/php2-mindaugasb.c9.io_error.log;
	#   rewrite ^(.*) $scheme://php2-mindaugasb.c9.io$1 last;
	# }


    # # Template: webapp_template_lua_v7_3_no_proxy_buffs
    # # Regenerated at: 2015-09-17 12:07:36 UTC
    # # Web app name: php2-mindaugasb.c9.io
    # proxy_cache_path cache/php2-mindaugasb.c9.io levels=2:2 keys_zone=php2-mindaugasb.c9.io:100m inactive=60d max_size=10g;
    # upstream php2-mindaugasb.c9.io_waf_http {
    #   server 127.0.0.1:803;
    # }

    # upstream php2-mindaugasb.c9.io_http {
    #   # Origin servers
    #   server php2-mindaugasb.c9.io:80 weight=1;
    #   # Backup servers
    #   # Health check
    # }

    # # DDoS (1)
    # server {
    #   listen 80;
    #   listen 8000 proxy_protocol;
    #   # turning OFF proxy buffers for bookmakers.co.uk
    #   proxy_buffering off; ################################################################
    #   server_name php2-mindaugasb.c9.io php-mindaugasb.c9.io;
    #   access_log logs/php2-mindaugasb.c9.io_access.log cache_with_fingerprint if=$loggable;
    #   error_log logs/php2-mindaugasb.c9.io_error.log;
    #   set $PassScheme "http";
    #   set $zul_upstream "waf";
    #   # global variables.
    #   set $zul_fingerprint '';
    #   set $CDNheader "Served-By-zulu";
    #   set $zul_cache_type "file";
    #   set $zul_headers "";
    #   location / {
    #     proxy_buffering off; ################################################################
    #     try_files $uri @access_ddos;
    #   }
    #   location @access_ddos {
    #     # Specifies that a given location can only be used for internal (nginx) requests.
    #     # For external requests, the client error 404 (Not Found) is returned.
    #     proxy_buffering off; ################################################################
    #     internal;
    #     add_header X-Cdn $CDNheader;
    #     log_by_lua_file ../lua-zulu/handlers/src/log.lua;
    #     rewrite_by_lua_file ../lua-zulu/handlers/src/rewrite.lua;
    #     access_by_lua_file ../lua-zulu/handlers/src/access.lua;
    #     content_by_lua_file ../lua-zulu/handlers/src/content.lua;
    #   }
    # }

    # # WAF and Caching (3)
    # server {
    #   listen 127.0.0.1:803;
    #   set_real_ip_from 127.0.0.1;
    #   real_ip_header X-Forwarded-For;
    #   # turning OFF proxy buffers for bookmakers.co.uk
    #   proxy_buffering off;
    #   server_name php2-mindaugasb.c9.io php-mindaugasb.c9.io;
    #   error_log logs/php2-mindaugasb.c9.io_error.log;
    #   # Mod security
    #   ModSecurityEnabled on;
    #   ModSecurityConfig waf/php2-mindaugasb.c9.io.conf;
    #   ModSecurityXHeaders on;
    #   set $PassScheme "http";
    #   set $zul_upstream "origin";
    #   set $CDNheader "Served-By-zulu";
    #   # Caching rules
    #   location / {
    #     proxy_buffering off; ################################################################
    #     proxy_pass $PassScheme://php2-mindaugasb.c9.io_$PassScheme;
    #     proxy_set_header Host $host;
    #     proxy_set_header X-Forwarded-For $remote_addr;
    #     proxy_hide_header Server;
    #     proxy_hide_header Vary;
    #     proxy_set_header Accept-Encoding "";
    #     more_set_headers "X-Cache-Status: NOTCACHED";
    #   }
    # }


    # Template: sys_template_basic_v8
    # Regenerated at: 2015-09-15 22:40:20 UTC
    # Web app name: php2-mindaugasb.c9.io
    proxy_cache_path cache/php2-mindaugasb.c9.io levels=2:2 keys_zone=php2-mindaugasb.c9.io:100m inactive=60d max_size=10g;
    upstream php2-mindaugasb.c9.io_http {
      # Origin servers
      server php2-mindaugasb.c9.io:80 weight=1;
      # Backup servers
      # Health check
    }

    server {
      listen 80;
      listen 8000 proxy_protocol;
      server_name php2-mindaugasb.c9.io;
      access_log logs/php2-mindaugasb.c9.io_access.log cache;
      error_log logs/php2-mindaugasb.c9.io_error.log debug;

      # proxy_buffering off;

      # Mod security 
      ModSecurityEnabled on;
      ModSecurityConfig waf/php2-mindaugasb.c9.io.conf;
      ModSecurityXHeaders on;
      ModSecurityAllHeaders on;

      set $PassScheme "http";
      set $CDNheader "Served-By-zulu";
      # Caching rules
      location / {
        proxy_pass $PassScheme://php2-mindaugasb.c9.io_$PassScheme;
        proxy_set_header Host $host;
        proxy_set_header X-Forwarded-For $remote_addr;
        add_header X-Cdn $CDNheader;
        proxy_hide_header Vary;
        proxy_set_header Accept-Encoding "";
        add_header X-Cache-Status "NOTCACHED";
      }
    }

    server {
      listen 80;
      listen 8000 proxy_protocol;
      server_name channelsmanager.com;
      access_log logs/php2-mindaugasb.c9.io_access.log cache;
      error_log logs/php2-mindaugasb.c9.io_error.log;
      rewrite ^(.*) $scheme://php2-mindaugasb.c9.io$1 last;
    }

    # #server {
    # #  listen 80 default_server;
    # #  server_name _ "" ; 
    # #  return 402;
    # #}

    # # default_server

    # server {
    #   listen 80;
    #   server_name ror-mindaugasb.c9.io;
    #   #access_log logs/ror-mindaugasb.c9.io_access.log cache;
    #   #error_log logs/ror-mindaugasb.c9.io_error.log;
      
    #   # Mod security 
    #   ModSecurityEnabled on;
    #   ModSecurityConfig waf/ror-mindaugasb.c9.io.conf;
    #   ModSecurityXHeaders on;
    #   ModSecurityAllHeaders on;

    #   location / {
    #     root /usr/local/openresty/nginx;

    #     proxy_set_header Accept-Encoding "";
    #   }
    # }


///////////////////////

proxy_cache_path cache/m levels=2:2 keys_zone=m:100m inactive=60d max_size=10g;

upstream m_http {
    # Origin servers

	server 127.0.0.31:80;
	server 127.0.0.32:80;

}

upstream m_lua_http {
  server 127.0.0.2:801;
}
upstream m_lua_https {
  server 127.0.0.2:4431;
}

upstream m_cache_http {
  server 127.0.0.2:802;
}
upstream m_cache_https {
server 127.0.0.2:4432;
}

upstream m_pagespeed_http {
  server 127.0.0.2:80;
}
upstream m_pagespeed_https {
  server 127.0.0.2:443;
}


# ModSecurity layer (1st)
server {
  listen 80;
  listen 8000 proxy_protocol;

  # Domains
  server_name m.com;

  access_log logs/m_access.log cache;
  error_log logs/m_error.log;

  # Mod security
  ModSecurityEnabled on;
  ModSecurityConfig waf/php-mindaugasb.c9.io.conf;
  ModSecurityXHeaders on;

  set $orig_https 0;
  set $PassScheme "http";
  if ($orig_https) {
    set $PassScheme $scheme;
  }


  location / {
#echo 'Hello world!';    

proxy_pass $PassScheme://m_lua_$PassScheme;
    proxy_set_header Host $host;
    proxy_set_header X-Forwarded-For $remote_addr;
	#add_header mmm mmm;
	add_header M $upstream_addr;
	proxy_pass_header M2;
  }
}

# LUA layer with zulTags (2nd)
server {
  listen 127.0.0.2:801;

  # Domains
  server_name m.com add.com;

  access_log off;
  error_log logs/m_error.log;
  
  set $orig_https 0;
  set $PassScheme "http";
  if ($orig_https) {
    set $PassScheme $scheme;
  }

  set $CDNheader "Served-By-zulu";


  # zulTags configuration
  set $zultags_lua_path '/usr/local/openresty/lua-zulu/zultags/src';
  set $session_name __zulu_session;


  # Run lua processing. Except if a matching static file is found in node nginx server html root,
  # in which case we directly serve that file.
  location / {
    try_files $uri @zt_request_gateway;
add_header M2 'aaaaa';



  }

  location @zt_request_gateway {
    content_by_lua_file $zultags_lua_path/zt_request_gateway.lua;
add_header M2 'aaaa';
  }

  # This rule replaces zultag placeholders with zultag fetching javascript in cached upstream content
  location @zt_request_processor {
    # Specifies that a given location can only be used for internal (nginx) requests.
    # For external requests, the client error 404 (Not Found) is returned.
    internal;

    content_by_lua_file $zultags_lua_path/zt_request_processor.lua;

add_header M2 'aaaa';

  }

  # This is a proxy rule that fetches cached upstream content
  location /@zt_upstream {
    # Specifies that a given location can only be used for internal (nginx) requests.
    # For external requests, the client error 404 (Not Found) is returned.
    internal;

    # Proxy to upstream, caching the result
    proxy_pass $PassScheme://m_cache_$PassScheme$request_uri;

    proxy_set_header Host $host;
    proxy_set_header X-Forwarded-For $remote_addr;
    proxy_hide_header Vary;

add_header M2 'aaaa';

#proxy_pass_header Mindaugas-PageSpeed;
  }

  # zultag dynamic content data fetcher
  location /__zulu/zultags/fetch_tags {
    default_type 'application/json';
    content_by_lua_file $zultags_lua_path/fetch_tags.lua;
  }
}

# Caching layer (3rd)
server {
  listen 127.0.0.2:802;

  # Domains
  server_name m.com add.com;

  access_log off;

  set $orig_https 0;
  set $PassScheme "http";
  if ($orig_https) {
    set $PassScheme $scheme;
  }

  set $CDNheader "Served-By-zulu";

  # Caching rules
  
      # File cache rule
location ~* .(js)$ {
    proxy_pass $PassScheme://m_$PassScheme;
    proxy_set_header       Host $host;
    proxy_cache            m;
    proxy_cache_key "$scheme://$host$request_uri";
    proxy_cache_valid 200      1m;
    add_header Cache-Control public;
    expires 2m;
    proxy_cache_use_stale  error timeout invalid_header updating http_500 http_502 http_503 http_504;
    add_header X-Cache-Status $upstream_cache_status;
    add_header X-Cdn $CDNheader;
    proxy_set_header X-Forwarded-For $remote_addr;
    proxy_set_header Accept-Encoding "";
    proxy_hide_header Set-Cookie;
}
  

  location / {
    proxy_pass $PassScheme://m_pagespeed_$PassScheme;
    proxy_set_header Host $host;
    proxy_set_header X-Forwarded-For $remote_addr;
    add_header X-Cdn $CDNheader;
    proxy_hide_header Vary;
    proxy_set_header Accept-Encoding "";
    add_header X-Cache-Status "NOTCACHED";
    proxy_pass_header Mindaugas-PageSpeed;
  }
}

# Pagespeed layer (4th)
server {
  listen 127.0.0.2:80;

  server_name m.com;

  access_log off;

  location ~ /purge(/.*) {
    allow 127.0.0.2;
    deny all;
    proxy_cache_purge m $scheme://$host$1$is_args$args;
  }

  pagespeed on;
  pagespeed FetchHttps enable,allow_self_signed,allow_unknown_certificate_authority,allow_certificate_not_yet_valid;
  pagespeed SslCertDirectory /etc/ssl/certs;
  pagespeed FileCachePath /usr/local/openresty/nginx/pagespeed_cache/m;
  pagespeed FileCacheSizeKb 1024000;
  pagespeed XHeaderValue "Powered By Pagespeed on zulu";
  pagespeed RewriteLevel PassThrough;

  #include pagespeed/m.conf;

  pagespeed DownstreamCachePurgeMethod "GET";
  pagespeed DownstreamCachePurgeLocationPrefix "http://127.0.0.2:80/purge";
  pagespeed DownstreamCacheRewrittenPercentageThreshold 95;
  pagespeed RateLimitBackgroundFetches off;

  location ~ "\.pagespeed\.([a-z]\.)?[a-z]{2}\.[^.]{10}\.[^.]+" { add_header "" ""; }
  location ~ "^/ngx_pagespeed_static/" { }
  location ~ "^/ngx_pagespeed_beacon$" { }

  location / {
    proxy_pass $scheme://m_$scheme;
    proxy_set_header Host $host;
    #proxy_set_header Host 'm';
    proxy_set_header X-Forwarded-For $remote_addr;
add_header Mindaugas-PageSpeed $upstream_addr;
    proxy_set_header Accept-Encoding "";
  }
}



//////////////// WAF triggers

Injection for common system commands
	http://php2-mindaugasb.c9.io/WAF-Testing/?a=telnet.exe

php code injection
	http://php2-mindaugasb.c9.io/WAF-Testing/?a=<?php >

OS Command Injection
	http://php-mindaugasb.c9.io/WAF-Testing/?a=wget

URL Contains an IP Address
	http://php-mindaugasb.c9.io/WAF-Testing/?a=http://1.1.1.1

Local File Inclusion Attacks
	http://php-mindaugasb.c9.io/WAF-Testing/?a=../proc/self/environ

Common system files access attempt
	http://php2-mindaugasb.c9.io/WAF-Testing/?a=boot.ini

Embedded Scripts Within URI Schemes 
	http://php-mindaugasb.c9.io/WAF-Testing/?a=<p style="background:url(javascript:alert(1))">

Embedded Scripts Within Event Handlers
	http://php-mindaugasb.c9.io/WAF-Testing/?a=<body onload="alert(1)">

Embedding Scripts Within Scripts
	http://php-mindaugasb.c9.io/WAF-Testing/?a=<script> alert(1)</script>

SQL Comment Sequences DROP/*comment*/sampletable
	http://php-mindaugasb.c9.io/WAF-Testing/?a=DROP/*comment*/sampletable

MongoDB SQL injection
	http://php-mindaugasb.c9.io/WAF-Testing/?a=[$ne]&a=DROP/*comment*/sampletable

Credit card leakage in request
	http://php-mindaugasb.c9.io/WAF-Testing/?a=5364006522406798
	http://stage.zulu.net/a=5364006522406798

SQL Operators
	for i in {1..100}; do curl -X GET -s -D - https://portal.collaborate.telus.com/?webportal=isnull -o /dev/null -m0.3 -k -i; done
	http://php-mindaugasb.c9.io/?a=isnull

Internet Explorer XSS Filters (973347)
	http://php-mindaugasb.c9.io/WAF-Testing/?a=a',\\x76*\\x61*\\x6C*\\x75*\\x65*\\x4F*\\x66: 

Ð¡lassic SQL injection probings (981242)
	http://php2-mindaugasb.c9.io/?a=%22like%223\\\\x27

Common direct HTML injection details (973302)
	php2-mindaugasb.c9.io/?a=_application/x-shockwave-flash

SQL Hex Evasion Methods 981260
	A0xaaa

SQL Keyword Anomaly Scoring
	http://php-mindaugasb.c9.io/WAF-Testing/JS/displayName.js?a=select&b=union&c=top&d=where

SQL Tautologies
	http://example.com/?a=\'like\'=\'like

DB Names 
	http://example.com/?a=tempdb

String Termination/Statement Ending
	http://example.com/?a=\"\"

981172 SQL Character Anomaly Scoring
	http://example.com/?a===========

981242 Ð¡lassic SQL injection probings
	http://php2-mindaugasb.c9.io/?testWAFid=981242&attackString="information_schema

981243 Ð¡lassic SQL injection probings
	http://php2-mindaugasb.c9.io/?testWAFid=981243&attackString=^"

981244 SQL authentication bypass attempts
	http://php2-mindaugasb.c9.io/?testWAFid=981244&attackString=5" " 5

981245 SQL authentication bypass attempts
	http://php2-mindaugasb.c9.io/?testWAFid=981245&attackString=union all ( select 1

981246 SQL authentication bypass attempts
	curl 'http://5.101.107.81/?testWAFid=981246&attackString=union all ( select 1' -H "Host: php2-mindaugasb.c9.io"

981257 MySQL comment-/space-obfuscated
	curl 'http://5.101.107.81/?testWAFid=981257&attackString=+select_from' -H "Host: php2-mindaugasb.c9.io"


/////////////////////////// TELNET request

GET / HTTP/1.1
Host: php2-mindaugasb.c9.io

You can also send male with telnet

//////////////////////////


 char *
 ngx_conf_check_num_bounds(ngx_conf_t *cf, void *post, void *data)
 {
     ngx_conf_num_bounds_t  *bounds = post;
     ngx_int_t  *np = data;
 
     if (bounds->high == -1) {
         if (*np >= bounds->low) {
             return NGX_CONF_OK;
         }
 
         ngx_conf_log_error(NGX_LOG_EMERG, cf, 0,
                            "value must be equal to or greater than %i",
                            bounds->low);
 
         return NGX_CONF_ERROR;
     }
 
     if (*np >= bounds->low && *np <= bounds->high) {
         return NGX_CONF_OK;
     }
 
     ngx_conf_log_error(NGX_LOG_EMERG, cf, 0,
                        "value must be between %i and %i",
                        bounds->low, bounds->high);
 
     return NGX_CONF_ERROR;
 }


////////////////////////

DOJO troubleshooting {
	- RAILS_ENV=production bundle exec rails c
	- Webapp.find_by(domain: 'zulu.snowmachine.me').init_settings(force:true) 	===> initialize settings for webapp;
	- Webapp.find_by(domain: 'zulu.snowmachine.me').init_configs				 	===> initialize configs for webapp;

	TASKS / JOBS {
		- Task::SetConfig.last 														===> check the last SetConfig task;
		- Task::SetConfig.last
		- InitTaskActionsJob.new.perform(Task::SetConfig.last) 						===> launch last task bypassing sidekiq entirelly - usefull when sidekiq is down;
		- class InitTaskActionsJob < BaseJob
			  queue_as :high_priority
			  def perform(task, node_group = nil) 									===> perform has a default parameter present, node_group = nil;

		- https://github.com/zulu/dojo/tree/RC/app/jobs 							===> all jobs;
		- NodeGroup.find_by(name: 'pavadinimas')									===> the node group class inherits from ActiveRecord::Base, which provides all the methods 																								NodeGroup < ActiveRecord::Base
		-
	}
}

NODE troubleshooting {
	- Run poll action from node, run in ~/nodeAgent/current/ director 
	bundle exec rake node_agent:poll_state RAILS_ENV=production
}

//////////////////////////

JMETER {

	- RESOURCE :: http://blog.novatec-gmbh.de/how-to-pass-command-line-properties-to-a-jmeter-testplan/
	- variables : can not be set using CLI 					===> added in the "Test Plan" part of the test 
															===> can be accesed through all parts of the test with ant like variables: ${HOST}, ${PORT};
	- properties : can be set using CLI{
		- ${__P([property],[defaultvalue])}
		- Properties are passed using the -J option to the jmeter start
		- Example: "jmeter -JHOST=localhost -JPORT=8080 -t StressTest_0119.jmx"
		- java -jar /Applications/apache-jmeter-2.12/bin/ApacheJMeter.jar -n -JTHREADS=10 -JLOOPS=100 -JPROTOCOL=https -JHOST=rc.zulu.net -JPORT=80  -t Desktop/StressTest_0119.jmx
	- a good use suggestion for usage is to asign properties to variables in the first "Test Plan" step, then use only variables internally. This is much less confusing, than having a mixed approach.
	Property access{
		-D[prop_name]=[value] - defines a java system property value.
		-J[prop name]=[value] - defines a local JMeter property.
		-G[prop name]=[value] - defines a JMeter property to be sent to all remote servers.
	}
	- You can specify the URLs must match parameter like so:
		- http://${HOST}.* 
		- http://rc\.zulu\.net.* (.* matches any character (except newline) as many times as possible)

	- Retrieve All Embedded Resources from HTML Files 		===> flag
	- Give more memory durring startup 						===> JVM_ARGS="-Xms1024m -Xmx2048m" ./jmeter.sh
	- Get URL's from file, log file parser or CSV 			===> CSV allows looping, .txt does not - it goes through them once;
}

/////////////////////////////

Automate for QA in ZU {
	- https://dojo-rc.zulu.com/waf_policies/1/generic_attacks ===> show count of total, off, alert, on rules in one page
	- https://dojo-rc.zulu.com/admin/companies 				===> to see all companies immediatelly 
	- https://dojo-rc.zulu.com/admin/webapps 				===> to see all webapps immediatelly
	- https://dojo-rc.zulu.com/admin/waf_rules 				===> delete all the rules and all the pending changes
	- https://dojo-rc.zulu.com/admin/templates 				===> see all templates in one page, delte all pending changes
	- https://dojo-rc.zulu.com/admin/features 				===> set a local storage or cookie, that would remember all the options when pressed "remember" and I could revert
}

///////////////////////////// curl: (18) transfer closed with outstanding read data remaining 

curl \
'https://104.145.13.93/' \
-k \
-H 'Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8' \
-H 'Accept-Language: en-US,en;q=0.5' \
-H 'Cache-Control: no-cache' \
-H 'Connection: keep-alive' \
-H 'Host: 104.145.13.93' \
-H 'Pragma: no-cache' \
-I


curl 'https://104.145.13.93/' -k -H 'Connection: keep-alive' -H 'Host: 104.145.13.93' ==> puikiai
curl 'https://104.145.13.93/' -k -H 'Connection: keep-alive' -H 'Host: www.origin.sandbox.orderdynamics.net' ==> puikiai

- keep alive is causing ==> nope
curl 'https://104.131.103.33/' -k -H 'Connection: keep-alive' -H 'Host: www.origin.sandbox.orderdynamics.net'
curl 'https://104.131.103.33/' -k -H 'Connection: Close' -H 'Host: www.origin.sandbox.orderdynamics.net'

- incorrect content-leght

////////////////////////////////

googledrivesync.exe --enable_snapshot_reconstruct

////////////////////////////////

-- get the size of each table in postgress
SELECT
  relname as "Table",
  pg_size_pretty(pg_total_relation_size(relid)) As "Size",
  pg_size_pretty(pg_total_relation_size(relid) - pg_relation_size(relid)) as "External Size"
  FROM pg_catalog.pg_statio_user_tables ORDER BY pg_total_relation_size(relid) DESC;

SELECT nspname || '.' || relname AS "relation",
    pg_size_pretty(pg_relation_size(C.oid)) AS "size"
  FROM pg_class C
  LEFT JOIN pg_namespace N ON (N.oid = C.relnamespace)
  WHERE nspname NOT IN ('pg_catalog', 'information_schema')
  ORDER BY pg_relation_size(C.oid) DESC
  LIMIT 20;


-- select all users from a specific company
	SELECT a.email, c.* FROM companies as c
	  JOIN accounts as a 
	  ON c.id = a.company_id
	  WHERE c.name like '%Mindaugas Corporation%'



-- select * from accounts;
-- select * from account_webapps;
-- select * from ip_headers;
-- select * from node_agents where deleted = false;
select * from stats_requests limit 10;

////////////////////////////////

def perform
    ActiveRecord::Base.transaction do
      TaskAction.delete_all
      Task.delete_all
    end
end

function perform() {
	ActiveRecord::Base.transaction(TaskAction.delete_all, Task.delete_all);
}

RAILS_ENV=production bundle exec rails c
def a = CleanupTasksWorker.new();
<ctrl+c>
a.perform;

TaskAction.delete_all; Task.delete_all

////////////////////////////////// JS Challenge 

time_to_sleep=20; iterations=13; eval "for i in {1..$iterations}; do curl -s -D - http://php-mindaugasb.c9.io/zul-Tag-Testing/index.php -o /dev/null | grep "HTTP"; done;" echo ""; echo $"Going to sleep now for "$time_to_sleep" seconds .. "; echo ""; sleep $time_to_sleep; eval "for i in {1..$iterations}; do curl -s -D - http://php-mindaugasb.c9.io/zul-Tag-Testing/index.php -o /dev/null | grep "HTTP"; done;"

time_to_sleep=20; iterations=3; eval "for i in {1..$iterations}; do curl -s -D - http://php-mindaugasb.c9.io/zul-Tag-Testing/index.php -o /dev/null; done;" echo ""; echo $"Going to sleep now for "$time_to_sleep" seconds!"; echo ""; sleep $time_to_sleep; eval "for i in {1..$iterations}; do curl -s -D - http://php-mindaugasb.c9.io/zul-Tag-Testing/index.php -o /dev/null; done;"

time_to_sleep=20; iterations=13; eval "for i in {1..$iterations}; do curl -s -D - rc.zulu.com -o /dev/null; done;" echo ""; echo $"Going to sleep now for "$time_to_sleep" seconds"; echo ""; sleep $time_to_sleep; eval "for i in {1..$iterations}; do curl -s -D - rc.zulu.com -o /dev/null; done;"

time_to_sleep=20; iterations=20; eval "for i in {1..$iterations}; do curl -s -D - http://rc.zulu.com/wp-includes/js/jquery/jquery.js?ver=1.11.1 -o /dev/null; done;" echo ""; echo $"Going to sleep now for "$time_to_sleep" seconds"; echo ""; sleep $time_to_sleep; eval "for i in {1..$iterations}; do curl -s -D - http://rc.zulu.com/wp-includes/js/jquery/jquery.js?ver=1.11.1 -o /dev/null; done;"

time_to_sleep=21; iterations=15; eval "for i in {1..$iterations}; do curl -s -D - rc.zulu.com -o /dev/null; done;" echo ""; echo $"Going to sleep now for "$time_to_sleep" seconds"; echo ""; sleep $time_to_sleep; eval "for i in {1..$iterations}; do curl -s -D - rc.zulu.com -o /dev/null; done;"

time_to_sleep=21; iterations=15; eval "for i in {1..$iterations}; do curl -s -D - php-mindaugasb.c9.io -o /dev/null; done;" echo ""; echo $"Going to sleep now for "$time_to_sleep" seconds"; echo ""; sleep $time_to_sleep; eval "for i in {1..$iterations}; do curl -s -D - php-mindaugasb.c9.io -o /dev/null; done;"

time_to_sleep=21; iterations=15; eval "for i in {1..$iterations}; do curl -s -D - 178.62.131.40 -H \"Host: php-mindaugasb.c9.io\" -o /dev/null; done;" echo ""; echo $"Going to sleep now for "$time_to_sleep" seconds"; echo ""; sleep $time_to_sleep; eval "for i in {1..$iterations}; do curl -s -D - 178.62.131.40 -H \"Host: php-mindaugasb.c9.io\" -o /dev/null; done;"

time_to_sleep=21; iterations=15; eval "for i in {1..$iterations}; do curl -s -D - 178.62.131.40 -H \"Host: rc.zulu.com\" -o /dev/null; done;" echo ""; echo $"Going to sleep now for "$time_to_sleep" seconds"; echo ""; sleep $time_to_sleep; eval "for i in {1..$iterations}; do curl -s -D - 178.62.131.40 -H \"Host: rc.zulu.com\"-o /dev/null; done;"


curl -X OPTIONS -s -D - 178.62.131.40 -H \"Host: rc.zulu.com\" -o /dev/null 
curl -X GET -s -D - 178.62.131.40 -H \"Host: rc.zulu.com\" -o /dev/null
curl -X HEAD -s -D - 178.62.131.40 -H \"Host: rc.zulu.com\"-o /dev/null
curl -X POST -s -D - http://rc.zulu.com -o /dev/null -m0.4 -k -i
curl -X PUT -s -D - 178.62.131.40 -H \"Host: rc.zulu.com\" -m0.2
curl -X PUT -s -D - http://rc.zulu.com -m0.2
curl -X DELETE -s -D - 178.62.131.40 -H \"Host: rc.zulu.com\" -o /dev/null -m0.2
curl -X TRACE -s -D - 178.62.131.40 -H \"Host: rc.zulu.com\" -o /dev/null -m0.2
curl -X CONNECT -s -D - 178.62.131.40 -H \"Host: rc.zulu.com\" -o /dev/null -m0.2
curl -X PROPFIND -s -D - 178.62.131.40 -H \"Host: rc.zulu.com\" -o /dev/null -m0.2
curl -X PROPPATCH -s -D - 178.62.131.40 -H \"Host: rc.zulu.com\" -o /dev/null -m0.2
curl -X MKCOL -s -D - 178.62.131.40 -H \"Host: rc.zulu.com\" -o /dev/null -m0.2
curl -X COPY -s -D - 178.62.131.40 -H \"Host: rc.zulu.com\" -o /dev/null -m0.2
curl -X MOVE -s -D - 178.62.131.40 -H \"Host: rc.zulu.com\" -o /dev/null -m0.2
curl -X LOCK -s -D - 178.62.131.40 -H \"Host: rc.zulu.com\" -o /dev/null -m0.2
curl -X UNLOCK -s -D - 178.62.131.40 -H \"Host: rc.zulu.com\" -o /dev/null -m0.2
curl -X PATCH -s -D - 178.62.131.40 -H \"Host: rc.zulu.com\" -o /dev/null -m0.2
curl -X SEARCH -s -D - 178.62.131.40 -H \"Host: rc.zulu.com\" -o /dev/null -m0.2


time_to_sleep=21; iterations=2; eval "for i in {1..$iterations}; do curl -i -X HEAD 178.62.131.40 -H \"Host: rc.zulu.com\"; done;" echo ""; echo $"Going to sleep now for "$time_to_sleep" seconds"; echo ""; sleep $time_to_sleep; eval "for i in {1..$iterations}; do curl -i -X HEAD 178.62.131.40 -H \"Host: rc.zulu.com\"; done;"

time_to_sleep=21; iterations=3; eval "for i in {1..$iterations}; do curl -i -X HEAD rc.zulu.com -m0.2; done;" echo ""; echo $"Going to sleep now for "$time_to_sleep" seconds"; echo ""; sleep $time_to_sleep; eval "for i in {1..$iterations}; do curl -i -X HEAD rc.zulu.com -m0.2; done;"

time_to_sleep=21; iterations=14; eval "for i in {1..$iterations}; do curl -X POST -s -D - http://rc.zulu.com -o /dev/null -m0.3 -k -i; done;" echo ""; echo $"Going to sleep now for "$time_to_sleep" seconds"; echo ""; sleep $time_to_sleep; eval "for i in {1..$iterations}; do curl -X POST -s -D - http://rc.zulu.com -o /dev/null -m0.3 -k -i; done;"

time_to_sleep=31; iterations=24; eval "for i in {1..$iterations}; do curl -X GET -s -D - 88winners.com -o /dev/null -k -i; done;" echo ""; echo $"Going to sleep now for "$time_to_sleep" seconds"; echo ""; sleep $time_to_sleep; eval "for i in {1..$iterations}; do curl -X GET -s -D - 88winners.com -o /dev/null -k -i; done;"


sudo tcpdump -s 0 -A 'tcp[((tcp[12:1] & 0xf0) >> 2):4] = 0x47455420'

sudo tcpdump -vvv -A -nn -i en1 '(tcp[((tcp[12:1] & 0xf0) >> 2):4] = 0x47455420)' and dst host 178.62.131.40 

//////////////////////////////////////////// DNS testing for NGINX

clear ; dig tkt.exceda.com +short; /etc/init.d/openresty reload ; dig tkt.exceda.com +short


////////////////////////////////////////////  

netsh wlan show network

sudo iwlist wlan0 scan

FOR /L %i IN (1,1,254) DO ping -n 1 192.168.1.%i

FOR /L %i IN (1,1,100) DO curl rc.zulu.com

//////////////////////////////////////////// netcat

- nc -z -v -n 192.168.1.1 1-500 			===> scan ports from 1 to 500 on host
	- z zero IO .i.e the connection is closed as soon as it opens and no actual data exchange take place.
	- v verbose.
	- n use the DNS lookup for the address

- nc -l -p 4444 </> file.html				===> nc server, download / upload;
- nc -l -p 4444 -e cmd.exe (/bin/bash)		===> nc sever on port 4444 that when connected to executes cmd.exe (reverse shell);
- nc 192.168.1.100 4444 </>	file.html	 	===> nc client;
- nc -vvv -l 1234 localhost 				===> specify "localhost" to be able to connect from the same machine;
- nc -w1 -z $redis $redisport 				===> using netcat for application availability detection. -w {timeout in seconds};
- YOU MUST SET UP PORT FORWARDING TO CONNECT FROM THE INTERNET - the server will be able to receive requests only if port forward is set;
- MY router does not support hairpining (I can't make a request to another LAN machine in my NAT);

Setting up a one-shot webserver on port 8080 to present the content of a file
	- { echo -ne "HTTP/1.0 200 OK\r\nContent-Length: $(wc -c < some.file)\r\n\r\n"; cat some.file; } | nc -l 8080
	- while true ; do { echo -ne "HTTP/1.0 200 OK\r\nContent-Length: $(wc -c < html.html)\r\n\r\n"; cat html.html; } | nc -l -p 8080 ; done

That is because pipes are unidirectional. This can be worked around with a named pipe to redirect the input and output.
mkfifo backpipe
nc -l 12345 0<backpipe | nc www.google.com 80 1>backpipe


one can create a pipe and set up gzip to compress things piped to it:
mkfifo my_pipe
gzip -9 -c < my_pipe > out.gz &
.....
cat file > my_pipe
.....
rm my_pipe
.....
mkfifo tmp
mkfifo tmp2
nc -l 8080 -k > tmp < tmp2 &
while [ 1 ]
do
	openssl s_client -connect www.google.com:443 -quiet < tmp > tmp2
done


Making any process a server :: netcat can be used to make any process a network server. It can listen on a port and pipe the input it receives to that process.
For example, it is possible to expose a bourne shell process to remote computers.


////////////////////////////////////////////

time_to_sleep=31; iterations=23; eval "for i in {1..$iterations}; do curl -X GET -s -D - https://portal.collaborate.telus.com/?webportal=1234');alert('xss -o /dev/null -m0.3 -k -i; done;" echo ""; echo $"Going to sleep now for "$time_to_sleep" seconds"; echo ""; sleep $time_to_sleep; eval "for i in {1..$iterations}; do curl -X GET -s -D - 8https://portal.collaborate.telus.com/?webportal=1234');alert('xss -o /dev/null -m0.3 -k -i; done;"

for i in {1..100}; do curl -X GET -s -D - https://portal.collaborate.telus.com/?webportal=1234');alert('xss -o /dev/null -m0.3 -k -i; done
for i in {1..100}; do curl -X GET -g -s -D - https://portal.collaborate.telus.com/?webportal=1234%27);alert(%27xss-o /dev/null -m0.3 -k -i; done
/?webportal=1234%27);alert(%27xss
s
https://portal.collaborate.telus.com/?webportal=http://1.1.1.1&a=<p style="background:url(javascript:alert(1))">
https://portal.collaborate.telus.com/?webportal=<?php >
https://portal.collaborate.telus.com/?webportal=[$ne]&a=DROP/*comment*/sampletable
 

////////////////////////////////////////////

tail -f /usr/local/openresty/nginx/logs/error.log | egrep "(\[error\]|crit|alert|emerg)"


/////////////////// Curl for API testing 

	- replace spaces with dashes when using api calls
	- web app id is the id genearated in dojo, you can get it from /api/v2/webapps

	GET ACC TOKEN 		===> curl -X POST https://dojo.zulu.com/api/oauth/token -F client_id=0e4e4e1578c8e323c88140028740e73de94210f9ebe12fd95eb815505c3b2e82 -F client_secret=4877ca37dff8e65e3fab25f0147f5bdb31c92233f726bf496f0431924f01a871

	curl -X POST https://172.31.19.242/api/oauth/token -F client_id=253aa87608bcbbda23ccb4aa9fc8c904383fd32019452c734fc022944abfded7 -F client_secret=bd8c6e053fe90017584f14e1b926e5cfeeb272e607d4875d0530382fe7ad04d6 -H "Host: dojo.zulu.com"

	ACC TOKEN: 44b3e0a1601c6c6b441fd8eede3d34dec852c4f4f6d5ff794834a2aebde3ecb1

	PURGE ALL CACHE  	===> curl -X PUT https://dojo-rc.zulu.com/api/v1/cache/purge_all -F webapp_domain=php2-mindaugasb.c9.io -F access_token=3b629c6836efc973c3a52299d5662e9333bef3eb30f84e18ceaf8ba0c01d4c40

	WEBAPP ID'S 		===> curl -X GET https://dojo-rc.zulu.com/api/v2/webapps -F access_token=44b3e0a1601c6c6b441fd8eede3d34dec852c4f4f6d5ff794834a2aebde3ecb1 | python -m json.tool
	UPDATE C RULE		===> curl -X PUT https://dojo-rc.zulu.com/api/v2/webapps/php2-mindaugasb.c9.io/caching_rules/js -F access_token=f38f7d0698649115206af726616852212e789f3976b5b8d56cddd303c722f4c6 -F "cache_set"="jpg,png"
	DELETE CACHE RULE 	===> curl -X DELETE https://dojo-rc.zulu.com/api/v2/webapps/php2-mindaugasb-c9-io-f165c354-509c-4817-9e21-c72846224677/caching_rules/mindaugas-api-call-caching-rule -F access_token=3f55523942a92a0b0b75fd7f86105c782a7aad4eb9111a2212e5feb928090163

	CREATE CACHE RULE 	===> curl -X POST https://dojo-rc.zulu.com/api/v2/webapps/php2-mindaugasb-c9-io-f165c354-509c-4817-9e21-c72846224677/caching_rules -d '{"access_token":"3f55523942a92a0b0b75fd7f86105c782a7aad4eb9111a2212e5feb928090163","name":"Mindaugas API CALL CACHING RULE","setting_type":"file_cache_rule","expire_after":1,"expire_time_unit":"h","client_expire_after":1,"client_expire_time_unit":"h","client_expire_after_enabled":"true","cache_set":"jpg,png,css"}' -H "Content-Type:application/json"

	W/ AUTHORIZATION H 	===> curl -sS -H "Authorization: Bearer d37e7f383c25a7f8c152375d52c52dc0f3df3f9d9ea5725cefac9576a79a042c" -X GET https://dojo.zulu.com/api/v2/webapps/lb-examplesites-staging-net

	INVITE USER 		===> curl -X POST https://dojo-rc.zulu.com/api/v2/users/invite -d '{"access_token":"1775c3dbdc9e82c2b3e8beb45512763f8372d82f1bc981cd3d278f397ac1ea2d","email": "mindaugas+test1010@zulu.com"}' -H "Content-Type:application/json"


curl -X GET https://dojo.zulu.com/api/v2/webapps -H "Authorization: Bearer 44b3e0a1601c6c6b441fd8eede3d34dec852c4f4f6d5ff794834a2aebde3ecb1" -D -


curl -X GET https://dojo.zulu.com/api/v3/webapps/47942a60c6020134ebe212007bac8676/changes/pending -H "Authorization: Bearer 44b3e0a1601c6c6b441fd8eede3d34dec852c4f4f6d5ff794834a2aebde3ecb1" -D -




	WAF{
		- GET /v2/webapps/:webapp_id/waf_rules		Returns a list of waf rules for webapp
		- GET /v2/webapps/:webapp_id/waf_rules/:id	Returns a waf rule details for webapp.
		- PUT /v2/webapps/:webapp_id/waf_rules/:id 	Updates waf rule for webapp.

		curl -sX GET https://dojo-rc.zulu.com/api/v2/webapps/php2-mindaugasb-c9-io-f165c354-509c-4817-9e21-c72846224677/waf_rules -d '{"access_token":"4eadca96143faeae006d5cd61321c47c63ab2b0349f5844b26cd70da55fae266"}' -H "Content-Type:application/json" | python -m json.tool

		curl -sX GET https://dojo.zulu.com/api/v2/webapps/telus-test-ndacorp-com/waf_rules -d '{"access_token":"cfcf0f2b8f9ec0ccc266e2b78f9f2352c85f78958b06b2f352fba43350181464"}' -H "Content-Type:application/json" | python -m json.tool

		curl -sX PUT https://dojo.zulu.com/api/v2/webapps/47e721f0b07201331c0b12ab248d6d53/waf_rules/activexobject-xss-attack -d '{"value": "alert_only", "access_token":"8e44c35b74fec8e7d9c1bf379096e5fbdb998ec37e936211145762eea35c92b6"}' -H "Content-Type:application/json" | python -m json.tool

		curl -sX PUT https://dojo.zulu.com/api/v2/webapps/47e721f0b07201331c0b12ab248d6d53/waf_rules/activexobject-xss-attack -d '{"value": "block", "access_token":"8e44c35b74fec8e7d9c1bf379096e5fbdb998ec37e936211145762eea35c92b6"}' -H "Content-Type:application/json" | python -m json.tool

		curl -sX PUT https://dojo.zulu.com/api/v2/webapps/47e721f0b07201331c0b12ab248d6d53/waf_rules/activexobject-xss-attack -F value=alert_only -F access_token=8e44c35b74fec8e7d9c1bf379096e5fbdb998ec37e936211145762eea35c92b6




		curl -sX POST https://dojo.zulu.com/api/oauth/token -F client_id=d0648776dc6a33555fefa2f327e0ec0026e63d945c54ca15df3f089519bd0414 -F client_secret=097c5d5a7afcea0fbe0dd4286d1b904335c3eff685818b60b7e5bd2d2ad7cf1e

		curl -sX GET https://dojo.zulu.com/api/v2/webapps -F access_token=8e44c35b74fec8e7d9c1bf379096e5fbdb998ec37e936211145762eea35c92b6 | python -m json.tool

		curl -sX GET https://dojo.zulu.com/api/v2/webapps/47e721f0b07201331c0b12ab248d6d53/waf_rules -d '{"access_token":"8e44c35b74fec8e7d9c1bf379096e5fbdb998ec37e936211145762eea35c92b6"}' -H "Content-Type:application/json" | python -m json.tool

		curl -sX PUT https://dojo.zulu.com/api/v2/webapps/47e721f0b07201331c0b12ab248d6d53/waf_rules/activexobject-xss-attack alert_only -d '{"access_token":"8e44c35b74fec8e7d9c1bf379096e5fbdb998ec37e936211145762eea35c92b6"}' -H "Content-Type:application/json" | python -m json.tool
	}

/////////////////// C#

C# {

	- http://www.tutorialspoint.com/compile_csharp_online.php

	Kudvekat tutorials {

		Verbattim Literal, System namespace, null coalesence {
			using System; 	// namespace (a logical collection of classes, 
				// interfaces, enums, structures, delegates and even other namespaces) 
				// declaration

			public class Test{
				public static void Main(){
					Console.WriteLine("Enter your name!");
					// System.Console.WriteLine(); // you can use this if you don't want to use the namespace declaration

					string userName = Console.ReadLine();

					Console.WriteLine("Hello " + userName);
					// Console.WriteLine("Hello {0}", userName); // another way to concat

					string URL = @"C:\usr\"; // this is the a so called verbatim litteral --> treats excape sequences as litterals
					Console.WriteLine(URL);
					
					int? ticketsOnSale = null;
					// null coalescing openrestyrator ===> if ticketsOnSale = null, set availableTickets to 1
					int availableTickets = ticketsOnSale ?? 1; 
					
					Console.WriteLine(availableTickets);


					flout f = 1.1F;
					int i = (int) d; // data conversion using typecast operator
					int j = Convert.ToInt32(f); // another way to perform datatype conversion

				}
			}
		}

		Type conversion {
			using System.IO;
			using System;

			class Program
			{
			    static void Main()
			    {
			        float f = 1.1F;
			        
			        // data conversion using typecast operator
			        // no exception if flout is too big 
					int i = (int) f; 
					
					// another way to perform datatype conversion
					// throws and exception if float is toobig
					int j = Convert.ToInt32(f); 
					
					Console.WriteLine("1: {0}", i);
					Console.WriteLine("2: {0}", j);
					
					// converting a string to integer
					string s = "100";
					int k = int.Parse(s);
					
					Console.WriteLine("3: {0}", k);
					
					// converting a string to integer
					string s2 = "100M";
					int k2;
					bool isConversionSuccessful = int.TryParse(s2, out k2);
					
					if(isConversionSuccessful){
					    Console.WriteLine("4: {0}", k2);
					}else{
					    Console.WriteLine("Please enter a number!");
					}
					
			    }
			}
		}

		Arrays and Loops {
			using System.IO;
			using System;

			class Program
			{
			    static void Main()
			    {
			        // arrays are 
			            // strongly typed
			            // constant size (runtime error if index out of bounds)
			            // can only retrieve values by numeric indexes
				    int[] intArray = new int[3];
				    
				    intArray[0] = 1;
				    intArray[1] = 2;
				    intArray[2] = 3;
				    
				    foreach(int i in intArray){
				        Console.WriteLine("foreach : {0}", intArray[i-1]); // this is not a way to do it
				        Console.WriteLine("foreach : {0}", intArray[i-1]); // this is the way to do it with foreach
				    }
				    
				    for(int j = 0; j < intArray.Length; j++){
				        Console.WriteLine("for : {0}", intArray[j]);
				    }
				    
				    int k = 0;
				    while(k < intArray.Length){
				        Console.WriteLine("while : {0}", intArray[k]);
				        k += 1;
				    }

				    // good tests for break and continue
				    for (int i = 0; i < 20; i++){
				        Console.WriteLine(i);
				    	if(i == 10) continue; // continue / break
				    }
				    Console.WriteLine("Jumped out");
			    }
			}
		}

		Passing by reference and by copy {

			using System.IO;
			using System;

			class Program
			{
			    public static void Main()
			    {
			        int i = 1;
			        
			        PrintNumber(i);
			        Console.WriteLine("Main 1: {0}", i); // prints 1
			        
			        PrintNumber(ref i);
			        Console.WriteLine("Main 2: {0}", i); // prints 1
			        
			        AssignNumber(i);
			        Console.WriteLine("Main 3: {0}", i); // prints 1
			        
			        AssignNumber(ref i);
			        Console.WriteLine("Main 3: {0}", i); // prints 3
			    }
			    
			    public static void PrintNumber(int number){
			        Console.WriteLine("PrintNumber: {0}", number + 1);
			    }
			    
			    public static void PrintNumber(ref int number){
			        Console.WriteLine("PrintNumber ref: {0}", number + 1);
			    }
			    
			    public static void AssignNumber(int number){
			        Console.WriteLine("PrintNumber ref: {0}", number = 3);
			   	}
			    
			    public static void AssignNumber(ref int number){
			        Console.WriteLine("PrintNumber ref: {0}", number = 3);
			    }
			}
		}

		Multi-return{

			using System;

			public class Test{
	
				public static void Main(){
					int o, p;
					fu(5, out o, out p);
					Console.WriteLine("Number: o = {0}, p = {1}", o, p);
				}
				
				public static void fu(int i, out int o, out int p){
					o = i;
					p = i;
				}
			}
		}

		Parameter arrays (variadic functions / varargs){
			using System;

			public class Testr{
			    
			    public static void Main(){
			        ParamArrays(9, 2, 1, 125, 66);
			    }
			    
			    public static void ParamArrays(int i, params int[] numbers){
			        Console.WriteLine("i is: {0}", i);
			        foreach(int j in numbers) {
			            Console.WriteLine("numbers member j is : {0}", j);
			        }
			    }
			}
		}

		Properties {
			using System;

			public class Person{
			    
			    string _Name = string.Empty;
			    int _Age = 0;

			    public string Name {
			        get {
			            // you can't use throw with the ternary operator apparently, because it the form of the ternary operator
			            // is << expression ? expression : expression >> so you can' t have << expression ? statment : expression >>
			            return string.IsNullOrEmpty(this._Name) ? "GET NAME: Name is either empty or null" : this._Name;
			        }
			        set {
			            if(string.IsNullOrEmpty(value)) throw new Exception("SET NAME: The name can't be null or empty!");
			            this._Name = value;
			        }
			    }
			    
			    public int Age {
			        get {
			            if (this._Age < 0) throw new Exception("GET AGE: Age is nagative!");
			            return this._Age;
			        }
			        set {
			            if(value < 0) throw new Exception("SET AGE: Age can't be nagative!");
			            this._Age = value;
			        }
			    }
			    
			    public Person(string Name, int Age){
			        this.Name = Name;   // constructor will also use the setters and getters 
			        this.Age = Age;     // but if you tried accesing _Age then constructor 
			                            // would be able to use the field directly (bypassing
			                            // the validation in the mutator)
			    }
			}

			public class Program {
			    public static void Main(){
			        Person p1 = new Person("", -25);
			        Console.WriteLine("P name is: {0}", p1.Name);
			        Console.WriteLine("P age is: {0}", p1.Age);
			        Console.ReadKey();
			    }
			}
		}
	}
}


//////////////////////////////////////////////////// Flush Yosemites DNS resolver cache 

printf "\n\n"; echo " ------------------- Cache stats before -------------------- "; sudo discoveryutil mdnscachestats; sudo discoveryutil udnscachestats; sudo discoveryutil mdnsflushcache; sudo discoveryutil udnsflushcaches;  printf "\n\n"; echo " ---------------------  Cache stats after ------------------------ "; sudo discoveryutil mdnscachestats; sudo discoveryutil udnscachestats;

//////////////////////////////////////////////////// ORIGIN TESTING

1. Add two origins

2. Construct TCPDUMP statments for both origins

	sudo tcpdump -i eth0 src host 178.62.131.40 or 178.62.170.138 -XX -e -nn and 'tcp[((tcp[12:1] & 0xf0) >> 2):4] = 0x47455420'
	sudo tcpdump -i eth0 src host 178.62.170.138 -XX -e -nn and 'tcp[((tcp[12:1] & 0xf0) >> 2):4] = 0x47455420'
	sudo tcpdump -i eth0 src host 178.62.131.40 -XX -e -nn and 'tcp[((tcp[12:1] & 0xf0) >> 2):4] = 0x47455420'

	sudo tcpdump -i eth0 src host 178.16.44.81 -XX -e -nn and 'tcp[((tcp[12:1] & 0xf0) >> 2):4] = 0x47455420'
	sudo tcpdump -i eth0 src host 178.16.44.81 -XX -e -nn and 'tcp[((tcp[12:1] & 0xf0) >> 2):4] != 0x47455420'

3. Check for equal distribution of requests (equal weights)

	Will need a TCP Dump by unique request - will make that request(best by URL), see how it is forwarded among the origins
	Use this light weight JS: rc.zulu.com/wp-includes/js/comment-reply.min.js?ver=4.1

4. Check for weighting

	Will need a TCP Dump by unique request - will make that request(best by URL), see how it is forwarded among the origins
	Use this light weight JS: rc.zulu.com/wp-includes/js/comment-reply.min.js?ver=4.1

//////////////////////////////////////////////////// HEALTH CHECK TESTING

1. Check that healthcheck requests are being sent with appropriate frequencies

2. Stop all outgoing traffic from one origin with iptables 	===> is it really port 80 for the response? ===> yes, but it's better to block by ip
	iptables -A INPUT -i lo -j ACCEPT 						===> append (-A) a rule to accept all trafic in the INPUT chain from the lo interface
	iptables -L -n 											===> list all rules with no reverse DNS lookups
	iptables -A INPUT -p tcp --dport 22 -j ACCEPT 			===> allow ssh connection on destination port
	iptables -A INPUT -i eth0 -p tcp --dport 443 -j ACCEPT 	===> optional interface parameter
	iptables -D INPUT <index>								===> delete rule @ the index, starting from 1, not 0
	iptables -A INPUT -p ICMP -j DROP 						===> drop all icmp traffic
	iptables --flush 										===> deletes all the rules, but keeps the policity set for all inbound connections, a good way to lock yourself
	iptables -L INPUT --line-numbers 						===> 
	iptables -A OUTPUT -d 178.62.170.138 -j DROP; 			===>
	iptables -A OUTPUT -d 178.62.131.40 -j DROP; 			===>
	iptables -D OUTPUT 1; sudo iptables -D OUTPUT 1; 		===>
	iptables-save > /etc/iptables.save 						===> save iptables into some file to be loaded with rc.local
	iptables-restore < /etc/iptables.save 					===> place this command in rc.local file so that on boot iptable rules would be restored

3. Traffic accounting with iptables:
	iptables -I INPUT -p tcp --dport 80 -m string --to --algo bm --string 'GET /' -j DROP 
	iptables -L INPUT -nvx --line-numbers 					===> check the stats for each rule in the INPUT chain;
	http://blog.nintechnet.com/how-to-block-w00tw00t-at-isc-sans-dfind-and-other-web-vulnerability-scanners/

4. TO DO (Still no success). Whitelisting (bypassing zul-NODE) w/ IPTABLES
	
	In /etc/sysctl.conf add this line:
	# enble ip forwarding with ip tables
 	net.ipv4.ip_forward = 1

 	Run: sysctl -p

	iptables -t nat -A PREROUTING -p tcp -s 178.62.182.48 --dport 80 -j DNAT --to-destination 23.251.133.229:80
	iptables -t nat -A PREROUTING -p tcp --dport 80 -j DNAT --to 23.251.133.229:80
	iptables -t nat -A POSTROUTING -p tcp --dport 80 -j SNAT --to-source 5.101.107.81
	iptables -t nat -nL --line-numbers 				    	===> this should be used to inspect the PRE and PORT routing rules;
	iptables -t nat -D PREROUTING <index> 					===> delete the PRE and PORT routing rules;
	iptables -t nat -R PREROUTING 1 -p tcp --dport 80 -j DNAT --to 130.211.111.104:80


5. Rate limiting with IPTABLES
	iptables -A INPUT -p tcp --dport 80 -m limit --limit 25/minute --limit-burst 100 -j ACCEPT

6. IP spoofing with iptables:
	iptables -t nat -I PREROUTING -s 84.46.250.117 -p tcp --dport 80 -j DNAT --to 1.1.1.1


Init.d iptables script
#########################################################################################################
#! /bin/bash
### BEGIN INIT INFO
# Provides:          iptables
# Required-Start:    mountkernfs $local_fs
# Required-Stop:     mountkernfs $local_fs
# X-Start-Before:    networking
# X-Stop-After:      networking
# Default-Start:     2 3 4 5
# Default-Stop:      0 1 6
# Short-Description: Iptables
# Description:       Debian init script for iptables
### END INIT INFO

. /lib/lsb/init-functions

function do_start {
    if [ -e "/etc/iptables.rule" ]; then
        log_daemon_msg "Starting iptables service" "iptables"
        /sbin/iptables-restore < /etc/iptables.rule
        log_end_msg $?
    else
        log_action_msg "No rule saved for iptables"
    fi
}

function do_stop {
    log_daemon_msg "Stopping iptables service" "iptables"
    /sbin/iptables -F
    /sbin/iptables -X
    /sbin/iptables -t nat -F
    /sbin/iptables -t nat -X
    /sbin/iptables -t mangle -F
    /sbin/iptables -t mangle -X
    /sbin/iptables -P INPUT ACCEPT
    /sbin/iptables -P FORWARD ACCEPT
    /sbin/iptables -P OUTPUT ACCEPT
    log_end_msg $?
}

function do_save {
    log_daemon_msg "Saving iptables rule" "iptables"
    /sbin/iptables-save > /etc/iptables.rule
    log_end_msg $?
}

case "$1" in
    start)
        do_start
    ;;
    stop)
        do_stop
    ;;
    save)
        do_save
    ;;
    restart)
        do_stop
        do_start
    ;;
    *)
        echo "Usage: /etc/init.d/iptables {start|stop|restart|save}"
        exit 1
    ;;
esac

exit 0
##############################################################################################################


Resilience testing ===> do a lot of requests with JMETER, switch off on server, check how many responses are lost completelly 

//////////////////////////////////////////////////// BACKUP SERVERS TESTING

1. Block all access to all origins (I will have only one) and check that backup server is used

2. Resilience - how many requiests will be losed in case of outage in all web servers

3. Backup server with 

check interval=2000 rise=2 fall=2 timeout=2000 type=http;
  check_http_send "GET /?p=11 HTTP/1.0\r\n\r\n";
  check_http_expect_alive http_2xx http_3xx http_4xx;

//////////////////////////////////////////////////// STICKY SESSIONS TESTING

1. All trafic should redirected to one server from one IP

2. The next Ip should get a new session and all traffic should be redirected to it

//////////////////////////////////////////////////// BACKUP SERVERS WITH STICKY SESSIONS TESTING

1. If all primary servers are lost does the stickyness persist?

///////////////////////////////////////////////////


\\\\\\\\\\\\\\\\ Issues

SQL Keyword Anomaly Scoring
== Warning. Matched phrase "offset" at ARGS_NAMES:GmtOffset. 
== Warning. Matched phrase "as" at ARGS_NAMES:password.
== Warning. Matched phrase "limit" at ARGS_NAMES:limit. ====> what does this mean :: Message details: Warning. String match "limit" at TX:sqli_select_statement.  ???
'tx.sqli_select_statement=%{tx.sqli_select_statement} %{matched_var}'
== Warning. Matched phrase "top" at ARGS_NAMES:AutoPinInd.
== Warning. Matched phrase "from" at ARGS_NAMES:FromScheduleList. 
== Warning. Matched phrase "select" at ARGS_NAMES:select_1.
== Warning. Matched phrase "from" at ARGS:error.  /console/console-error-dialog?error=You%20are%20already%20logged%20in%20to%20Audio%20Console%20from%20this%20browser

\\\\\\\\\\\\\\\\ Not solved
== Warning. Matched phrase "select" at REQUEST_COOKIES:s_pers.


\\\\\\\\\\\\\\\\ Original rule

SecRule REQUEST_COOKIES|!REQUEST_COOKIES:/__utm/|!REQUEST_COOKIES:/_pk_ref/|REQUEST_COOKIES_NAMES|ARGS_NAMES|ARGS|XML:/* "@pm select show top distinct from dual where group by order having limit offset union rownum as (case" "phase:2,id:'981300',ctl:ruleEngine=DetectionOnly,t:none,t:urlDecodeUni,t:lowercase,log,deny,log,setvar:'tx.sqli_select_statement=%{tx.sqli_select_statement} %{matched_var}',severity:'2'"
SecRule TX:SQLI_SELECT_STATEMENT "@containsWord select" "phase:2,id:'981301',ctl:ruleEngine=DetectionOnly,t:none,deny,log,setvar:tx.sqli_select_statement_count=+1,setvar:tx.sql_injection_score=+1,severity:'2'"
SecRule TX:SQLI_SELECT_STATEMENT "@containsWord show" "phase:2,id:'981302',ctl:ruleEngine=DetectionOnly,t:none,deny,log,setvar:tx.sqli_select_statement_count=+1,setvar:tx.sql_injection_score=+1,severity:'2'"
SecRule TX:SQLI_SELECT_STATEMENT "@containsWord top" "phase:2,id:'981303',ctl:ruleEngine=DetectionOnly,t:none,deny,log,setvar:tx.sqli_select_statement_count=+1,setvar:tx.sql_injection_score=+1,severity:'2'"
SecRule TX:SQLI_SELECT_STATEMENT "@containsWord distinct" "phase:2,id:'981304',ctl:ruleEngine=DetectionOnly,t:none,deny,log,setvar:tx.sqli_select_statement_count=+1,setvar:tx.sql_injection_score=+1,severity:'2'"
SecRule TX:SQLI_SELECT_STATEMENT "@containsWord from" "phase:2,id:'981305',ctl:ruleEngine=DetectionOnly,t:none,deny,log,setvar:tx.sqli_select_statement_count=+1,setvar:tx.sql_injection_score=+1,severity:'2'"
SecRule TX:SQLI_SELECT_STATEMENT "@containsWord dual" "phase:2,id:'981306',ctl:ruleEngine=DetectionOnly,t:none,deny,log,setvar:tx.sqli_select_statement_count=+1,setvar:tx.sql_injection_score=+1,severity:'2'"
SecRule TX:SQLI_SELECT_STATEMENT "@containsWord where" "phase:2,id:'981307',ctl:ruleEngine=DetectionOnly,t:none,deny,log,setvar:tx.sqli_select_statement_count=+1,setvar:tx.sql_injection_score=+1,severity:'2'"
SecRule TX:SQLI_SELECT_STATEMENT "@contains group by" "phase:2,id:'981308',ctl:ruleEngine=DetectionOnly,t:none,deny,log,setvar:tx.sqli_select_statement_count=+1,setvar:tx.sql_injection_score=+1,severity:'2'"
SecRule TX:SQLI_SELECT_STATEMENT "@contains order by" "phase:2,id:'981309',ctl:ruleEngine=DetectionOnly,t:none,deny,log,setvar:tx.sqli_select_statement_count=+1,setvar:tx.sql_injection_score=+1,severity:'2'"
SecRule TX:SQLI_SELECT_STATEMENT "@containsWord having" "phase:2,id:'981310',ctl:ruleEngine=DetectionOnly,t:none,deny,log,setvar:tx.sqli_select_statement_count=+1,setvar:tx.sql_injection_score=+1,severity:'2'"
SecRule TX:SQLI_SELECT_STATEMENT "@containsWord limit" "phase:2,id:'981311',ctl:ruleEngine=DetectionOnly,t:none,deny,log,setvar:tx.sqli_select_statement_count=+1,setvar:tx.sql_injection_score=+1,severity:'2'"
SecRule TX:SQLI_SELECT_STATEMENT "@containsWord offset" "phase:2,id:'981312',ctl:ruleEngine=DetectionOnly,t:none,deny,log,setvar:tx.sqli_select_statement_count=+1,setvar:tx.sql_injection_score=+1,severity:'2'"
SecRule TX:SQLI_SELECT_STATEMENT "@containsWord union" "phase:2,id:'981313',ctl:ruleEngine=DetectionOnly,t:none,deny,log,setvar:tx.sqli_select_statement_count=+1,setvar:tx.sql_injection_score=+1,severity:'2'"
SecRule TX:SQLI_SELECT_STATEMENT "@contains union all" "phase:2,id:'981314',ctl:ruleEngine=DetectionOnly,t:none,deny,log,setvar:tx.sqli_select_statement_count=+1,setvar:tx.sql_injection_score=+1,severity:'2'"
SecRule TX:SQLI_SELECT_STATEMENT "@contains rownum as" "phase:2,id:'981315',ctl:ruleEngine=DetectionOnly,t:none,deny,log,setvar:tx.sqli_select_statement_count=+1,setvar:tx.sql_injection_score=+1,severity:'2'"
SecRule TX:SQLI_SELECT_STATEMENT "@contains (case" "phase:2,id:'981316',ctl:ruleEngine=DetectionOnly,t:none,deny,log,setvar:tx.sqli_select_statement_count=+1,setvar:tx.sql_injection_score=+1,severity:'2'"
SecRule TX:SQLI_SELECT_STATEMENT_COUNT "@ge 3" "phase:2,t:none,block,id:'981317',ctl:ruleEngine=DetectionOnly,deny,rev:'2',ver:'OWASP_CRS/2.2.9',maturity:'8',accuracy:'8',msg:'SQL SELECT Statement Anomaly Detection Alert',logdata:'Matched Data: %{TX.0} found within %{MATCHED_VAR_NAME}: %{MATCHED_VAR}',tag:'OWASP_CRS/WEB_ATTACK/SQL_INJECTION',tag:'WASCTC/WASC-19',tag:'OWASP_TOP_10/A1',tag:'OWASP_AppSensor/CIE1',tag:'PCI/6.5.2',setvar:tx.anomaly_score=+%{tx.warning_anomaly_score},setvar:tx.sql_injection_score=+1,setvar:'tx.msg=%{rule.msg}',setvar:tx.%{rule.id}-OWASP_CRS/WEB_ATTACK/SQL_INJECTION-%{matched_var_name}=%{tx.0},severity:'2'"
# zulRule:End


\\\\\\\\\\\\\\\\ Debug variables

logdata:'Matched Data: %{TX.0} found within %{MATCHED_VAR_NAME}: %{MATCHED_VAR}'


\\\\\\\\\\\\\\\\ Regex variant - does not work as expected: only the last string matched by the first SecRule will be sent to be processed by the TX:SQLI_SELECT_STATEMENT rules.

SecRule REQUEST_COOKIES|!REQUEST_COOKIES:/__utm/|!REQUEST_COOKIES:/_pk_ref/|REQUEST_COOKIES_NAMES|ARGS_NAMES|ARGS|XML:/* "@rx (?i)(select(?!_)|show|(?<!u)top|distinct|(?<!%20)from(?!s)|dual|where|group|by|order|having|(?<!&)limit|(?<!gmt)offset|union|rownum|as(?!s)|\(case)" "phase:2,id:'813008',ctl:ruleEngine=DetectionOnly,t:none,t:urlDecodeUni,t:lowercase,log,deny,log,setvar:'tx.sqli_select_statement=%{matched_var}',severity:'2'"
SecRule TX:SQLI_SELECT_STATEMENT "@containsWord select" "phase:2,id:'981301',ctl:ruleEngine=DetectionOnly,t:none,deny,log,setvar:tx.sqli_select_statement_count=+1,setvar:tx.sql_injection_score=+1,severity:'2'"
SecRule TX:SQLI_SELECT_STATEMENT "@containsWord show" "phase:2,id:'981302',ctl:ruleEngine=DetectionOnly,t:none,deny,log,setvar:tx.sqli_select_statement_count=+1,setvar:tx.sql_injection_score=+1,severity:'2'"
SecRule TX:SQLI_SELECT_STATEMENT "@containsWord top" "phase:2,id:'981303',ctl:ruleEngine=DetectionOnly,t:none,deny,log,setvar:tx.sqli_select_statement_count=+1,setvar:tx.sql_injection_score=+1,severity:'2'"
SecRule TX:SQLI_SELECT_STATEMENT "@containsWord distinct" "phase:2,id:'981304',ctl:ruleEngine=DetectionOnly,t:none,deny,log,setvar:tx.sqli_select_statement_count=+1,setvar:tx.sql_injection_score=+1,severity:'2'"
SecRule TX:SQLI_SELECT_STATEMENT "@containsWord from" "phase:2,id:'981305',ctl:ruleEngine=DetectionOnly,t:none,deny,log,setvar:tx.sqli_select_statement_count=+1,setvar:tx.sql_injection_score=+1,severity:'2'"
SecRule TX:SQLI_SELECT_STATEMENT "@containsWord dual" "phase:2,id:'981306',ctl:ruleEngine=DetectionOnly,t:none,deny,log,setvar:tx.sqli_select_statement_count=+1,setvar:tx.sql_injection_score=+1,severity:'2'"
SecRule TX:SQLI_SELECT_STATEMENT "@containsWord where" "phase:2,id:'981307',ctl:ruleEngine=DetectionOnly,t:none,deny,log,setvar:tx.sqli_select_statement_count=+1,setvar:tx.sql_injection_score=+1,severity:'2'"
SecRule TX:SQLI_SELECT_STATEMENT "@contains group by" "phase:2,id:'981308',ctl:ruleEngine=DetectionOnly,t:none,deny,log,setvar:tx.sqli_select_statement_count=+1,setvar:tx.sql_injection_score=+1,severity:'2'"
SecRule TX:SQLI_SELECT_STATEMENT "@contains order by" "phase:2,id:'981309',ctl:ruleEngine=DetectionOnly,t:none,deny,log,setvar:tx.sqli_select_statement_count=+1,setvar:tx.sql_injection_score=+1,severity:'2'"
SecRule TX:SQLI_SELECT_STATEMENT "@containsWord having" "phase:2,id:'981310',ctl:ruleEngine=DetectionOnly,t:none,deny,log,setvar:tx.sqli_select_statement_count=+1,setvar:tx.sql_injection_score=+1,severity:'2'"
SecRule TX:SQLI_SELECT_STATEMENT "@containsWord limit" "phase:2,id:'981311',ctl:ruleEngine=DetectionOnly,t:none,deny,log,setvar:tx.sqli_select_statement_count=+1,setvar:tx.sql_injection_score=+1,severity:'2'"
SecRule TX:SQLI_SELECT_STATEMENT "@containsWord offset" "phase:2,id:'981312',ctl:ruleEngine=DetectionOnly,t:none,deny,log,setvar:tx.sqli_select_statement_count=+1,setvar:tx.sql_injection_score=+1,severity:'2'"
SecRule TX:SQLI_SELECT_STATEMENT "@containsWord union" "phase:2,id:'981313',ctl:ruleEngine=DetectionOnly,t:none,deny,log,setvar:tx.sqli_select_statement_count=+1,setvar:tx.sql_injection_score=+1,severity:'2'"
SecRule TX:SQLI_SELECT_STATEMENT "@contains union all" "phase:2,id:'981314',ctl:ruleEngine=DetectionOnly,t:none,deny,log,setvar:tx.sqli_select_statement_count=+1,setvar:tx.sql_injection_score=+1,severity:'2'"
SecRule TX:SQLI_SELECT_STATEMENT "@contains rownum as" "phase:2,id:'981315',ctl:ruleEngine=DetectionOnly,t:none,deny,log,setvar:tx.sqli_select_statement_count=+1,setvar:tx.sql_injection_score=+1,severity:'2'"
SecRule TX:SQLI_SELECT_STATEMENT "@contains (case" "phase:2,id:'981316',ctl:ruleEngine=DetectionOnly,t:none,deny,log,setvar:tx.sqli_select_statement_count=+1,setvar:tx.sql_injection_score=+1,severity:'2'"
SecRule TX:SQLI_SELECT_STATEMENT_COUNT "@ge 3" "phase:2,t:none,block,id:'981317',ctl:ruleEngine=DetectionOnly,deny,rev:'2',ver:'OWASP_CRS/2.2.9',maturity:'8',accuracy:'8',msg:'SQL SELECT Statement Anomaly Detection Alert',logdata:'Matched Data: %{TX.0} found within %{MATCHED_VAR_NAME}: %{MATCHED_VAR}',tag:'OWASP_CRS/WEB_ATTACK/SQL_INJECTION',tag:'WASCTC/WASC-19',tag:'OWASP_TOP_10/A1',tag:'OWASP_AppSensor/CIE1',tag:'PCI/6.5.2',setvar:tx.anomaly_score=+%{tx.warning_anomaly_score},setvar:tx.sql_injection_score=+1,setvar:'tx.msg=%{rule.msg}',setvar:tx.%{rule.id}-OWASP_CRS/WEB_ATTACK/SQL_INJECTION-%{matched_var_name}=%{tx.0},severity:'2'"
# zulRule:End


\\\\\\\\\\\\\\\\ Final rule - it does not match the FP's, but matches the possitives precissely. 

SecRule REQUEST_COOKIES|!REQUEST_COOKIES:/__utm/|!REQUEST_COOKIES:/_pk_ref/|REQUEST_COOKIES_NAMES|ARGS_NAMES|ARGS|XML:/* "@rx (?i)(select(?!_))" "phase:2,id:'8130081',ctl:ruleEngine=DetectionOnly,t:none,t:urlDecodeUni,t:lowercase,log,deny,log,setvar:'tx.sqli_select_statement=%{matched_var}',severity:'2'"
SecRule TX:SQLI_SELECT_STATEMENT "@containsWord select" "phase:2,id:'9813011',ctl:ruleEngine=DetectionOnly,t:none,deny,log,setvar:tx.sqli_select_statement_count=+1,setvar:tx.sql_injection_score=+1,severity:'2'"

SecRule REQUEST_COOKIES|!REQUEST_COOKIES:/__utm/|!REQUEST_COOKIES:/_pk_ref/|REQUEST_COOKIES_NAMES|ARGS_NAMES|ARGS|XML:/* "@rx (?i)show" "phase:2,id:'8130082',ctl:ruleEngine=DetectionOnly,t:none,t:urlDecodeUni,t:lowercase,log,deny,log,setvar:'tx.sqli_select_statement=%{matched_var}',severity:'2'"
SecRule TX:SQLI_SELECT_STATEMENT "@containsWord show" "phase:2,id:'9813022',ctl:ruleEngine=DetectionOnly,t:none,deny,log,setvar:tx.sqli_select_statement_count=+1,setvar:tx.sql_injection_score=+1,severity:'2'"

SecRule REQUEST_COOKIES|!REQUEST_COOKIES:/__utm/|!REQUEST_COOKIES:/_pk_ref/|REQUEST_COOKIES_NAMES|ARGS_NAMES|ARGS|XML:/* "@rx (?i)(?<!u)top" "phase:2,id:'8130083',ctl:ruleEngine=DetectionOnly,t:none,t:urlDecodeUni,t:lowercase,log,deny,log,setvar:'tx.sqli_select_statement=%{matched_var}',severity:'2'"
SecRule TX:SQLI_SELECT_STATEMENT "@containsWord top" "phase:2,id:'9813033',ctl:ruleEngine=DetectionOnly,t:none,deny,log,setvar:tx.sqli_select_statement_count=+1,setvar:tx.sql_injection_score=+1,severity:'2'"

SecRule REQUEST_COOKIES|!REQUEST_COOKIES:/__utm/|!REQUEST_COOKIES:/_pk_ref/|REQUEST_COOKIES_NAMES|ARGS_NAMES|ARGS|XML:/* "@rx (?i)distinct" "phase:2,id:'8130084',ctl:ruleEngine=DetectionOnly,t:none,t:urlDecodeUni,t:lowercase,log,deny,log,setvar:'tx.sqli_select_statement=%{matched_var}',severity:'2'"
SecRule TX:SQLI_SELECT_STATEMENT "@containsWord distinct" "phase:2,id:'9813044',ctl:ruleEngine=DetectionOnly,t:none,deny,log,setvar:tx.sqli_select_statement_count=+1,setvar:tx.sql_injection_score=+1,severity:'2'"

SecRule REQUEST_COOKIES|!REQUEST_COOKIES:/__utm/|!REQUEST_COOKIES:/_pk_ref/|REQUEST_COOKIES_NAMES|ARGS_NAMES|ARGS|XML:/* "@rx (?i)(?<!%20)from(?!s)" "phase:2,id:'8130085',ctl:ruleEngine=DetectionOnly,t:none,t:urlDecodeUni,t:lowercase,log,deny,log,setvar:'tx.sqli_select_statement=%{matched_var}',severity:'2'"
SecRule TX:SQLI_SELECT_STATEMENT "@containsWord from" "phase:2,id:'9813055',ctl:ruleEngine=DetectionOnly,t:none,deny,log,setvar:tx.sqli_select_statement_count=+1,setvar:tx.sql_injection_score=+1,severity:'2'"

SecRule REQUEST_COOKIES|!REQUEST_COOKIES:/__utm/|!REQUEST_COOKIES:/_pk_ref/|REQUEST_COOKIES_NAMES|ARGS_NAMES|ARGS|XML:/* "@rx (?i)dual" "phase:2,id:'8130086',ctl:ruleEngine=DetectionOnly,t:none,t:urlDecodeUni,t:lowercase,log,deny,log,setvar:'tx.sqli_select_statement=%{matched_var}',severity:'2'"
SecRule TX:SQLI_SELECT_STATEMENT "@containsWord dual" "phase:2,id:'9813066',ctl:ruleEngine=DetectionOnly,t:none,deny,log,setvar:tx.sqli_select_statement_count=+1,setvar:tx.sql_injection_score=+1,severity:'2'"

SecRule REQUEST_COOKIES|!REQUEST_COOKIES:/__utm/|!REQUEST_COOKIES:/_pk_ref/|REQUEST_COOKIES_NAMES|ARGS_NAMES|ARGS|XML:/* "@rx (?i)where" "phase:2,id:'8130087',ctl:ruleEngine=DetectionOnly,t:none,t:urlDecodeUni,t:lowercase,log,deny,log,setvar:'tx.sqli_select_statement=%{matched_var}',severity:'2'"
SecRule TX:SQLI_SELECT_STATEMENT "@containsWord where" "phase:2,id:'9813077',ctl:ruleEngine=DetectionOnly,t:none,deny,log,setvar:tx.sqli_select_statement_count=+1,setvar:tx.sql_injection_score=+1,severity:'2'"

SecRule REQUEST_COOKIES|!REQUEST_COOKIES:/__utm/|!REQUEST_COOKIES:/_pk_ref/|REQUEST_COOKIES_NAMES|ARGS_NAMES|ARGS|XML:/* "@rx (?i)(group by)" "phase:2,id:'8130088',ctl:ruleEngine=DetectionOnly,t:none,t:urlDecodeUni,t:lowercase,log,deny,log,setvar:'tx.sqli_select_statement=%{matched_var}',severity:'2'"
SecRule TX:SQLI_SELECT_STATEMENT "@contains group by" "phase:2,id:'9813088',ctl:ruleEngine=DetectionOnly,t:none,deny,log,setvar:tx.sqli_select_statement_count=+1,setvar:tx.sql_injection_score=+1,severity:'2'"

SecRule REQUEST_COOKIES|!REQUEST_COOKIES:/__utm/|!REQUEST_COOKIES:/_pk_ref/|REQUEST_COOKIES_NAMES|ARGS_NAMES|ARGS|XML:/* "@rx (?i)(order by)" "phase:2,id:'8130089',ctl:ruleEngine=DetectionOnly,t:none,t:urlDecodeUni,t:lowercase,log,deny,log,setvar:'tx.sqli_select_statement=%{matched_var}',severity:'2'"
SecRule TX:SQLI_SELECT_STATEMENT "@contains order by" "phase:2,id:'9813099',ctl:ruleEngine=DetectionOnly,t:none,deny,log,setvar:tx.sqli_select_statement_count=+1,setvar:tx.sql_injection_score=+1,severity:'2'"

SecRule REQUEST_COOKIES|!REQUEST_COOKIES:/__utm/|!REQUEST_COOKIES:/_pk_ref/|REQUEST_COOKIES_NAMES|ARGS_NAMES|ARGS|XML:/* "@rx (?i)having" "phase:2,id:'81300810',ctl:ruleEngine=DetectionOnly,t:none,t:urlDecodeUni,t:lowercase,log,deny,log,setvar:'tx.sqli_select_statement=%{matched_var}',severity:'2'"
SecRule TX:SQLI_SELECT_STATEMENT "@containsWord having" "phase:2,id:'98131010',ctl:ruleEngine=DetectionOnly,t:none,deny,log,setvar:tx.sqli_select_statement_count=+1,setvar:tx.sql_injection_score=+1,severity:'2'"

SecRule REQUEST_COOKIES|!REQUEST_COOKIES:/__utm/|!REQUEST_COOKIES:/_pk_ref/|REQUEST_COOKIES_NAMES|ARGS_NAMES|ARGS|XML:/* "@rx (?i)(?<!&)limit" "phase:2,id:'81300811',ctl:ruleEngine=DetectionOnly,t:none,t:urlDecodeUni,t:lowercase,log,deny,log,setvar:'tx.sqli_select_statement=%{matched_var}',severity:'2'"
SecRule TX:SQLI_SELECT_STATEMENT "@containsWord limit" "phase:2,id:'98131111',ctl:ruleEngine=DetectionOnly,t:none,deny,log,setvar:tx.sqli_select_statement_count=+1,setvar:tx.sql_injection_score=+1,severity:'2'"

SecRule REQUEST_COOKIES|!REQUEST_COOKIES:/__utm/|!REQUEST_COOKIES:/_pk_ref/|REQUEST_COOKIES_NAMES|ARGS_NAMES|ARGS|XML:/* "@rx (?i)(?<!gmt)offset" "phase:2,id:'81300812',ctl:ruleEngine=DetectionOnly,t:none,t:urlDecodeUni,t:lowercase,log,deny,log,setvar:'tx.sqli_select_statement=%{matched_var}',severity:'2'"
SecRule TX:SQLI_SELECT_STATEMENT "@containsWord offset" "phase:2,id:'98131212',ctl:ruleEngine=DetectionOnly,t:none,deny,log,setvar:tx.sqli_select_statement_count=+1,setvar:tx.sql_injection_score=+1,severity:'2'"

SecRule REQUEST_COOKIES|!REQUEST_COOKIES:/__utm/|!REQUEST_COOKIES:/_pk_ref/|REQUEST_COOKIES_NAMES|ARGS_NAMES|ARGS|XML:/* "@rx (?i)union" "phase:2,id:'81300813',ctl:ruleEngine=DetectionOnly,t:none,t:urlDecodeUni,t:lowercase,log,deny,log,setvar:'tx.sqli_select_statement=%{matched_var}',severity:'2'"
SecRule TX:SQLI_SELECT_STATEMENT "@containsWord union" "phase:2,id:'98131313',ctl:ruleEngine=DetectionOnly,t:none,deny,log,setvar:tx.sqli_select_statement_count=+1,setvar:tx.sql_injection_score=+1,severity:'2'"

SecRule REQUEST_COOKIES|!REQUEST_COOKIES:/__utm/|!REQUEST_COOKIES:/_pk_ref/|REQUEST_COOKIES_NAMES|ARGS_NAMES|ARGS|XML:/* "@rx (?i)union" "phase:2,id:'81300814',ctl:ruleEngine=DetectionOnly,t:none,t:urlDecodeUni,t:lowercase,log,deny,log,setvar:'tx.sqli_select_statement=%{matched_var}',severity:'2'"
SecRule TX:SQLI_SELECT_STATEMENT "@contains union all" "phase:2,id:'98131414',ctl:ruleEngine=DetectionOnly,t:none,deny,log,setvar:tx.sqli_select_statement_count=+1,setvar:tx.sql_injection_score=+1,severity:'2'"

SecRule REQUEST_COOKIES|!REQUEST_COOKIES:/__utm/|!REQUEST_COOKIES:/_pk_ref/|REQUEST_COOKIES_NAMES|ARGS_NAMES|ARGS|XML:/* "@rx (?i)(rownum|as(?!s))" "phase:2,id:'81300815',ctl:ruleEngine=DetectionOnly,t:none,t:urlDecodeUni,t:lowercase,log,deny,log,setvar:'tx.sqli_select_statement=%{matched_var}',severity:'2'"
SecRule TX:SQLI_SELECT_STATEMENT "@contains rownum as" "phase:2,id:'98131515',ctl:ruleEngine=DetectionOnly,t:none,deny,log,setvar:tx.sqli_select_statement_count=+1,setvar:tx.sql_injection_score=+1,severity:'2'"

SecRule REQUEST_COOKIES|!REQUEST_COOKIES:/__utm/|!REQUEST_COOKIES:/_pk_ref/|REQUEST_COOKIES_NAMES|ARGS_NAMES|ARGS|XML:/* "@rx (?i)\(case" "phase:2,id:'81300816',ctl:ruleEngine=DetectionOnly,t:none,t:urlDecodeUni,t:lowercase,log,deny,log,setvar:'tx.sqli_select_statement=%{matched_var}',severity:'2'"
SecRule TX:SQLI_SELECT_STATEMENT "@contains (case" "phase:2,id:'98131616',ctl:ruleEngine=DetectionOnly,t:none,deny,log,setvar:tx.sqli_select_statement_count=+1,setvar:tx.sql_injection_score=+1,severity:'2'"

SecRule TX:SQLI_SELECT_STATEMENT_COUNT "@ge 3" "phase:2,t:none,block,id:'98131717',ctl:ruleEngine=DetectionOnly,deny,rev:'2',ver:'OWASP_CRS/2.2.9',maturity:'8',accuracy:'8',msg:'SQL SELECT Statement Anomaly Detection Alert',logdata:'Matched Data: %{TX.0} found within %{MATCHED_VAR_NAME}: %{MATCHED_VAR}',tag:'OWASP_CRS/WEB_ATTACK/SQL_INJECTION',tag:'WASCTC/WASC-19',tag:'OWASP_TOP_10/A1',tag:'OWASP_AppSensor/CIE1',tag:'PCI/6.5.2',setvar:tx.anomaly_score=+%{tx.warning_anomaly_score},setvar:tx.sql_injection_score=+1,setvar:'tx.msg=%{rule.msg}',setvar:tx.%{rule.id}-OWASP_CRS/WEB_ATTACK/SQL_INJECTION-%{matched_var_name}=%{tx.0},severity:'2'"
# zulRule:End


\\\\\\\\\\\\\\\\ Can be added to DOJO

# zulRule:Start
# @Title CUSTOM SQL Keyword Anomaly Scoring for TELUS
# @Description detects common SQL keywords anomalies
# @id 8130081,8130082,8130083,8130084,8130085,8130086,8130087,8130088,8130089,81300810,81300811,81300812,81300813,81300814,81300815,81300816,9813011,9813022,9813033,9813044,9813055,9813066,9813077,9813088,9813099,98131010,98131111,98131212,98131313,98131414,98131515,98131616,98131717
# @References

SecRule REQUEST_COOKIES|!REQUEST_COOKIES:s_pers|!REQUEST_COOKIES:/__utm/|!REQUEST_COOKIES:/_pk_ref/|REQUEST_COOKIES_NAMES|ARGS_NAMES|ARGS|XML:/* "@rx (?i)(select(?!_))" "phase:2,id:'8130081',ctl:ruleEngine={{mode}},t:none,t:urlDecodeUni,t:lowercase,log,deny,log,setvar:'tx.sqli_select_statement=%{matched_var}',severity:'2'"
SecRule TX:SQLI_SELECT_STATEMENT "@containsWord select" "phase:2,id:'9813011',ctl:ruleEngine={{mode}},t:none,deny,log,setvar:tx.sqli_select_statement_count=+1,setvar:tx.sql_injection_score=+1,severity:'2'"

SecRule REQUEST_COOKIES|!REQUEST_COOKIES:/__utm/|!REQUEST_COOKIES:/_pk_ref/|REQUEST_COOKIES_NAMES|ARGS_NAMES|ARGS|XML:/* "@rx (?i)show" "phase:2,id:'8130082',ctl:ruleEngine={{mode}},t:none,t:urlDecodeUni,t:lowercase,log,deny,log,setvar:'tx.sqli_select_statement=%{matched_var}',severity:'2'"
SecRule TX:SQLI_SELECT_STATEMENT "@containsWord show" "phase:2,id:'9813022',ctl:ruleEngine={{mode}},t:none,deny,log,setvar:tx.sqli_select_statement_count=+1,setvar:tx.sql_injection_score=+1,severity:'2'"

SecRule REQUEST_COOKIES|!REQUEST_COOKIES:/__utm/|!REQUEST_COOKIES:/_pk_ref/|REQUEST_COOKIES_NAMES|ARGS_NAMES|ARGS|XML:/* "@rx (?i)(?<!u)top" "phase:2,id:'8130083',ctl:ruleEngine={{mode}},t:none,t:urlDecodeUni,t:lowercase,log,deny,log,setvar:'tx.sqli_select_statement=%{matched_var}',severity:'2'"
SecRule TX:SQLI_SELECT_STATEMENT "@containsWord top" "phase:2,id:'9813033',ctl:ruleEngine={{mode}},t:none,deny,log,setvar:tx.sqli_select_statement_count=+1,setvar:tx.sql_injection_score=+1,severity:'2'"

SecRule REQUEST_COOKIES|!REQUEST_COOKIES:/__utm/|!REQUEST_COOKIES:/_pk_ref/|REQUEST_COOKIES_NAMES|ARGS_NAMES|ARGS|XML:/* "@rx (?i)distinct" "phase:2,id:'8130084',ctl:ruleEngine={{mode}},t:none,t:urlDecodeUni,t:lowercase,log,deny,log,setvar:'tx.sqli_select_statement=%{matched_var}',severity:'2'"
SecRule TX:SQLI_SELECT_STATEMENT "@containsWord distinct" "phase:2,id:'9813044',ctl:ruleEngine={{mode}},t:none,deny,log,setvar:tx.sqli_select_statement_count=+1,setvar:tx.sql_injection_score=+1,severity:'2'"

SecRule REQUEST_COOKIES|!REQUEST_COOKIES:/__utm/|!REQUEST_COOKIES:/_pk_ref/|REQUEST_COOKIES_NAMES|ARGS_NAMES|ARGS|XML:/* "@rx (?i)(?<!%20)from(?!s)" "phase:2,id:'8130085',ctl:ruleEngine={{mode}},t:none,t:urlDecodeUni,t:lowercase,log,deny,log,setvar:'tx.sqli_select_statement=%{matched_var}',severity:'2'"
SecRule TX:SQLI_SELECT_STATEMENT "@containsWord from" "phase:2,id:'9813055',ctl:ruleEngine={{mode}},t:none,deny,log,setvar:tx.sqli_select_statement_count=+1,setvar:tx.sql_injection_score=+1,severity:'2'"

SecRule REQUEST_COOKIES|!REQUEST_COOKIES:/__utm/|!REQUEST_COOKIES:/_pk_ref/|REQUEST_COOKIES_NAMES|ARGS_NAMES|ARGS|XML:/* "@rx (?i)dual" "phase:2,id:'8130086',ctl:ruleEngine={{mode}},t:none,t:urlDecodeUni,t:lowercase,log,deny,log,setvar:'tx.sqli_select_statement=%{matched_var}',severity:'2'"
SecRule TX:SQLI_SELECT_STATEMENT "@containsWord dual" "phase:2,id:'9813066',ctl:ruleEngine={{mode}},t:none,deny,log,setvar:tx.sqli_select_statement_count=+1,setvar:tx.sql_injection_score=+1,severity:'2'"

SecRule REQUEST_COOKIES|!REQUEST_COOKIES:/__utm/|!REQUEST_COOKIES:/_pk_ref/|REQUEST_COOKIES_NAMES|ARGS_NAMES|ARGS|XML:/* "@rx (?i)where" "phase:2,id:'8130087',ctl:ruleEngine={{mode}},t:none,t:urlDecodeUni,t:lowercase,log,deny,log,setvar:'tx.sqli_select_statement=%{matched_var}',severity:'2'"
SecRule TX:SQLI_SELECT_STATEMENT "@containsWord where" "phase:2,id:'9813077',ctl:ruleEngine={{mode}},t:none,deny,log,setvar:tx.sqli_select_statement_count=+1,setvar:tx.sql_injection_score=+1,severity:'2'"

SecRule REQUEST_COOKIES|!REQUEST_COOKIES:/__utm/|!REQUEST_COOKIES:/_pk_ref/|REQUEST_COOKIES_NAMES|ARGS_NAMES|ARGS|XML:/* "@rx (?i)(group by)" "phase:2,id:'8130088',ctl:ruleEngine={{mode}},t:none,t:urlDecodeUni,t:lowercase,log,deny,log,setvar:'tx.sqli_select_statement=%{matched_var}',severity:'2'"
SecRule TX:SQLI_SELECT_STATEMENT "@contains group by" "phase:2,id:'9813088',ctl:ruleEngine={{mode}},t:none,deny,log,setvar:tx.sqli_select_statement_count=+1,setvar:tx.sql_injection_score=+1,severity:'2'"

SecRule REQUEST_COOKIES|!REQUEST_COOKIES:/__utm/|!REQUEST_COOKIES:/_pk_ref/|REQUEST_COOKIES_NAMES|ARGS_NAMES|ARGS|XML:/* "@rx (?i)(order by)" "phase:2,id:'8130089',ctl:ruleEngine={{mode}},t:none,t:urlDecodeUni,t:lowercase,log,deny,log,setvar:'tx.sqli_select_statement=%{matched_var}',severity:'2'"
SecRule TX:SQLI_SELECT_STATEMENT "@contains order by" "phase:2,id:'9813099',ctl:ruleEngine={{mode}},t:none,deny,log,setvar:tx.sqli_select_statement_count=+1,setvar:tx.sql_injection_score=+1,severity:'2'"

SecRule REQUEST_COOKIES|!REQUEST_COOKIES:/__utm/|!REQUEST_COOKIES:/_pk_ref/|REQUEST_COOKIES_NAMES|ARGS_NAMES|ARGS|XML:/* "@rx (?i)having" "phase:2,id:'81300810',ctl:ruleEngine={{mode}},t:none,t:urlDecodeUni,t:lowercase,log,deny,log,setvar:'tx.sqli_select_statement=%{matched_var}',severity:'2'"
SecRule TX:SQLI_SELECT_STATEMENT "@containsWord having" "phase:2,id:'98131010',ctl:ruleEngine={{mode}},t:none,deny,log,setvar:tx.sqli_select_statement_count=+1,setvar:tx.sql_injection_score=+1,severity:'2'"

SecRule REQUEST_COOKIES|!REQUEST_COOKIES:/__utm/|!REQUEST_COOKIES:/_pk_ref/|REQUEST_COOKIES_NAMES|ARGS_NAMES|ARGS|XML:/* "@rx (?i)(?<!&)limit" "phase:2,id:'81300811',ctl:ruleEngine={{mode}},t:none,t:urlDecodeUni,t:lowercase,log,deny,log,setvar:'tx.sqli_select_statement=%{matched_var}',severity:'2'"
SecRule TX:SQLI_SELECT_STATEMENT "@containsWord limit" "phase:2,id:'98131111',ctl:ruleEngine={{mode}},t:none,deny,log,setvar:tx.sqli_select_statement_count=+1,setvar:tx.sql_injection_score=+1,severity:'2'"

SecRule REQUEST_COOKIES|!REQUEST_COOKIES:/__utm/|!REQUEST_COOKIES:/_pk_ref/|REQUEST_COOKIES_NAMES|ARGS_NAMES|ARGS|XML:/* "@rx (?i)(?<!gmt)offset" "phase:2,id:'81300812',ctl:ruleEngine={{mode}},t:none,t:urlDecodeUni,t:lowercase,log,deny,log,setvar:'tx.sqli_select_statement=%{matched_var}',severity:'2'"
SecRule TX:SQLI_SELECT_STATEMENT "@containsWord offset" "phase:2,id:'98131212',ctl:ruleEngine={{mode}},t:none,deny,log,setvar:tx.sqli_select_statement_count=+1,setvar:tx.sql_injection_score=+1,severity:'2'"

SecRule REQUEST_COOKIES|!REQUEST_COOKIES:/__utm/|!REQUEST_COOKIES:/_pk_ref/|REQUEST_COOKIES_NAMES|ARGS_NAMES|ARGS|XML:/* "@rx (?i)union" "phase:2,id:'81300813',ctl:ruleEngine={{mode}},t:none,t:urlDecodeUni,t:lowercase,log,deny,log,setvar:'tx.sqli_select_statement=%{matched_var}',severity:'2'"
SecRule TX:SQLI_SELECT_STATEMENT "@containsWord union" "phase:2,id:'98131313',ctl:ruleEngine={{mode}},t:none,deny,log,setvar:tx.sqli_select_statement_count=+1,setvar:tx.sql_injection_score=+1,severity:'2'"

SecRule REQUEST_COOKIES|!REQUEST_COOKIES:/__utm/|!REQUEST_COOKIES:/_pk_ref/|REQUEST_COOKIES_NAMES|ARGS_NAMES|ARGS|XML:/* "@rx (?i)union" "phase:2,id:'81300814',ctl:ruleEngine={{mode}},t:none,t:urlDecodeUni,t:lowercase,log,deny,log,setvar:'tx.sqli_select_statement=%{matched_var}',severity:'2'"
SecRule TX:SQLI_SELECT_STATEMENT "@contains union all" "phase:2,id:'98131414',ctl:ruleEngine={{mode}},t:none,deny,log,setvar:tx.sqli_select_statement_count=+1,setvar:tx.sql_injection_score=+1,severity:'2'"

SecRule REQUEST_COOKIES|!REQUEST_COOKIES:/__utm/|!REQUEST_COOKIES:/_pk_ref/|REQUEST_COOKIES_NAMES|ARGS_NAMES|ARGS|XML:/* "@rx (?i)(rownum as(?!s))" "phase:2,id:'81300815',ctl:ruleEngine={{mode}},t:none,t:urlDecodeUni,t:lowercase,log,deny,log,setvar:'tx.sqli_select_statement=%{matched_var}',severity:'2'"
SecRule TX:SQLI_SELECT_STATEMENT "@contains rownum as" "phase:2,id:'98131515',ctl:ruleEngine={{mode}},t:none,deny,log,setvar:tx.sqli_select_statement_count=+1,setvar:tx.sql_injection_score=+1,severity:'2'"

SecRule REQUEST_COOKIES|!REQUEST_COOKIES:/__utm/|!REQUEST_COOKIES:/_pk_ref/|REQUEST_COOKIES_NAMES|ARGS_NAMES|ARGS|XML:/* "@rx (?i)\(case" "phase:2,id:'81300816',ctl:ruleEngine={{mode}},t:none,t:urlDecodeUni,t:lowercase,log,deny,log,setvar:'tx.sqli_select_statement=%{matched_var}',severity:'2'"
SecRule TX:SQLI_SELECT_STATEMENT "@contains (case" "phase:2,id:'98131616',ctl:ruleEngine={{mode}},t:none,deny,log,setvar:tx.sqli_select_statement_count=+1,setvar:tx.sql_injection_score=+1,severity:'2'"

SecRule TX:SQLI_SELECT_STATEMENT_COUNT "@ge 3" "phase:2,t:none,block,id:'98131717',ctl:ruleEngine={{mode}},deny,rev:'2',ver:'OWASP_CRS/2.2.9',maturity:'8',accuracy:'8',msg:'SQL SELECT Statement Anomaly Detection Alert',logdata:'Matched Data: %{TX.0} found within %{MATCHED_VAR_NAME}: %{MATCHED_VAR}',tag:'OWASP_CRS/WEB_ATTACK/SQL_INJECTION',tag:'WASCTC/WASC-19',tag:'OWASP_TOP_10/A1',tag:'OWASP_AppSensor/CIE1',tag:'PCI/6.5.2',setvar:tx.anomaly_score=+%{tx.warning_anomaly_score},setvar:tx.sql_injection_score=+1,setvar:'tx.msg=%{rule.msg}',setvar:tx.%{rule.id}-OWASP_CRS/WEB_ATTACK/SQL_INJECTION-%{matched_var_name}=%{tx.0},severity:'2'"
# zulRule:End



\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ tshark 

	- https://www.openssl.org/docs/manmaster/apps/ciphers.html  								===> get the cypher names and their abreviations for usage w/ curl;
	- curl -v --ciphers RSA https://www.zulu.com/wp-content/themes/namo-child/style.css 		===> 
	- sudo tshark -nn -x -o "ssl.desegment_ssl_records: TRUE" \
		-o "ssl.desegment_ssl_application_data: TRUE" \
		-o "ssl.keys_list:178.62.131.40,443,http,/usr/local/openresty/nginx/conf/ssl/star_zulu_com.key" \
		-o "ssl.debug_file:rsa_private.log" -Y "(tcp.port eq 443)" port 443 and src host 82.140.178.99
	- ssl_decrypt_pre_master_secret key exchange 0 different from KEX_RSA (16) 				===> Wireshark does not see a RSA key exchange and is therefore not able to do decryption based on the servers private key. If you take a look at the ServerHello message, you can see that a DH cipher has been chosen: Cipher Suite: TLS_DHE_RSA_WITH_AES_256_CBC_SHA (0x0039) ... so basically PFS;

	- http://packetpushers.net/using-wireshark-to-decode-ssltls-packets/
	- http://pauldotcom.com/2010/10/tsharkwireshark-ssl-decryption.html
	- tshark -r <file> -nn -R tcp.port==<port> -d tcp.port==<port>,ssl -o "ssl.keys_list: <ip>,<port>,<data>,<private_key_path>" -V > output.file

	sudo tshark -nn -x -o "ssl.desegment_ssl_records: TRUE" -o "ssl.desegment_ssl_application_data: TRUE" -o "ssl.keys_list:172.31.64.149,443,http,/usr/local/openresty/nginx/conf/ssl/www.zuzu.com.key" -o "ssl.debug_file:rsa_private.log" -Y "(tcp.port eq 443)" port 443 and dst host 216.220.52.167

	sudo tshark -nn -x -o "ssl.desegment_ssl_records: TRUE" -o "ssl.desegment_ssl_application_data: TRUE" -o "ssl.keys_list:172.31.64.149,443,http,/usr/local/openresty/nginx/conf/ssl/www.zuzu.com.key" -o "ssl.debug_file:rsa_private.log" -Y "(tcp.port eq 443)" dst port 443 and dst host 172.31.64.149

	ssl_certificate ssl/SAN_1.crt;
	ssl_certificate_key ssl/SAN_1.key;
	ssl_protocols SSLv2 SSLv3 TLSv1 TLSv1.1 TLSv1.2;
	ssl_prefer_server_ciphers on; 						# Specifies that server ciphers should be preferred over client ciphers when using the SSLv3 and TLS protocols.
	ssl_ciphers 'ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-AES256-GCM-SHA384:DHE-RSA-AES128-GCM-SHA256:DHE-DSS-AES128-GCM-SHA256:kEDH+AESGCM:ECDHE-RSA-AES128-SHA256:ECDHE-ECDSA-AES128-SHA256:ECDHE-RSA-AES128-SHA:ECDHE-ECDSA-AES128-SHA:ECDHE-RSA-AES256-SHA384:ECDHE-ECDSA-AES256-SHA384:ECDHE-RSA-AES256-SHA:ECDHE-ECDSA-AES256-SHA:DHE-RSA-AES128-SHA256:DHE-RSA-AES128-SHA:DHE-DSS-AES128-SHA256:DHE-RSA-AES256-SHA256:DHE-DSS-AES256-SHA:DHE-RSA-AES256-SHA:AES128-GCM-SHA256:AES256-GCM-SHA384:AES128-SHA256:AES256-SHA256:AES128-SHA:AES256-SHA:AES:CAMELLIA:DES-CBC3-SHA:!aNULL:!eNULL:!EXPORT:!DES:!RC4:!MD5:!PSK:!aECDH:!EDH-DSS-DES-CBC3-SHA:!EDH-RSA-DES-CBC3-SHA:!KRB5-DES-CBC3-SHA';
	ssl_dhparam dhparams.pem;

	2016/05/10 07:24:52 [info] 32547#0: *28297 SSL_do_handshake() failed (SSL: error:1408A0C1:SSL routines:SSL3_GET_CLIENT_HELLO:no shared cipher) while SSL handshaking, client: 206.128.156.45, server: 0.0.0.0:443
	2016/05/10 07:24:53 [error] 32553#0: check time out with peer: 52.8.76.227:443

	zulu@ec2-us-east-node40-soc:/usr/local/openresty/nginx/logs$ O=$(openssl ciphers); echo $O | perl -pne 's/:/\n/g' | grep RSA
	ECDHE-RSA-AES256-GCM-SHA384
	ECDHE-RSA-AES256-SHA384
	ECDHE-RSA-AES256-SHA
	SRP-RSA-AES-256-CBC-SHA
	DHE-RSA-AES256-GCM-SHA384
	DHE-RSA-AES256-SHA256
	DHE-RSA-AES256-SHA
	DHE-RSA-CAMELLIA256-SHA
	ECDH-RSA-AES256-GCM-SHA384
	ECDH-RSA-AES256-SHA384
	ECDH-RSA-AES256-SHA
	ECDHE-RSA-DES-CBC3-SHA
	SRP-RSA-3DES-EDE-CBC-SHA
	EDH-RSA-DES-CBC3-SHA
	ECDH-RSA-DES-CBC3-SHA
	ECDHE-RSA-AES128-GCM-SHA256
	ECDHE-RSA-AES128-SHA256
	ECDHE-RSA-AES128-SHA
	SRP-RSA-AES-128-CBC-SHA
	DHE-RSA-AES128-GCM-SHA256
	DHE-RSA-AES128-SHA256
	DHE-RSA-AES128-SHA
	DHE-RSA-SEED-SHA
	DHE-RSA-CAMELLIA128-SHA
	ECDH-RSA-AES128-GCM-SHA256
	ECDH-RSA-AES128-SHA256
	ECDH-RSA-AES128-SHA
	ECDHE-RSA-RC4-SHA
	ECDH-RSA-RC4-SHA
	EDH-RSA-DES-CBC-SHA


	443 https
	636 ldaps
	989 ftps-data
	990 ftps
	992 telnets
	993 imaps
	994 ircs
	995 pop3s
	5061 sips

	Valid dissectors are:
	'http' TCP 443
	'smtp' TCP 465
	'ldap' TCP 636
	'imap' TCP 993
	'pop' TCP 995
	'q931.tpkt' TCP 1300
	'skinny' TCP 2443
	'sip.tcp' TCP 5061


	zulu@ec2-us-east-node40-soc:/usr/local/openresty/nginx/logs$ sudo tshark -v
			tshark: Lua: Error during loading:
			 [string "/usr/share/wireshark/init.lua"]:46: dofile has been disabled due to running Wireshark as superuser. See http://wiki.wireshark.org/CaptureSetup/CapturePrivileges for help in running Wireshark as an unprivileged user.
			TShark 1.10.6 (v1.10.6 from master-1.10)

			Copyright 1998-2014 Gerald Combs <gerald@wireshark.org> and contributors.
			This is free software; see the source for copying conditions. There is NO
			warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.

			Compiled (64-bit) with GLib 2.39.91, with libpcap, with libz 1.2.8, with POSIX
			capabilities (Linux), without libnl, with SMI 0.4.8, with c-ares 1.10.0, with
			Lua 5.2, without Python, with GnuTLS 2.12.23, with Gcrypt 1.5.3, with MIT
			Kerberos, with GeoIP.

			Running on Linux 3.13.0-48-generic, with locale en_US.UTF-8, with libpcap
			version 1.5.3, with libz 1.2.8.
			      Intel(R) Xeon(R) CPU E5-2670 v2 @ 2.50GHz

			Built using gcc 4.8.2.


	any, anyipv4, anyipv6

	TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256

	ECDHE_RSA 		===> The key exchange algorithm, is used to determine if and how the client and server will authenticate during the handshake.[7]
	AES_128_GCM 	===> The bulk encryption algorithm, is used to encrypt the message stream. It also includes the key size and the lengths of explicit and implicit initialization vectors (cryptographic nonces).[8]
	SHA256 		 	===> The message authentication code algorithm, is used to create the message digest, a cryptographic hash of each block of the message stream.[8]
	The pseudorandom function, e.g. TLS 1.2's PRF using the MAC algorithm's hash function, is used to create the master secret, a 48-byte secret shared between the two peers in the connection. The master secret is used as a source of entropy when creating session keys, such as the one used to create the MAC.[9]

	openssl ciphers -v  | grep "Kx=RSA" 	===> to find the needed key exchange
		AES256-GCM-SHA384       TLSv1.2 Kx=RSA      Au=RSA  Enc=AESGCM(256) 	Mac=AEAD
		AES256-SHA256           TLSv1.2 Kx=RSA      Au=RSA  Enc=AES(256)  		Mac=SHA256
		AES256-SHA              SSLv3 Kx=RSA      	Au=RSA  Enc=AES(256)  		Mac=SHA1
		CAMELLIA256-SHA         SSLv3 Kx=RSA      	Au=RSA  Enc=Camellia(256) 	Mac=SHA1
		DES-CBC3-SHA            SSLv3 Kx=RSA      	Au=RSA  Enc=3DES(168) 		Mac=SHA1
		AES128-GCM-SHA256       TLSv1.2 Kx=RSA      Au=RSA  Enc=AESGCM(128) 	Mac=AEAD
		AES128-SHA256           TLSv1.2 Kx=RSA      Au=RSA  Enc=AES(128)  		Mac=SHA256
		AES128-SHA              SSLv3 Kx=RSA      	Au=RSA  Enc=AES(128)  		Mac=SHA1
		SEED-SHA                SSLv3 Kx=RSA      	Au=RSA  Enc=SEED(128) 		Mac=SHA1
		CAMELLIA128-SHA         SSLv3 Kx=RSA      	Au=RSA  Enc=Camellia(128) 	Mac=SHA1
		RC4-SHA                 SSLv3 Kx=RSA      	Au=RSA  Enc=RC4(128)  		Mac=SHA1
		RC4-MD5                 SSLv3 Kx=RSA      	Au=RSA  Enc=RC4(128)  		Mac=MD5 
		DES-CBC-SHA             SSLv3 Kx=RSA      	Au=RSA  Enc=DES(56)   		Mac=SHA1



	Note that only RSA key exchanges can be decrypted using this RSA private key, Diffie-Hellman key exchanges cannot be decrypted using a RSA key file! (See "SSLKEYLOGFILE" if you have such a capture.)


	Processing:
		-2                       perform a two-pass analysis 									===>
		-R <read filter>         packet Read filter in Wireshark display filter syntax 			===>
		-Y <display filter>      packet displaY filter in Wireshark display filter syntax 		===>
		-X <key>:<value>         eXtension options, see the man page for details 				===>
		-z <statistics>          various statistics, see the man page for details				===>
		-o <name>:<value>		   override preference setting 									===> ssl.keys_list: 127.0.0.1,443,http,/tmp/privkey.pem; <=== with the private key file
		-l                       flush standard output after each packet 						===>
		-K <keytab>              keytab file to use for kerberos decryption 					===> ???

	Preferences:
		- zulu@rc-node1:~$ tshark -G defaultprefs | grep ssl
			#http.ssl.port: 443
			#ldap.ssl.port: 636
			#ssl.debug_file:
			#ssl.keys_list: 							===> <SERVER_IP><SERVER_PORT:443><PROTOCOL_FOR_TLS:http><FULL_PATH_TO_KEY>
														===> once key is imported you will see:
																Private key imported: KeyID 20:98:fd:ef:f8:11:74:da:a5:99:37:d2:fb:94:c6:c7:...
																ssl_load_key: swapping p and q parameters and recomputing u
																ssl_init IPv4 addr '178.62.131.40' (178.62.131.40) port '443' filename '/usr/local/openresty/nginx/conf/ssl/star_zulu_com.key' password(only for p12 file) ''
																ssl_init private key file /usr/local/openresty/nginx/conf/ssl/star_zulu_com.key successfully loaded.
																association_add TCP port 443 protocol http handle 0x1b2f710

			#ssl.desegment_ssl_records: TRUE
			#ssl.desegment_ssl_application_data: TRUE
			#ssl.ignore_ssl_mac_failed: FALSE
			#ssl.psk:
			#ssl.keylog_file:

	I have 3 files:
		star_zulu_com.crt ===> this is the digital certificate file used with a web browser.
		star_zulu_com.csr ===> Certificate Signing request is a block of encrypted text that is generated on the server that the certificate will be used on. It contains 								  information that will be included in your certificate such as your organization name, common name (domain name), locality, and country.
		star_zulu_com.key ===> private key


sudo tshark -x -2 -d tcp.port==443,http 															===> -x = hex and ascii, -2 = two pass, -d <layer_type>==<selector>,<decode_as_protocol> 
sudo tshark -f "udp port 1812" -i eth0 -w /tmp/capture.cap 											===> -f = filter
sudo tshark -i eth0 -f "ether[12:2] = 0x888e" 														===> filters with byte matching
tshark -2 -o "tcp.desegment_tcp_streams:TRUE" -R "http.response" -T fields -e http.response.code	===> 

sudo tshark -x -2 -d tcp.port==443,http -R "ip.src==82.140.178.99" 	===>
sudo tshark -x -2 host 178.62.182.48 								===>
sudo tshark -VR 'ssl.handshake.type == 1' 							===> works fine even when desegmentation of ssl application data is not performed



////////// Funny 

	- http://www.mongodb-is-web-scale.com/

///////// Synchronous vs async 

	Synchronous:
	|---A---||--B--||-C-|

	Asynchronous:
	 |----A---------------|
	    |-----B-----|
	        	|-------C------|

////////// Vagrant
	
	- Download aind install 64 bit version of the newest vagrant 	===> https://www.vagrantup.com/downloads.html
	- vagrant box add ubuntu/trusty64 --provider virtualbox 		===> add vm image to your images
	- vagrant init ubuntu/trusty64 --provider virtualbox 			===> create a vm with a user and all that
	- vagrant up
	- vagrant ssh
	- vagrant reload  												===> reload VM after modifying the vagrantFile
	- vagrant halt 													===> shut down the machine gracefully
	- vagrant halt -f 												===> force shutdown
	- vagrant package 												===> create a package of the current state of your VM, share it or recreate it after you destroy it
	- vagrant destroy first_box										===> destroy the VM
	- vagrant box remove ubuntu/trusty64 --box-version 20150422.0.0 ===> remove a box
	- vagrant plugin update
	- vagrant plugin update vagrant-parallels
	- vagrant box update <box-name>

	Networking{
		- Default routing table:
				Kernel IP routing table
				Destination     Gateway         Genmask         Flags Metric Ref    Use Iface
				default         ip-10-0-2-2.ec2 0.0.0.0         UG    0      0        0 eth0
				10.0.2.0        *               255.255.255.0   U     0      0        0 eth0
				192.168.0.0     *               255.255.255.0   U     0      0        0 eth1
				192.168.0.0     *               255.255.255.0   U     0      0        0 eth2

				vagrant@node3:~$ route -n
				Kernel IP routing table
				Destination     Gateway         Genmask         Flags Metric Ref    Use Iface
				0.0.0.0         10.0.2.2        0.0.0.0         UG    0      0        0 eth0
				10.0.2.0        0.0.0.0         255.255.255.0   U     0      0        0 eth0
				192.168.0.0     0.0.0.0         255.255.255.0   U     0      0        0 eth1
				192.168.0.0     0.0.0.0         255.255.255.0   U     0      0        0 eth2

				vagrant@node3:~$ ip route get 91.234.200.113
				91.234.200.113 via 10.0.2.2 dev eth0  src 10.0.2.15 


	}

	Resources {
		- http://s0.cyberciti.org/uploads/cms/2014/10/states.jpg 	===> state diagram
		-
	}

	To-do:
		- where are all the images stored;
		- how to uninstall the vm;
		- how to run multiple vm's with the same image 
				===> http://docs.vagrantup.com/v2/multi-machine/
				===> http://kiennt.com/blog/2012/06/28/using-vagrant-to-setup-multiple-virtual-machie.html
				===> http://friendsofvagrant.github.io/v1/docs/multivm.html
		- install all needed things from the node: https://zulu.atlassian.net/wiki/display/DEVOPS/Edge+node+deployment+-+with+Openresty+from+source
		- create a real nodeAgent and all that
		- create another VM to experiment with nginx source code

	Done:
		- Are files deleted and packages wiped out when up update the vagrant box 	===> install nginx, create a file, update and see 	===> NO, you can safelly update as nothing is deleted

////////// Ansible

	Install from source {
		- sudo apt-get update
		- sudo apt-get install python-pip python-dev git -y
		- sudo pip install PyYAML jinja2 paramiko
		- git clone https://github.com/ansible/ansible.git
		- cd ansible
		- make install
		- mkdir /etc/ansible
		- cp ~/ansible/examples/hosts /etc/ansible/
	}
	Install from APT package repo {
		- sudo apt-get install software-properties-common
		- sudo apt-add-repository ppa:ansible/ansible
		- sudo apt-get update
		- sudo apt-get install ansible
	}
	- ansible --version 
	- ansible nodes -l node01 -m ping 		===>
	- ansible node01 -m ping 				===>
	- ansible webservers -a "free -m"  		===> the same way you can use grep as a command;

	- ansible all -m ping -s -k -u vagrant
		- all - Use all defined servers from the inventory file
		-m ping - Use the "ping" module, which simply runs the ping command and returns the results
		-s - Use "sudo" to run the commands
		-k - Ask for a password rather than use key-based authentication
		-u vagrant - Log into servers using user vagrant

	- ansible all -s -m shell -a 'apt-get install nginx' 												===> -s {sudo}, -m shell {module:shell}, -a {arguments} 'args';
	- ansible all -l 54.67.97.5 -m shell -a 'tail -f /usr/local/openresty/nginx/logs/waf/smb_waf.log'	===> ... you still need to define the hosts pattern {all}, even with the -l flag


	zulu@ansible:/opt/soc$ sudo ansible all -l prod-node -m shell -a 'curl http://52.8.139.100/ -H "Host: www.discountramps.com" -D - -s -o /dev/null' | grep HTTP
	HTTP/1.1 200 OK
	HTTP/1.1 200 OK
	HTTP/1.1 200 OK
	HTTP/1.1 200 OK
	HTTP/1.1 200 OK
	HTTP/1.1 200 OK
 
	ansible all -l 52.29.53.241,52.29.15.88 --list-hosts 												===> print's back the hosts you listed if any of them matched;
																											\ zulu@ansible:/etc/ansible$ ansible all -l 54.67.97.255 --list-hosts
																											\ No hosts matched


ansible all -m shell -a 'tail -f /usr/local/openresty/nginx/logs/php2-mindaugasb.c9.io'
ansible prod-node-ec2-us-east -m shell -a 'nc -v -z -w 2 38.115.1.28 443'`
ansible all -m shell -a 'nc -v -z -w 2 38.115.1.28 443'`

ansible all -m shell -a 'tail -f /usr/local/openresty/nginx/conf/websites/'

	Using ansible in ZE {
		- /etc/ansible 																									===> where ansible actually exists;
		- ansible-playbook auth_keys_dev.yml -t auth_keys 																===> run a playbook > tag auth_keys with ansible. This tag can 																		exist in any of the roles files. And role is just a directory containing all sorts of configuration files.
		- zulu@ansible:/etc/ansible/roles/base/files/home/zulu/.ssh/authorized_keys_dev 								===> where the authorized_keys are;
		- ansible-playbook --limit '!hoost1' yourPlaybook.yml 															===> exclude one host;
		- ansible-playbook --limit '!hoost1:!host2' yourPlaybook.yml 													===> exclude multiple hosts;
		- ansible-playbook -l 52.2.14.223,52.20.153.254 openresty_node_rc.yml -t nginx_conf 							===> deploy nginx config to the specified nodes;
		- ansible-playbook playbooks/openresty_node_rc.yml -l 52.2.14.223 -t heka,nginx_conf,lua_json_logs,logstash
		- ansible prod-nginx -m shell -a "grep keepalive /usr/local/openresty/nginx/conf/nginx.conf" 					===> grep keepalive from all production nodes;
		- ansible-playbook playbooks/build_prod_node.yml -e "region=us-west-1 hostname=test-host1 count=1 redis_ip=172.31.13.117" ===> build a node in AWS with this command;
	}		

////////// SSL certificates testing

	- openssl x509 -enddate -noout -in dojo-rc.zulu.com.crt 										===> check certificate expiration date;
	- openssl req -x509 -newkey rsa:2048 -keyout key.pem -out cert.pem -days 666 -nodes             ===> Generate a self signed certificate. nodes for "no pass phrase"
	- echo | openssl s_client -connect www.family.me:443 2>/dev/null | openssl x509 -noout -dates   ===> check valid before and after dates for a domain;
	- openssl x509 -startdate -enddate -noout -in star_family_me.crt                                ===> check valid before and after dates for a certificate from the file;
	- openssl x509 -in www.bingovega.com.crt -text -noout                                           ===> get all information from a certificate
																			To know whether the issuer is self signed? Compare the issuer and subject. If they are same, it is self signed 
																				- subject= /C=LT/ST=Kaunas/L=Kaunas/O=zulu/OU=Hacking dep./CN=minis/emailAddress=minis@ze.com
																				- issuer= /C=LT/ST=Kaunas/L=Kaunas/O=zulu/OU=Hacking dep./CN=minis/emailAddress=minis@ze.com

////////// Company deletion SQL's

/* 
* Company deletion SQL's
*/

/* select information about the company */

	SELECT name, state FROM companies 
	WHERE name like '%MindCorp%'
	;

/* select information about the webapps of that company */

	SELECT domain, 
		state 
	 FROM webapps 
	 WHERE company_id = (
		SELECT id FROM companies 
		WHERE name like '%MindCorp%'
	  )
	;

/* select all the rules */

	SELECT 	email,
		deleted_at
	 FROM accounts 
	 WHERE company_id = (
		SELECT id FROM companies WHERE name like '%MindCorp%'
	 )
	;


////////// Tools 

	- http://www.sysdig.org/install/




/////////////// Collaborative rules example

# zulRule:Start
# @Title SQL Keyword Anomaly Scoring
# @Description detects common SQL keywords anomalies
# @id 981300,981301,981302,981303,981304,981305,981306,981307,981308,981309,981310,981311,981312,981313,981314,981315,981316,981317
# @tags SQL Injections, WASCTC, OWASP TOP 10, OWASP A1, PCI
# @References http://example.com/WAF-Testing/JS/displayName.js?a=select&b=union&c=top&top=where
SecRule REQUEST_COOKIES|!REQUEST_COOKIES:/__utm/|!REQUEST_COOKIES:/_pk_ref/|REQUEST_COOKIES_NAMES|ARGS_NAMES|ARGS|XML:/* "@pm select show top distinct from dual where group by order having limit offset union rownum as (case" "phase:2,id:'981300',t:none,t:urlDecodeUni,t:lowercase,nolog,pass,setvar:'tx.sqli_select_statement=%{tx.sqli_select_statement} %{matched_var}',setvar:'tx.sqli_anomaly_matches=%{tx.sqli_anomaly_matches} keyword: [%{matched_var}] in [%{matched_var_name}];',severity:'2'"
SecRule TX:SQLI_SELECT_STATEMENT "@containsWord select" "phase:2,id:'981301',t:none,nolog,pass,setvar:tx.sqli_select_statement_count=+1,setvar:tx.sql_injection_score=+1,severity:'2'"
SecRule TX:SQLI_SELECT_STATEMENT "@containsWord show" "phase:2,id:'981302',t:none,nolog,pass,setvar:tx.sqli_select_statement_count=+1,setvar:tx.sql_injection_score=+1,severity:'2'"
SecRule TX:SQLI_SELECT_STATEMENT "@containsWord top" "phase:2,id:'981303',t:none,nolog,pass,setvar:tx.sqli_select_statement_count=+1,setvar:tx.sql_injection_score=+1,severity:'2'"
SecRule TX:SQLI_SELECT_STATEMENT "@containsWord distinct" "phase:2,id:'981304',t:none,nolog,pass,setvar:tx.sqli_select_statement_count=+1,setvar:tx.sql_injection_score=+1,severity:'2'"
SecRule TX:SQLI_SELECT_STATEMENT "@containsWord from" "phase:2,id:'981305',t:none,nolog,pass,setvar:tx.sqli_select_statement_count=+1,setvar:tx.sql_injection_score=+1,severity:'2'"
SecRule TX:SQLI_SELECT_STATEMENT "@containsWord dual" "phase:2,id:'981306',t:none,nolog,pass,setvar:tx.sqli_select_statement_count=+1,setvar:tx.sql_injection_score=+1,severity:'2'"
SecRule TX:SQLI_SELECT_STATEMENT "@containsWord where" "phase:2,id:'981307',t:none,nolog,pass,setvar:tx.sqli_select_statement_count=+1,setvar:tx.sql_injection_score=+1,severity:'2'"
SecRule TX:SQLI_SELECT_STATEMENT "@contains group by" "phase:2,id:'981308',t:none,nolog,pass,setvar:tx.sqli_select_statement_count=+1,setvar:tx.sql_injection_score=+1,severity:'2'"
SecRule TX:SQLI_SELECT_STATEMENT "@contains order by" "phase:2,id:'981309',t:none,nolog,pass,setvar:tx.sqli_select_statement_count=+1,setvar:tx.sql_injection_score=+1,severity:'2'"
SecRule TX:SQLI_SELECT_STATEMENT "@containsWord having" "phase:2,id:'981310',t:none,nolog,pass,setvar:tx.sqli_select_statement_count=+1,setvar:tx.sql_injection_score=+1,severity:'2'"
SecRule TX:SQLI_SELECT_STATEMENT "@containsWord limit" "phase:2,id:'981311',t:none,nolog,pass,setvar:tx.sqli_select_statement_count=+1,setvar:tx.sql_injection_score=+1,severity:'2'"
SecRule TX:SQLI_SELECT_STATEMENT "@containsWord offset" "phase:2,id:'981312',t:none,nolog,pass,setvar:tx.sqli_select_statement_count=+1,setvar:tx.sql_injection_score=+1,severity:'2'"
SecRule TX:SQLI_SELECT_STATEMENT "@containsWord union" "phase:2,id:'981313',t:none,nolog,pass,setvar:tx.sqli_select_statement_count=+1,setvar:tx.sql_injection_score=+1,severity:'2'"
SecRule TX:SQLI_SELECT_STATEMENT "@contains union all" "phase:2,id:'981314',t:none,nolog,pass,setvar:tx.sqli_select_statement_count=+1,setvar:tx.sql_injection_score=+1,severity:'2'"
SecRule TX:SQLI_SELECT_STATEMENT "@contains rownum as" "phase:2,id:'981315',t:none,nolog,pass,setvar:tx.sqli_select_statement_count=+1,setvar:tx.sql_injection_score=+1,severity:'2'"
SecRule TX:SQLI_SELECT_STATEMENT "@contains (case" "phase:2,id:'981316',t:none,nolog,pass,setvar:tx.sqli_select_statement_count=+1,setvar:tx.sql_injection_score=+1,severity:'2'"
SecRule TX:SQLI_SELECT_STATEMENT_COUNT "@ge 3" "phase:2,t:none,block,id:'981317',ctl:ruleEngine={{mode}},rev:'2',ver:'OWASP_CRS/2.2.9',maturity:'8',accuracy:'8',msg:'SQL Keyword Anomaly Detection. Matched Data:%{tx.sqli_anomaly_matches}',logdata:'Matched Data: %{TX.0} found within %{MATCHED_VAR_NAME}:PCIss %{MATCHED_VAR}',tag:'OWASP_CRS/WEB_ATTACK/SQdL_INJECTION',tag:'WASCTC/WASC-19',tag:'OWASP_TOP_10/A1',tag:'OWASP_AppSensor/CIE1',tag:'PCI/6.5.2',setvar:tx.anomaly_score=+%{tx.warning_anomaly_score},setvar:tx.sql_injection_score=+1,setvar:'tx.msg=%{rule.msg}',setvar:tx.%{rule.id}-OWASP_CRS/WEB_ATTACK/SQL_INJECTION-%{matched_var_name}=%{tx.0},severity:'2'"
# zulRule:End

/////////////// skipAfter example

# http://php2-mindaugasb.c9.io/empty_file.html?1=xxx&2=b&3=c&z=v
SecRule ARGS:1 "!@pm xxx" \
        "phase:2, \
        msg:'Matched Data: %{TX.0} found within %{MATCHED_VAR_NAME}: %{MATCHED_VAR}', \
        id:'1', \
        severity:'2', \
        nolog, \
        pass, \
        skipAfter:TEST"
        
SecRule ARGS "b" \
        "phase:2, \
        msg:'Matched Data: %{TX.0} found within %{MATCHED_VAR_NAME}: %{MATCHED_VAR}', \
        id:'2', \
        ctl:ruleEngine=DetectionOnly, \
        severity:'2'"

SecRule ARGS "c" \
        "phase:2, \
        msg:'Matched Data: %{TX.0} found within %{MATCHED_VAR_NAME}: %{MATCHED_VAR}', \
        id:'3', \
        ctl:ruleEngine=DetectionOnly, \
        severity:'2'"
SecMarker TEST


SecRule ARGS:z "!@pm d" \
        "phase:2, \
        msg:'Matched Data: %{TX.0} found within %{MATCHED_VAR_NAME}: %{MATCHED_VAR}', \
        id:'4', \
        ctl:ruleEngine=DetectionOnly, \
        severity:'2'"

/////////////// SSH key-pair generation

	- ssh-keygen -t rsa -b 4096 -C "some _label_to_recognize_key"
	- Enter file in which to save the key (/Users/you/.ssh/id_rsa): [Press enter]
	- Enter passphrase (empty for no passphrase): [Type a passphrase]
	- Enter same passphrase again: [Type passphrase again] 							===> strong pass phrase is recomended
	- eval "$(ssh-agent -s)"
	- ssh-add ~/.ssh/id_rsa
	- ssh-keygen -y -f private_keys/ssh-private-key 								===> generate public key from private key
	- ssh-keygen -lf /dev/stdin <<< $( ssh-keygen -f ~/.ssh/private.key -y ) 		===> check the fingerprint (-l) of the key, directly from the private key (-y generates the public key from private).
																							does not work with passphrase protected files

/////////////// Apache Portable Runtime C library

	Download: http://apr.apache.org/download.cgi

	- export P=$HOME/apr
	- tar zxvf apr-1.2.7.tar.gz
	- cd apr-1.2.7
	- ./configure --prefix=$P
	- make && make install

	- tar zxvf apr-util-...
	- cd apr-util-...
	- ./configure --prefix=$P --with-apr=$P/bin/apr-1-config
	- make && make install


///////////// Debuging
	
	- When debugging you might have a section of code that works, and s seemingly identical situation or set of code that does not.  How do you resolve it? One of these things is not like the others... One of these things just doesn't belong....
	- 


///////////// HA proxy

	 - /etc/haproxy/haproxy.cfg 


///////////// NSONE API

	- curl -s -X GET -H 'X-NSONE-Key: f4eyWHxLmUgoYPS9D1Z3' https://api.nsone.net/v1/zones/zulu.net 								
	- curl -s -X GET -H 'X-NSONE-Key: 'q0JkvMS9776dw4p6cFSi' https://api.nsone.net/v1/zones/zulurc.net 							===> RC env.
	- curl -s -X GET -H 'X-NSONE-Key: q0JkvMS9776dw4p6cFSi' https://api.nsone.net/v1/zones/zulurc.net | python -m json.tool 		===> pretty-print json;

Security {
	Tools {
		LIST: https://www.youtube.com/channel/UC99NRXEKhZKQ7INNJfH5rGw/videos
		- dirbuster ===> DirBuster is a java application that will brute force web directories and filenames on a web server / virtual host;
		- skipfish {
			- ./skipfish -o output_dir -S existing_dictionary.wl -W new_dictionary_for_future.wl http://www.example.com/path 
			- https://code.google.com/p/skipfish/wiki/SkipfishDoc
		}
		- w3af 		===> 
		- vega 		===>
		- arachni 	===>
	}

	- netstat -ant | awk '{print $6}' | sort | uniq -c | sort -n
		- LISTEN 		===> waiting to receive a synchronize (SYN) message from a client. Not included in the output unless you specify the --listening (-l) or --all (-a) option.
		- FIN_WAIT1 	===> A device in this state is waiting for an ACK for a FIN it has sent, or is waiting for a connection termination request from the other device.
		- SYN_RECV 		===> Server just received SYN from the client.
		- LAST_ACK 		===> A device that has already received a close request and acknowledged it, has sent its own FIN and is waiting for an ACK to this request.
		- FIN_WAIT2 	===> Client just received acknowledgment of its first FIN from the server. Connection is closed, and the socket is waiting for a shutdown from the remote end.
		- CLOSE_WAIT 	===> Indicates passive close. Server just received first FIN from a client.
		- SYN_SENT 		===> The device (normally a client) has sent a synchronize (SYN) message and is waiting for a matching SYN from the other device (usually a server).
		- TIME_WAIT 	===> The device has now received a FIN from the other device and acknowledged it, and sent its own FIN and received an ACK for it. We are done, except for waiting to ensure the ACK is received and prevent potential overlap with new connections.
		- ESTABLISHED 	===> Client received server's SYN and session is established.
}

	CAA - Onerror eventhandler - {

		- http://qa1.zuzu.ca/Home/Travel/Cruises/Fall-Cruise-2015.aspx?utm_source=MembershipRewardsHP&utm_medium=Slider3&utm_campaign=Fall-Cruise-2015#<img/src/onerror=console.log(a())>
		- URL structure: protocol://address:port/path1/â€¦/path2?query#anchor 	===> anchor identifier has the remarkable property of never being sent to the server by the browser! 
		- â€œ<a name=foobar></a>â€ 												===> will, for instance, be scrolled to the top whenever you visit it with a URL that ends with â€œ#foobarâ€.
		- Destination anchors in HTML documents may be specified either by the A element (naming it with the name attribute), or by any other element (naming with the id attribute).
		- This attribute [name] names the current anchor so that it may be the destination of another link. The value of this attribute must be a unique anchor name. The scope of this name is the current document. Note that this attribute shares the same name space as the id attribute.

		<form>
			<input type="text" name="exploit" id="exploitid" onfocus="alert(1)" />
		</form>

		- Loading that with a link to formpage.html#exploit or formpage.html#exploitid will pop up an â€˜alertâ€™ dialog box.
	}

}



Webpagetest.org {
	Scripting {
		navigate 	http://www.zulu.com
		setDNSName 	www.zulu.com 		wildcard.zulu.com.edgekey.net

		navigate	www.yoogiscloset.com
		setDns		www.yoogiscloset.com	52.8.68.133
	}
}



C PROGRAMMING {

    Best qoute on C {
        ---------------------
        - But, C is not to blame for this state of affairs. No my friends, your computer and the Operating System controlling it are the real tricksters. They conspire to hide their true inner workings from you so that you can never really know what is going on. The C programming language's only failing is giving you access to what is really there, and telling you the cold hard raw truth. C gives you the red pill. C pulls the curtain back to show you the wizard. C is truth. Why use C then if it's so dangerous? Because C gives you power over the false reality of abstraction and liberates you from stupidity.
        ---------------------
        - In programming nested structures are all over the place. You will find functions that call other functions that have if-statements that have arrays with arrays inside arrays.
        ---------------------
    }

	TODO:
	http://stackoverflow.com/questions/308695/how-to-concatenate-const-literal-strings-in-c
	https://www.google.com/search?q=c+valid+modes+for+opening+a+file&ie=utf-8&oe=utf-8
	http://www.gnu.org/software/libc/manual/html_node/Opening-and-Closing-Files.html
	https://www.google.com/search?q=c+ceonver+string+to+int&ie=utf-8&oe=utf-8#q=c+convert+string+to+int
	http://stackoverflow.com/questions/3420629/convert-string-to-integer-sscanf-or-atoi
	https://www.google.com/search?q=records+in+c&ie=utf-8&oe=utf-8
	http://stackoverflow.com/questions/1991667/how-to-add-records-struct-in-a-function-in-the-c-programming-language
	https://www.google.com/search?q=header+for+file+handling+in+c&ie=utf-8&oe=utf-8
	https://www.google.com/search?q=function+to+return+pointer+withing+a+file&ie=utf-8&oe=utf-8#q=function+to+return+pointer+within+a+file
	https://www.gnu.org/software/octave/doc/interpreter/File-Positioning.html
	http://www.mkssoftware.com/docs/man3/ftell.3.asp
	https://www.google.com/search?q=c+allocate++and+initialize+to+0&ie=utf-8&oe=utf-8
	http://stackoverflow.com/questions/1538420/difference-between-malloc-and-calloc
	http://stackoverflow.com/questions/8029584/why-does-malloc-initialize-the-values-to-0-in-gcc
	http://stackoverflow.com/questions/3449031/c-calloc-v-malloc
	https://www.google.com/search?q=c+format+data+in+memory&ie=utf-8&oe=utf-8
    http://www.cs.fsu.edu/~myers/c++/notes/c_io.html
    http://coreinterview.blogspot.com/2013/02/sprintf-sscanf-functions-for-formatting-data-in-memory.html
    https://www.google.com/search?q=xor+encryption+in+c&ie=utf-8&oe=utf-8#q=xor+encryption+in+c+algorithm
    http://stackoverflow.com/questions/20579363/how-to-decrypt-simple-xor-encryption
    http://www.cprogramming.com/tutorial/xor.html
    http://stackoverflow.com/questions/8072868/simple-xor-algorithm
    http://stackoverflow.com/questions/3649026/how-to-display-hexadecimal-numbers-in-c
    https://www.google.com/search?q=c+convert+fahrenheit+to+celclius&ie=utf-8&oe=utf-8#q=c+convert+fahrenheit+to+celsius
    http://stackoverflow.com/questions/4890480/converting-fahrenheit-to-celsius-in-c
    https://www.google.com/search?q=scnaf+float&ie=utf-8&oe=utf-8#q=scanf+float
    http://beej.us/guide/bgc/output/html/multipage/scanf.html
    http://stackoverflow.com/questions/1343890/rounding-number-to-2-decimal-places-in-c
    https://www.google.com/search?q=check+palindromes+in+c&ie=utf-8&oe=utf-8
    http://www.programiz.com/c-programming/examples/palindrome-number
    http://www.programmingsimplified.com/c-program-find-palindrome
    https://www.google.com/search?q=lowercase+a+string+in+x&ie=utf-8&oe=utf-8#q=lowercase+a+string+in+c
    http://stackoverflow.com/questions/2661766/c-convert-a-mixed-case-string-to-all-lower-case
    http://stackoverflow.com/questions/8534274/is-the-strrev-function-not-available-in-linux
    

    - Q :: What will this return and why? {
        #include <stdio.h>
        #include <string.h>
 
        int main(int argc, char *argv[])
        {
           char str1[5] = "abcde";
           char str2[5] = " haha";
 
           printf("%s\n", str1); // will print "abcde haha", because the strings are likelly to be stored adjecently to each other + abcde is 6 bytes in size, not 5;
           return 0;
        }
    }
    - CFLAGS="-Wall" make <source_name_without_the_extension>       ===> compile with all the compiler warnings. Explanation {
        ---------------------
        make asks: Does the file ex1 exist already?
        No. Ok, is there another file that starts with ex1?
        Yes, it's called ex1.c. Do I know how to build .c files?
        Yes, I run this command cc ex1.c   -o ex1 to build them.
        I shall make you one ex1 by using cc to build it from ex1.c.
        ---------------------
    }
    - Simple make file {
        ---------------------
        CFLAGS=-Wall -g
 
        all: ex1 # to only need to run "make" for ex1 to compile (not "make ex1")
 
        clean:
           rm -f ex1
        ---------------------
    }
    - Less common escape sequences {
        \a      ===> Bell (speaker beeps)
        \b      ===> Backspace (non-erase)
        \f      ===> Form feed/clear screen
        \r      ===> Carriage Return
        \v      ===> Vertical tab
        \xnn    ===> Hexadecimal character code nn
        \onn    ===> Octal character code nn
        \nn     ===> Octal character code nn
    }
    - Format codes in C{
        http://www.cprogramming.com/tutorial/printf-format-strings.html
            %[flag [+, - , 0, #]]   \
            [min width [5]] \
            [precision [.5, .0]] \
            [length modifier [h, l(+d|i), l(+s), L]] \
            [conversion specifier [d, i, g, x|X]]
        %%                      ===> display percent sign
        <width>.<precision>     ===> width and precision are releated in this way, example: printf( "%8.5f\n", 1.234 ); will print some leading spaces
    }
}

Ruby task {
	chef + ruby + redis + postfix
	parasyti chef cookbook'a, kuris sudiegtu, ir susetupintu
	redis, postfix
	ir visus gaunamus laiskus sukrautu i redis :)
	ir galetum search'int redis'e laikus pagal to/from
}

Programming task for facebook system engineer {
	[23:15] <\dev\ice> pirma:
	[23:15] <\dev\ice> ># Given a list (vector) of length at least j, write a function
	[23:15] <\dev\ice> # &quot;partial_reverse(A, i, j)&quot; that will reverse the items in the array A starting
	[23:15] <\dev\ice> # at i and ending at j. Your choice whether to 0-index or 1-index i and j.
	[23:15] <\dev\ice> # For example, given the array equal to (A, B, C, D, E, F), and using an index starting at 0:
	[23:15] <\dev\ice> #  A = (A, B, C, D, E, F)
	[23:15] <\dev\ice> # partial_reverse(A, 2, 4) -> (A, B, E, D, C, F)
	[23:15] <\dev\ice> # result: (A, B, E, D, C, F)
	[23:16] <\dev\ice> ---------------------------
	[23:16] <\dev\ice> antra:
	[23:16] <\dev\ice> # I want to monitor a value produced from a streaming app; say one of the swap columns from
	[23:16] <\dev\ice> # vmstat. If it goes over a certain value for a certain amount of time I'd like a message printed out.
	[23:16] <\dev\ice> # The command should take standard input and be invoked as:
	[23:16] <\dev\ice> #
	[23:16] <\dev\ice> # yourscript &lt;column&gt; &lt;max_count&gt; &lt;max_value&gt;
	[23:16] <\dev\ice> #
	[23:16] <\dev\ice> # Example: vmstat 1 | yourscript 8 5 200
	[23:16] <\dev\ice> #
	[23:16] <\dev\ice> # That means that when column 8 has gone over 200 for more than 5 times, print something out.
	[23:16] <\dev\ice> # My plan is to leave this running over night and check back on it in the morning.
	- kolegai va cia buvo tokie task'ai per 45min reik padaryt jis padare per 20min as per 40 +-
	--------
	Additional: create a service that shows the real time log count (distinguishing them by linebreaks). It should replace teh number of logs in place;
}

UPWORK {
	Cover letter {
		- Hi, 

		My name is Mindaugas and I saw your job advert, which seemed interesting to me. You can check my general experience in my porfile, of course, but what regards any specifics and my strong sides I believe have some major ones:
		- price,
		- I'm from Lithuania, so working hours should not be a problem;
		- avaialable in the weekends; 
		- have experience working with Linux distros;
		- strong understanding of performance testing principles;
		- excellent english skills;
		- experience in computer networks and cloud platforms;
		- coding skills;

		I have attached my CV as well. 
		Would be smilling all week for this oportunity :)
		Thanks in advance.
	}
}

virtual box {
	- resize the disk {
		- https://www.youtube.com/watch?v=r_UyKufXR3c
		- take screenshots of the settings before starting
		- detach the disk 
		- quit virtualbox
		- backup the *.vdi file before you start with cp
		- cp "Lenovo Windows 7 x64 0.2 (no Panda).vdi" "Lenovo Windows 7 x64 0.2 (no Panda)_bak.vdi"
		- VBoxManage internalcommands sethduuid "/home/user/VirtualBox VMs/drupal/drupal.vhd"
		- vboxmanage modifyhd "Lenovo Windows 7 x64 0.2 (no Panda).vdi" --resize 45000
		- Reattach, see if you have the same settings as in the screenshots ... and boot
	}

	- .\VBOXMANAGE.EXE internalcommands sethduuid "F:\..\.vmdk"  	===> to reattach a moved vbox disk you need regenerate uuid;
	- VBoxManage internalcommands sethduuid "/home/user/../drupal.vhd" 	===> On Linux

	- PROBLEM :: SIGSEGV IN THE ORACLE EXTENSION PACK DUE TO UBUNTU SHUTTING DOWN AFTER SLEEP {
    		- SOLUTION 1: REINSTALL EXTENSION PACK
    		- VBoxManage list extpacks 					===> check the extension packs that currently exist;
    		- sudo find / -name "*Oracle_VM_VirtualBox_Extension_Pack*"	===> find the extension pack;
    	- SOLUTION 2: REINSTALL VIRTUALBOX
    }
} Synonyms: virtualbox, virtual box, oracle virtual box;

VMWARE PLAYER{
	Guest additions installation, problem with kernel headers {
		- sudo apt-get update && sudo apt-get install build-essential linux-headers-$(uname -r)
		- sudo ln -s /usr/src/linux-headers-$(uname -r)/include/generated/uapi/linux/version.h /usr/src/linux-headers-$(uname -r)/include/linux/version.h
	}
} Synonyms: vmware player, vm, vmware, vmwareplayer, player;

ARACHNI {

	bin/arachni http://rc.zulu.com/ --report-save-path=/Users/Mindaugas/Downloads/arachni-1.1-0.5.7/report1.afr --mods=xss_* 					===> run in CLI mode, only specific modules;
	bin/arachni http://php2-mindaugasb.c9.io/WAF-Testing/File_Upload_Download/ --report-save-path=/Users/Mindaugas/arachni-1.1-0.5.7/report1.afr 	===> --||---
	../bin/arachni_reporter ../report1.afr --reporter=xml:outfile=my_report.xml 																	===> convert report;
	perl -T arachni2modsec.pl -f bin/my_report.xml 																									===> generate virtual patch;

	Can't locate Acme/Comment.pm in @INC (you may need to install the Acme::Comment module)
	sudo perl -MCPAN -e shell
	install Acme::Comment

	Can't locate Switch.pm
	sudo cpan -f Switch


	SQL Injection
	Cross-site Scripting
	Remote File Inclusion
	Local File Inclusion
	HTTP Response Splitting

	arachni2modsec.pl script fixing {
		#!/opt/local/bin/perl -T

		#############################################
		# -=[ Virtual Patching Converter Script ]=- #
		#       Converts arachni XML Ouput          #
		#    https://github.com/Zapotek/arachni     #
		#                                           #
		#           arachni2modsec.pl               #
		#             Version: 1.0                  #
		#                                           #
		#            Copyright 2011                 #
		#   Trustwave's SpiderLabs Research Team    #
		#           www.trustwave.com               #
		#                                           #
		#   Based On Code Originally Created by:    #
		#            The Denim Group                #
		#          www.denimgroup.com               #
		#############################################

		use XML::Smart;
		use Switch;
		use Data::Types qw(:all);
		use Data::Validate::URI qw(is_uri);
		use Getopt::Std;
		use Acme::Comment type=>'C++', one_line=>1; #Block commenting, can be removed later
		use Data::Dump 'dump';

		#############
		# Variables #
		#############

		# [Configuration Vars]
		my %param;
		getopt("f",\%param);
		$filename = $param{f};
		my $all_vulnerabilities_filename = "$filename";

		unless ($filename) {
		    print "Flag:\n\n\t -f:\t path to arachni xml report file\nUsage:\n\n\t./arachni2modsec.pl -f ./arachni_report.xml\n\n";
		    exit;
		}


		my $modsec_rules_file = "./modsecurity_crs_48_virtual_patches.conf";

		# [End Config Vars]

		my $VULN_CLASS_XSS = "Cross-Site Scripting (XSS)";
		my $VULN_CLASS_SQLI = "SQL Injection";
		my $VULN_CLASS_BLIND_SQLI = "Blind SQL Injection";
		my $VULN_CLASS_LFI = "Path Traversal";
		my $VULN_CLASS_RFI = "Remote file inclusion";
		my $VULN_CLASS_HTTPRS = "Response splitting";

		# Only the vulnerabilities in this array will have
		# rules generated for them.
		my @supported_vulns = ($VULN_CLASS_XSS, $VULN_CLASS_SQLI, $VULN_CLASS_BLIND_SQLI, $VULN_CLASS_LFI, $VULN_CLASS_RFI, $VULN_CLASS_HTTPRS);

		my $num_rules_generated=0;
		my $num_not_supported=0;
		my $num_bad_urls=0;

		my $wait_for_keypress=1;
		my $request_failed=0;

		my $all_vulns_xml;
		my @type;
		my @id;
		my $vuln_count;

		my $num_attacks_flag=0;
		my $num_attacks_noflag=0;

		# End Vars ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

		#############
		#   Main    #
		#############

		# Clean up env so perl doesn't complain
		# when trying to run the restart snort
		# script.
		delete @ENV{qw(IFS CDPATH ENV BASH_ENV PATH)};

		$all_vulns_xml = XML::Smart->new($all_vulnerabilities_filename);

		# my $other_xml = XML::Smart->new("test.xml");
		# my $other_xml = XML::Smart->new("test2.xml");
		# print "my test xml\n";
		# dump $other_xml;
		# print "---------------------------------------------------------------------------------\n";
		# print "parse xml\n";

		# print $other_xml->{CATALOG}{CD}{YEAR}; 			# working
		# print $other_xml->{CATALOG}{CD}{YEAR}[1]; 			# working
		# my @array_of_years = $other_xml->{CATALOG}{CD}('[@]', YEAR);	# takes first YEAR tag values from each CD tag
		# foreach(@array_of_years)
		# {
		#	print "$_\r\n"
		# }

		# my @array_of_years2 = $other_xml->{CATALOG}{CD}{YEAR};
		# foreach(@array_of_years2)
		# {
		# 	print "$_\r\n"
		# }

		# print "All_vulns_xml :" . "$all_vulns_xml \n";
		# print "vuln_class :" . "$VULN_CLASS_XSS \n";
		# print "all_v_filename: " . "$all_vulnerabilities_filename \n";

		 @type = $all_vulns_xml->{report}{issues}{issue}('[@]','name');
		 @url = $all_vulns_xml->{arachni_report}{issues}{issue}('[@]','url');
		 @param = $all_vulns_xml->{arachni_report}{issues}{issue}('[@]','variable');

		# print "@type";
		# print "@url";
		# print "@param";

		foreach(@type){
			print "$_\r\n"
		}
		# foreach(@url){
		# 	print "$_\r\n"
		# }
		# foreach(@param){
		# 	print "$_\r\n"
		# }

		# print "dump\n";
		# dump @type;
		# print $all_vulns_xml->{arachni_report}{issues}{issue}('[@]','name');

		# open(my $MODSEC_RULES, '>' , $modsec_rules_file) || die "Unable to open modsecurity rules file $modsec_rules_file";
		# $MODSEC_RULES->autoflush(1);

		# $vuln_count = 0;

		# foreach my $current_type (@type){
		#   print "==================================================================================================\n";
		#   print "Vulnerability[$vuln_count] -  Type: $current_type\n";

		#   if(exists {map { $_ => 1 } @supported_vulns}->{$current_type}){
		#     parseData(to_string($current_type));
		#   }else {
		#     print "Vulnerability Type: $type is not supported in this version.\n";
		#     $num_not_supported++;
		#   }
		#   $vuln_count++;
		# }

		# close($MODSEC_RULES);
	}

}


sys_template_v9{
		proxy_cache_path cache/<%= @domain %> levels=2:2 keys_zone=<%= @domain %>:100m inactive=60d max_size=10g;

		<% if @webapp_iprate_limit.enabled %>
		  <%= template_partial('_zone_limit_requests_per_ip') %>
		<% end %>

		upstream <%= @domain %>_http {
		  server 127.0.0.1:60080;
		}

		<% if @webapp.ssl_enabled %>
		upstream <%= @domain %>_https {
		  server 127.0.0.1:60443;
		}
		<% end %>

		server {
		  listen 80;
		  listen 8000 proxy_protocol;

		  <% if @webapp.ssl_enabled %>
		    <% if @webapp.spdy_enabled %>
		    listen 443 ssl spdy;
		    listen 8443 ssl spdy proxy_protocol;
		    <% else %>
		    listen 443 ssl;
		    listen 8443 ssl proxy_protocol;
		    listen 9443 ssl proxy_protocol;
		    listen 9000 proxy_protocol;
		    <% end %>
		      
		    <% if @webapp.ssl_certificate %>
		    ssl_certificate ssl/<%= @domain %>.crt;
		    ssl_certificate_key ssl/<%= @domain %>.key;
		    <% end %>
		  <% end %>

		  server_name <%= @domains.join(' ') %>;

		  access_log logs/<%= @domain %>_access.log cache_with_fingerprint if=$loggable;
		  error_log logs/<%= @domain %>_error.log;

		  <% if @webapp.ssl_enabled %>
		  set $PassScheme $scheme;
		  <% else %>
		  set $PassScheme "http";
		  <% end %>

		  <% if @webapp_iprate_limit.enabled %>
		    <%= template_partial('_limit_requests_per_ip') %>
		  <% end %>

		  set $CDNheader "Served-By-zulu";

		  # Caching rules
		  <% @cache_rules.each do |id, rule| %>
		    <%= render_cache_rule(rule) %>
		  <% end %>

		  location / {
		    proxy_pass $PassScheme://<%= @domain %>_$PassScheme;
		    proxy_set_header Host $host;
		    proxy_set_header X-Forwarded-For $remote_addr;
		    add_header X-Cdn $CDNheader;
		    proxy_hide_header Vary;
		    proxy_set_header Accept-Encoding "";
		    add_header X-Cache-Status "NOTCACHED";
		  }
		}

		<% if @webapp.redirect_from_base_domain_
		<% if @webapp.redirect_from_base_domain_enabled? %>			<% if @webapp.redirect_from_base_domain_
		server {	
		  listen 80;	
		  listen 8000 proxy_protocol;	

 		  <% if @webapp.ssl_enabled %>	
		    <% if @webapp.spdy_enabled %>	
		    listen 443 ssl spdy;	
		    listen 8443 ssl spdy proxy_protocol;	
		    <% else %>	
		    listen 443 ssl;	
		    listen 8443 ssl proxy_protocol;	
		    listen 9443 ssl proxy_protocol;	
		    listen 9000 proxy_protocol;	
		    <% end %>	

 		    <% if @webapp.ssl_certificate %>	
		    ssl_certificate ssl/<%= @domain %>.crt;	
		    ssl_certificate_key ssl/<%= @domain %>.key;	
		    <% end %>	
		  <% end %>	

 		  server_name <%= @webapp.base_domain_redirect_from %>;	
		  access_log logs/<%= @domain %>_access.log cache;	
		  error_log logs/<%= @domain %>_error.log;	
		  rewrite ^(.*) $scheme://<%= @domain %>$1 last;	
		}	
		<% end %>	
}	

 GPG/PGP{	
	http://irtfweb.ifa.hawaii.edu/~lockhart/gpg/gpg-cs.html	
	passphrase is set in /etc/zulu.yml	
	gpg --list-keys	
	gpg --export -a "username" > some_redundant_public_key.key	
	gpg --export-secret-key -a 'zulu' > private.key	
	gpg --allow-secret-key-import --import private.key	
	gpg --delete-secret-key "User Name"	
	gpg --delete-key "User Name"	

 } gpg, pgp	

 QA {	
	- https://github.com/minimaxir/big-list-of-naughty-strings 		===> a list of strings that can cause issues when added to the input forms;	
}	

 Security {	
	- https://securityheaders.io/?q=www.happystage.tk 													===> 	
	- http://www.reddit.com/r/netsec/ 																	===> security news and articles	
	- https://www.us-cert.gov/ncas/current-activity														===> new threats	
	- http://wordpress.stackexchange.com/questions/190993/why-use-admin-ajax-php-and-how-does-it-work	===> I wanted to whitelist "admin-ajax.php" AJAX call. 	
																								It is used to pass information the the WP core and can enable communication with different WP functions like DB calls with $wpdb() - so this is a mistake that I could have made.	
	- https://addons.mozilla.org/en-US/firefox/addon/hackbar/ 											===> great hacking addon for FF that allows POST data;	
	- //	
}	

 NTP {	
	server time-a.nist.gov  iburst minpoll 4 maxpoll 6	
	restrict time-a.nist.gov  nomodify notrap noquery	
	server time-b.nist.gov iburst minpoll 4 maxpoll 6	
	restrict time-b.nist.gov nomodify notrap noquery	
}	

 curl -s -u zulubot:123 -XPOST 'https://es.zulu.com/_search' -d '{"query":{"filtered":{"query":{"query_string":{"query":"_type:caching_logs AND webapp_domain:www.ilovesciencestore.com AND hostname:uk.ilovesciencestore.com","analyze_wildcard":false}},"filter":{"bool":{"must":[{"range":{"@timestamp":{"gte":"2016-11-01T00:00:00.001Z","lte":"2016-11-02T23:59:59.999Z"}}}],"must_not":[]}}}},"size":99}' | python -m json.tool	

 curl -s -u zulubot:123 -XPOST 'https://es.zulu.com/_search' -d '{"query":{"filtered":{"query":{"query_string":{"query":"_type:caching_logs AND webapp_domain:www.yell.com AND clientip:86.9.63.240","analyze_wildcard":false}},"filter":{"bool":{"must":[{"range":{"@timestamp":{"gte":"2016-11-0T00:00:00.001Z","lte":"2016-11-0T23:59:59.999Z"}}}],"must_not":[]}}}},"size":999}' | python -m json.tool	


 curl -s -u zulubot:123 -XPOST 'https://es.zulu.com/_search' -d '{"query":{"filtered":{"query":{"query_string":{"query":"webapp_domain:www.allheart.com AND _type:caching_logs AND clientip:91\.210* AND NOT verb:POST","analyze_wildcard":true}},"filter":{"bool":{"must":[{"range":{"@timestamp":{"gte":"2017-01-19T21:05:32.805Z","lte":"2017-01-19T22:43:53.149Z"}}}],"must_not":[]}}}},"size":999}' | python -m json.tool	

 91.210.84.250	

 curl -s -u zulubot:123 -XPOST 'https://es.zulu.com/_search' -d '{"query":{"filtered":{"query":{"query_string":{"query":"webapp_domain:www.allheart.com AND _type:caching_logs AND NOT verb:POST AND clientip:91.210.84.250","analyze_wildcard":true}},"filter":{"bool":{"must":[{"range":{"@timestamp":{"gte":"2017-01-19T21:05:32.805Z","lte":"2017-01-19T22:43:53.149Z"}}}],"must_not":[]}}}},"size":999}' | python -m json.tool	


 curl -s -u zulubot:123 -XPOST 'https://es.zulu.com/_search' -d '{"query":{"filtered":{"query":{"query_string":{"query":"webapp_domain:www.allheart.com AND '_type':'caching_logs' AND NOT verb:POST","analyze_wildcard":true}},"filter":{"bool":{"must":[{"range":{"@timestamp":{"gte":"2017-01-19T21:05:32.805Z","lte":"2017-01-19T22:43:53.149Z"}}}],"must_not":[]}}}},"size":99}' | python -m json.tool	



 curl -s -u zulubot:123 -XPOST 'https://es.zulu.com/2017.01.28/_search' -d '{"query":{"filtered":{"query":{"query_string":{"query":"webapp_domain:www.yell.com AND _type:caching_logs AND clientip:117.207.43.252","analyze_wildcard":"true"}},"filter":{"bool":{"must":[{"range":{"@timestamp":{"gte":"2017-01-28T04:44:00.000Z","lte":"2017-01-28T04:49:00.000Z"}}}],"must_not":[]}}}},"sort":["timestamp"],"size":99}' | python -m json.tool	




 WAF TUNNING TOOLS {	

 	# PARAMS w/ value w/ matched data for rule ID:	

 		result1=$(curl -s -u zulubot:123 -XPOST 'https://es.zulu.com/_search' -d '{"query":{"filtered":{"query":{"query_string":{"query":"_type:modsec_logs AND (action:ENABLED OR action:DETECTION_ONLY) AND (webapp_domain:www.totes.com)","analyze_wildcard":false}},"filter":{"bool":{"must":[{"range":{"@timestamp":{"gte":"2016-04-01T00:00:00.001Z","lte":"2016-04-09T23:59:59.999Z"}}}],"must_not":[]}}}},"size":999999}' | python -m json.tool | grep -P "\"id\": \"400101\"" -A30 -B5); echo "$result1" | grep -oP "\"matched_data\": \"Matched Data:.+found within.+\"" | sort | uniq -c | sort -nr	


 	# PARAMS w/ value w/ matched data for rule ID:	

 		result1=$(curl -s -u zulubot:123 -XPOST 'https://es.zulu.com/_search' -d '{"query":{"filtered":{"query":{"query_string":{"query":"_type:modsec_logs AND (action:ENABLED OR action:DETECTION_ONLY) AND (webapp_domain:www.examples.com)","analyze_wildcard":false}},"filter":{"bool":{"must":[{"range":{"@timestamp":{"gte":"2016-01-01T00:00:00.001Z","lte":"2016-02-25T05:59:59.999Z"}}}],"must_not":[]}}}},"size":999999}' | python -m json.tool | grep -P "\"id\": \"400104\"" -A30 -B5); echo "$result1" | grep -oP "\"matched_data\":\s\"Matched Data:\s*[\w\W]*\s*found within\s\w[\w\W]*(?=:)" | sort | uniq -c | sort -nr	

 	# PARAMS w/o value w/o matched data for rule ID:	

 		result1=$(curl -s -u zulubot:123 -XPOST 'https://es.zulu.com/_search' -d '{"query":{"filtered":{"query":{"query_string":{"query":"_type:modsec_logs AND (action:ENABLED OR action:DETECTION_ONLY) AND (webapp_domain:www.examples.com)","analyze_wildcard":false}},"filter":{"bool":{"must":[{"range":{"@timestamp":{"gte":"2016-01-01T00:00:00.001Z","lte":"2016-02-25T05:59:59.999Z"}}}],"must_not":[]}}}},"size":999}' | python -m json.tool | grep -P "\"id\": \"400104\"" -A30 -B5); echo "$result1" | grep -Po "(?<=found\swithin\s)\w*:\w*" | sort | uniq -c | sort -nr	

 	harvest all the data for the ARG (usefull to check the parameters that have random data, like jsessionid, opmizelly or whatever. Also usefull when trying to find patterns to exclude):	

 		result1=$(curl -s -u zulubot:123 -XPOST 'https://es.zulu.com/_search' -d '{"query":{"filtered":{"query":{"query_string":{"query":"_type:modsec_logs AND (action:ENABLED OR action:DETECTION_ONLY) AND (webapp_domain:www.zuzu.com)","analyze_wildcard":false}},"filter":{"bool":{"must":[{"range":{"@timestamp":{"gte":"2016-03-01T00:00:00.001Z","lte":"2016-03-08T05:59:59.999Z"}}}],"must_not":[]}}}},"size":9999}' | python -m json.tool | grep -P "\"id\": \"981136\"" -A30 -B5); echo "$result1" | grep -P "at ARGS:bbox" | sort | uniq -c | sort -nr	

 	get all the rules by ip:	

 		result1=$(curl -s -u zulubot:123 -XPOST 'https://es.zulu.com/_search' -d '{"query":{"filtered":{"query":{"query_string":{"query":"_type:modsec_logs AND ip:143.95.192.109","analyze_wildcard":false}},"filter":{"bool":{"must":[{"range":{"@timestamp":{"gte":"2016-02-01T00:00:00.001Z","lte":"2016-02-29T05:59:59.999Z"}}}],"must_not":[]}}}},"size":999999}' | python -m json.tool | grep -P "\"message\""); echo "$result1" | sort | uniq -c | sort -nr	

 	argument limit logs investigation:	

 		result1=$(curl -s -u zulubot:123 -XPOST 'https://es.zulu.com/_search' -d '{"query":{"filtered":{"query":{"query_string":{"query":"_type:modsec_logs AND (action:ENABLED OR action:DETECTION_ONLY) AND (webapp_domain: www.jamieoliver.com)","analyze_wildcard":false}},"filter":{"bool":{"must":[{"range":{"@timestamp":{"gte":"2016-03-09T00:00:00.001Z","lte":"2016-03-15T05:59:59.999Z"}}}],"must_not":[]}}}},"size":999999}' | python -m json.tool | grep -P "\"id\": \"960341\"" -A30 -B5); echo "$result1" | grep -P "\"message\": \"Argument value exceeds the limit of 400, argument .+? is \d+ characters long\"" | perl -pne 's/\"message\": \"Argument value exceeds the limit of 400, argument .+? is (\d+) characters long\",/\1/g' | sort -nr | head	


 	purge cache by finding the most accessed URL:	

 		result1=$(curl -s -u zulubot:123 -XPOST 'https://es.zulu.com/_search' -d '{"query":{"filtered":{"query":{"query_string":{"query":"_type:caching_logs AND webapp_domain:www.jamieoliver.com AND request.raw:*wp-admin*","analyze_wildcard":true}},"filter":{"bool":{"must":[{"range":{"@timestamp":{"gte":"2016-03-10T00:00:00.001Z","lte":"2016-03-14T05:59:59.999Z"}}}],"must_not":[]}}}},"size":99999}' | python -m json.tool ); echo "$result1" | grep -Po "\"request\":\s\".+php?" | sort | uniq -c | sort -nr	


 	result1=$(curl -s -u zulubot:123 -XPOST 'https://es.zulu.com/_search' -d '{"query":{"filtered":{"query":{"query_string":{"query":"_type:modsec_logs AND (action:ENABLED OR action:DETECTION_ONLY) AND (webapp_domain:www.examples.com)","analyze_wildcard":false}},"filter":{"bool":{"must":[{"range":{"@timestamp":{"gte":"2016-01-01T00:00:00.001Z","lte":"2016-01-25T05:59:59.999Z"}}}],"must_not":[]}}}},"size":99999}' | python -m json.tool | grep -P "\"id\": \"981080\"" -A30 -B5); echo "$result1" | grep -P "\"data\": " > 981080_matches.txt	


 	http://meyerweb.com/eric/tools/dencoder/	
	http://textmechanic.com/Remove-Duplicate-Lines.html	
	http://www.seo4experts.com/view/subtract_a_from_b.php  ===> list subtraction	



 	ALL PROPOSAL RULES	

 		https://dojo.zulu.com/stg-oaktreecapital-com/waf_logs?utf8=âœ“&rule_ids[]=960335&rule_ids[]=960208&rule_ids[]=960341&rule_ids[]=960032&rule_ids[]=960011&rule_ids[]=960017&rule_ids[]=950012&rule_ids[]=950910&rule_ids[]=950911&rule_ids[]=960015&rule_ids[]=960021&rule_ids[]=960904&rule_ids[]=960007&rule_ids[]=960008&rule_ids[]=960009&rule_ids[]=960006&rule_ids[]=960034&rule_ids[]=960014&rule_ids[]=960012&rule_ids[]=958295&rule_ids[]=950006&rule_ids[]=950907&rule_ids[]=950011&rule_ids[]=950002&rule_ids[]=950005&rule_ids[]=950103&rule_ids[]=1000000&rule_ids[]=1000001&rule_ids[]=1000002&rule_ids[]=1000003&rule_ids[]=1000004&rule_ids[]=950010&rule_ids[]=90004&rule_ids[]=981177&rule_ids[]=981000&rule_ids[]=981001&rule_ids[]=981003&rule_ids[]=2250117&rule_ids[]=2250118&rule_ids[]=2250119&rule_ids[]=2250120&rule_ids[]=2250121&rule_ids[]=950117&rule_ids[]=950120&rule_ids[]=958000&rule_ids[]=958416&rule_ids[]=958005&rule_ids[]=973300&rule_ids[]=973301&rule_ids[]=973302&rule_ids[]=958001&rule_ids[]=973310&rule_ids[]=973337&rule_ids[]=973303&rule_ids[]=973307&rule_ids[]=973338&rule_ids[]=973304&rule_ids[]=973305&rule_ids[]=973306&rule_ids[]=973336&rule_ids[]=958002&rule_ids[]=981136&rule_ids[]=958018&rule_ids[]=958019&rule_ids[]=958057&rule_ids[]=958009&rule_ids[]=958031&rule_ids[]=958051&rule_ids[]=958032&rule_ids[]=958045&rule_ids[]=958046&rule_ids[]=973313&rule_ids[]=958011&rule_ids[]=958006&rule_ids[]=973309&rule_ids[]=973308&rule_ids[]=973312&rule_ids[]=950007&rule_ids[]=950001&rule_ids[]=959070&rule_ids[]=959071&rule_ids[]=959072&rule_ids[]=950908&rule_ids[]=959073&rule_ids[]=981256&rule_ids[]=981244&rule_ids[]=981245&rule_ids[]=981246&rule_ids[]=981250&rule_ids[]=981260&rule_ids[]=981318&rule_ids[]=981241&rule_ids[]=981248&rule_ids[]=981249&rule_ids[]=981247&domains[]=&ips[]=&time=custom&period[from]=Jul 10, 2015 23:59&period[to]=Aug 31, 2015 23:00&per_page=250	

 	ALL ID's for system WAF rules --> copy the HTML from admin/waf_rules and use this regex to get the id's :: /^((?!\d{5}).)*\n/gm	

 		https://dojo.zulu.com/www-examples-com/waf_logs?utf8=âœ“&rule_ids[]=1000004&rule_ids[]=1000000&rule_ids[]=1000001&rule_ids[]=1000002&rule_ids[]=1000003&rule_ids[]=2100019&rule_ids[]=2100023&rule_ids[]=2100026&rule_ids[]=2100027&rule_ids[]=2100028&rule_ids[]=2100032&rule_ids[]=2100033&rule_ids[]=2100034&rule_ids[]=2100035&rule_ids[]=2100048&rule_ids[]=2100062&rule_ids[]=2100063&rule_ids[]=2100069&rule_ids[]=2100070&rule_ids[]=2100082&rule_ids[]=2100083&rule_ids[]=2100084&rule_ids[]=2100085&rule_ids[]=2100086&rule_ids[]=2100087&rule_ids[]=2100088&rule_ids[]=2100089&rule_ids[]=2100090&rule_ids[]=2200924&rule_ids[]=2200926&rule_ids[]=2200925&rule_ids[]=2250118&rule_ids[]=2250119&rule_ids[]=2250117&rule_ids[]=2250120&rule_ids[]=2250121&rule_ids[]=2250122&rule_ids[]=2250123&rule_ids[]=2250124&rule_ids[]=2250125&rule_ids[]=2250126&rule_ids[]=2250127&rule_ids[]=2250128&rule_ids[]=2250129&rule_ids[]=90001&rule_ids[]=90002&rule_ids[]=90004&rule_ids[]=90005&rule_ids[]=90006&rule_ids[]=90007&rule_ids[]=90008&rule_ids[]=90009&rule_ids[]=90010&rule_ids[]=90011&rule_ids[]=90012&rule_ids[]=90013&rule_ids[]=90014&rule_ids[]=90015&rule_ids[]=90016&rule_ids[]=90017&rule_ids[]=90018&rule_ids[]=90019&rule_ids[]=90020&rule_ids[]=90021&rule_ids[]=90022&rule_ids[]=90023&rule_ids[]=90024&rule_ids[]=920021&rule_ids[]=920022&rule_ids[]=920023&rule_ids[]=950001&rule_ids[]=959071&rule_ids[]=959073&rule_ids[]=950908&rule_ids[]=959072&rule_ids[]=959070&rule_ids[]=950002&rule_ids[]=950005&rule_ids[]=950006&rule_ids[]=950007&rule_ids[]=950008&rule_ids[]=950003&rule_ids[]=950009&rule_ids[]=950000&rule_ids[]=950010&rule_ids[]=950011&rule_ids[]=950012&rule_ids[]=950018&rule_ids[]=950019&rule_ids[]=950103&rule_ids[]=950109&rule_ids[]=950108&rule_ids[]=950107&rule_ids[]=950921&rule_ids[]=950922&rule_ids[]=950110&rule_ids[]=950116&rule_ids[]=950117&rule_ids[]=950118&rule_ids[]=950119&rule_ids[]=950120&rule_ids[]=950801&rule_ids[]=950901&rule_ids[]=950907&rule_ids[]=950911&rule_ids[]=950910&rule_ids[]=958000&rule_ids[]=958001&rule_ids[]=958002&rule_ids[]=958003&rule_ids[]=958004&rule_ids[]=958005&rule_ids[]=958006&rule_ids[]=958007&rule_ids[]=958008&rule_ids[]=958009&rule_ids[]=958010&rule_ids[]=958011&rule_ids[]=958012&rule_ids[]=958013&rule_ids[]=958016&rule_ids[]=958017&rule_ids[]=958018&rule_ids[]=958019&rule_ids[]=958020&rule_ids[]=958022&rule_ids[]=958023&rule_ids[]=958024&rule_ids[]=958025&rule_ids[]=958026&rule_ids[]=958027&rule_ids[]=958028&rule_ids[]=958030&rule_ids[]=958031&rule_ids[]=958032&rule_ids[]=958033&rule_ids[]=958034&rule_ids[]=958036&rule_ids[]=958037&rule_ids[]=958038&rule_ids[]=958039&rule_ids[]=958040&rule_ids[]=958041&rule_ids[]=958045&rule_ids[]=958046&rule_ids[]=958047&rule_ids[]=958049&rule_ids[]=958051&rule_ids[]=958052&rule_ids[]=958054&rule_ids[]=958056&rule_ids[]=958057&rule_ids[]=958059&rule_ids[]=958231&rule_ids[]=958291&rule_ids[]=958230&rule_ids[]=958295&rule_ids[]=958404&rule_ids[]=958405&rule_ids[]=958406&rule_ids[]=958407&rule_ids[]=958408&rule_ids[]=958409&rule_ids[]=958410&rule_ids[]=958411&rule_ids[]=958412&rule_ids[]=958413&rule_ids[]=958414&rule_ids[]=958415&rule_ids[]=958416&rule_ids[]=958417&rule_ids[]=958418&rule_ids[]=958419&rule_ids[]=958420&rule_ids[]=958421&rule_ids[]=958422&rule_ids[]=958423&rule_ids[]=959151&rule_ids[]=958976&rule_ids[]=958977&rule_ids[]=960000&rule_ids[]=960008&rule_ids[]=960007&rule_ids[]=960006&rule_ids[]=960009&rule_ids[]=960010&rule_ids[]=960011&rule_ids[]=960012&rule_ids[]=960014&rule_ids[]=960015&rule_ids[]=960021&rule_ids[]=960016&rule_ids[]=960017&rule_ids[]=960020&rule_ids[]=960022&rule_ids[]=960024&rule_ids[]=960032&rule_ids[]=960034&rule_ids[]=960208&rule_ids[]=960209&rule_ids[]=960335&rule_ids[]=960341&rule_ids[]=960901&rule_ids[]=960018&rule_ids[]=960902&rule_ids[]=960904&rule_ids[]=960911&rule_ids[]=960912&rule_ids[]=960914&rule_ids[]=960915&rule_ids[]=970002&rule_ids[]=970003&rule_ids[]=970904&rule_ids[]=970004&rule_ids[]=970007&rule_ids[]=970008&rule_ids[]=970009&rule_ids[]=970010&rule_ids[]=970011&rule_ids[]=970903&rule_ids[]=970012&rule_ids[]=970013&rule_ids[]=970014&rule_ids[]=970902&rule_ids[]=970015&rule_ids[]=970016&rule_ids[]=970018&rule_ids[]=970021&rule_ids[]=970118&rule_ids[]=970901&rule_ids[]=973300&rule_ids[]=973302&rule_ids[]=973301&rule_ids[]=973306&rule_ids[]=973307&rule_ids[]=973309&rule_ids[]=973308&rule_ids[]=973310&rule_ids[]=973311&rule_ids[]=973312&rule_ids[]=973313&rule_ids[]=973314&rule_ids[]=973317&rule_ids[]=973332&rule_ids[]=973344&rule_ids[]=973333&rule_ids[]=973334&rule_ids[]=973331&rule_ids[]=973315&rule_ids[]=973330&rule_ids[]=973327&rule_ids[]=973326&rule_ids[]=973346&rule_ids[]=973345&rule_ids[]=973324&rule_ids[]=973323&rule_ids[]=973322&rule_ids[]=973335&rule_ids[]=973347&rule_ids[]=973318&rule_ids[]=973348&rule_ids[]=973321&rule_ids[]=973320&rule_ids[]=973329&rule_ids[]=973328&rule_ids[]=973316&rule_ids[]=973325&rule_ids[]=973319&rule_ids[]=973336&rule_ids[]=973337&rule_ids[]=973303&rule_ids[]=973304&rule_ids[]=973338&rule_ids[]=973305&rule_ids[]=981004&rule_ids[]=981005&rule_ids[]=981006&rule_ids[]=981007&rule_ids[]=920005&rule_ids[]=920019&rule_ids[]=981078&rule_ids[]=920017&rule_ids[]=920009&rule_ids[]=920011&rule_ids[]=920013&rule_ids[]=920015&rule_ids[]=920007&rule_ids[]=920014&rule_ids[]=981080&rule_ids[]=920020&rule_ids[]=920006&rule_ids[]=920008&rule_ids[]=920010&rule_ids[]=920012&rule_ids[]=920016&rule_ids[]=920018&rule_ids[]=981136&rule_ids[]=981173&rule_ids[]=981172&rule_ids[]=981003&rule_ids[]=981001&rule_ids[]=981177&rule_ids[]=981000&rule_ids[]=981227&rule_ids[]=981231&rule_ids[]=981240&rule_ids[]=981241&rule_ids[]=981243&rule_ids[]=981242&rule_ids[]=981246&rule_ids[]=981244&rule_ids[]=981245&rule_ids[]=981247&rule_ids[]=981249&rule_ids[]=981248&rule_ids[]=981250&rule_ids[]=981251&rule_ids[]=981252&rule_ids[]=981253&rule_ids[]=981254&rule_ids[]=981255&rule_ids[]=981256&rule_ids[]=981257&rule_ids[]=981260&rule_ids[]=981270&rule_ids[]=981272&rule_ids[]=981276&rule_ids[]=981277&rule_ids[]=981313&rule_ids[]=981314&rule_ids[]=981315&rule_ids[]=981316&rule_ids[]=981317&rule_ids[]=981300&rule_ids[]=981301&rule_ids[]=981302&rule_ids[]=981303&rule_ids[]=981304&rule_ids[]=981309&rule_ids[]=981306&rule_ids[]=981307&rule_ids[]=981308&rule_ids[]=981310&rule_ids[]=981311&rule_ids[]=981312&rule_ids[]=981305&rule_ids[]=981318&rule_ids[]=981319&rule_ids[]=981320&domains[]=&ips[]=&time=30_d&period[from]=Jul 18, 2014 23:59&period[to]=Jun 29, 2015 00:00&per_page=250	
}	


 IT CERTIFICATION {	
 	PATHS:	
		Cloud:			
			Azure:
			GCP:
			AWS:
		Devops: 
			DCA (docker): https://training.mirantis.com/dca-certification-exam/
			CKAD (kubern): https://training.linuxfoundation.org/full-catalog/?_sft_product_type=certification
			CKA (kubern): https://training.linuxfoundation.org/full-catalog/?_sft_product_type=certification
		Networking:
			Cisco:		CCNA 		CCNP 		CCIE		CCAr
			Jupiter Nets: 	JNCA ... (and on)
 		Windows:		
					MCSA Server					MCSE Server	
					MCSA App Builder (70-483 C#, 486 ASP.NET MVC) 	MCSD App Builder (487 Azure Web Services)
 		Vmware:			
					VCA		VCP		VCE		VCDX	
 		Linux: 				
			RedHat:		RHCSA		RHCSE		RHCSS	
			Linux Found.:	LFCS 		LCFE	
 		Programming:	
			Python:		PCEP 		PCAP 		PCPP I, II	
			Java		OCA		OCP			
			C: 		CLA		CLP		CLS (available after december 2017)	
			Cpp:		CPA		CPP		CPS (available after december 2017)	
			C#: 		MCSA 		MCSE 		MCSM
			Android: 	AAD Kotlin
 		Security: 		CEH		GIAC GPEN 	GIAC GXPN	GIAC GSE 	CISSP	
		Testing: 		CTFL 		CTAL(tech)	
		Big Data: 		CCP:DS		AWS
		ML: 			Coursera ML 	Deeplearning.ai	
		SQL (DBA): 		Oracle 		Microsoft Data	
		PM: 			PMP	
		General:		CompTIA A+ 	Storage+ 	Network+ 	Security+ 	Project+
		
 	CCNA/P/E {	
		- https://learningnetwork.cisco.com/community/certifications/ccna 				===> main cisco page for ccna / a guide;	
		- http://www.cisco.com/web/partners/downloads/765/tools/quickreference/routerperformance.pdf  	===> to get this, google "cisco router performance numbers" 
		- CCIE - written + 8 hours lab !!! - this is the prep plan: https://www.youtube.com/watch?v=XiCi9P9rJME	
	}	

 	LFCS/LFCE {	
		- https://app.pluralsight.com/library/courses/linux-systems-programming/table-of-contents	
		- https://app.pluralsight.com/library/courses/linux-network-programming/table-of-contents	

 		- https://training.linuxfoundation.org/upcoming-program-changes-for-the-lfcs-certification-exam	
		- http://www.tecmint.com/sed-command-to-create-edit-and-manipulate-files-in-linux/	
		- http://dataminer.lt/linux/lpi-101#kurso-turinys	
	}	
}	

 Pass arguments to curl {	
	- echo 'GET aaa' | cut -d ' ' -f 1,2 | xargs curl -X 		
}	

 DDoS {	
	- hping3 -c 10000 -d 120 -S -w 64 -p 21 --flood --rand-source www.hping3testsite.com;	
		-c 100000 = Number of packets to send.	
		-d 120 = Size of each packet that was sent to target machine.	
		-S = I am sending SYN packets only.	
		-w 64 = TCP window size.	
		-p 21 = Destination port (21 being FTP port). You can use any port here.	
		--flood = Sending packets as fast as possible, without taking care to show incoming replies. Flood mode.	
		--rand-source = Using Random Source IP Addresses. You can also use -a or â€“spoof to hide hostnames. See MAN page below.		
}	

 BGP {	
	- telnet route-views.routeviews.org 		===> telnet to a looking glass router and you will get the username (http://www.routeviews.org/);	
	- route-views>show ip bgp 178.16.44.81 		===> 	
		BGP routing table entry for 178.16.32.0/20, version 110319798	
		Paths: (35 available, best #23, table default)	
		  Not advertised to any peer	
		  Refresh Epoch 1	
		  58511 174 21412, (aggregated by 21412 217.17.85.230)	
		    103.247.3.45 from 103.247.3.45 (103.247.3.45)	
		      Origin IGP, localpref 100, valid, external, atomic-aggregate	
		      rx pathid: 0, tx pathid: 0	
		  Refresh Epoch 1	
		  ...	

 	- route-views>show ip bgp 207.178.0.0/16  	
	% Network not in table	


 	- route-views>show ip bgp 178.16.0.0/16 longer-prefixes 	
		BGP table version is 132769108, local router ID is 128.223.51.103	
		Status codes: s suppressed, d damped, h history, * valid, > best, i - internal, 	
		              r RIB-failure, S Stale, m multipath, b backup-path, f RT-Filter, 	
		              x best-external, a additional-path, c RIB-compressed, 	
		Origin codes: i - IGP, e - EGP, ? - incomplete	
		RPKI validation codes: V valid, I invalid, N Not found	

 		     Network          Next Hop            Metric LocPrf Weight Path	
		 *   178.16.0.0/21    103.247.3.45                           0 58511 13122 i	
		 *                    114.31.199.1                           0 4826 174 13122 i	
		 *                    5.101.110.2                            0 202018 2914 3356 13122 i	
		 ...	
		 *                    207.172.6.20             0             0 6079 3356 13122 i	
		 *>                   216.218.252.164                        0 6939 13122 i	
		 *                    134.222.87.1           250             0 286 3356 13122 i	
		 *                    203.181.248.168                        0 7660 2516 3356 13122 i	
		 *                    128.223.253.10                         0 3582 3701 3356 13122 i	
		 *   178.16.0.0/20    103.247.3.45                           0 58511 13122 i	
		 *                    114.31.199.1                           0 4826 174 13122 i	
		 *                    195.208.112.161                        0 3277 39710 9002 13122 i	
		 ...	

 	- show ip bgp 106.37.0.0/16 longer-prefixes | exclude 286 			===> detect BGP leakage. You have to 	
	- The lower the AS number the more preference it has;	
	- AS prepending - when the same AS number is used multiple times in order to decrease the preference	

 }	

 Javascript {	
	Here are the events in alphabetical order...	

 	- onabort 		===> Loading of an image is interrupted	
	- onblur 		===> An element loses focus	
	- onchange 		===> The user changes the content of a field	
	- onclick 		===> Mouse clicks an object	
	- ondblclick 	===> Mouse doubleclicks an object	
	- onerror 		===> An error occurs when loading a document or an image	
	- onfocus 		===> An element gets focus	
	- onkeydown 	===> A keyboard key is pressed	
	- onkeypress 	===> A keyboard key is pressed or held down	
	- onkeyup 		===> A keyboard key is released	
	- onload 		===> A page or an image is finished loading	
	- onmousedown 	===> A mouse button is pressed	
	- onmousemove 	===> The mouse is moved	
	- onmouseout 	===> The mouse is moved off an element	
	- onmouseover 	===> The mouse is moved over an element	
	- onmouseup 	===> A mouse button is released	
	- onreset 		===> The reset button is clicked	
	- onresize 		===> A window or frame is resized	
	- onselect 		===> Text is selected	
	- onsubmit 		===> The submit button is clicked	
	- onunload 		===> The user exits the page	
	- onpageshow 	===> The onpageshow event is similar to the onload event, except that it occurs after the onload event when the page first loads. Also, the onpageshow event occurs every time the page is loaded, whereas the onload event does not occur when the page is loaded from the cache.	

 	The order of JS events {	
		- To coordinate events, user interaction, scripts, rendering, networking, and so forth, user agents must use event loops as described in this section. There must be at least one event loop per user agent, and at most one event loop per unit of related similar-origin browsing contexts. An event loop has one or more task queues. A task queue is an ordered list of tasks [...] When a user agent is to queue a task, it must add the given task to one of the task queues of the relevant event loop. All the tasks from one particular task source must always be added to the same task queue, but tasks from different task sources may be placed in different task queues. [...] a user agent could have one task queue for mouse and key events (the user interaction task source), and another for everything else. The user agent could then give keyboard and mouse events preference over other tasks three quarters of the time, keeping the interface responsive but not starving other task queues, and never processing events from any one task source out of order. [...]	


 	}	
}	

 SYSCTL {	
	sysctl -w net.ipv4.conf.all.arp_ignore=1  		===> 1 - reply only if the target IP address is local address configured on the incoming interface	
	sysctl -w net.ipv4.conf.all.arp_announce=2 		===> 	
	sysctl -p 										===> read values from file	
}	

 RSYNC {	
	- RSYNC has the advantage of preserving permissions, ownership, and ensuring data integrity.	
	- rsync is faster than scp (secure copy) because it only transfers the diff. It consumes less bandwidth because it has the ability to do compression and decompression on both ends.	
	- rsync options src dst 						===> general usage of rsync	
	- rsync -avzh root@192.168.0.100:/home /tmp 	===> remote to local;	
	- rsync -avzh /tmp root@192.168.0.100:/home 	===> local to remote;	
	- rsync -Pav -e 'ssh -i /path/to/id_rsa -C -c blowfish' user@remote:/remote/dir/ /local/dir/	
		-a, --archive              	archive mode; equals -rlptgoD (no -H,-A,-X) - It is a quick way of saying you want recursion and want to preserve almost everything (with -H being a notable omission). 	
		-r, --recursive            	recurse into directories	
		-P                         	same as --partial --progress	
		-v 							verbose	
	- rsync -Lavz -e "ssh -i /home/vagrant/.ssh/prod_priv.key -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null" --exclude "*.something" --progress zulu@172.31.64.149:/usr/local/openresty/nginx/conf/ /usr/local/	
		--exclude={access_rules,block_page,captcha,js_challenge,threat,waf,websites} 					===> exclude multiple patterns;	
		--exclude-from='/home/ben/exclude_me.txt' 														===> specify the excudes in a file;	

 sudo rsync -Lavz -e "ssh -i /home/vagrant/.ssh/prod_priv.key -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null" \	
--exclude={logs,cache,*_temp,runav.pl,sbin} \	
--progress zulu@172.31.64.149:/usr/local/openresty/ /usr/local/openresty/	

 sudo mkdir -p /usr/local/openresty/nginx/cache/temp	

 sudo rsync -Lavz -e "ssh -i /home/vagrant/.ssh/prod_priv.key -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null" --progress zulu@172.31.64.149:/etc/zulu.yml /etc/zulu.yml	


 	- rsync --help | grep -P "(-P\W|-r\W|-a\W)" 	===> using grep on the --help flag to figure out what is going on in these statments;	
} rsync	

 BASH SCRIPTS {
 		############################################################# - check host icmp reachability in a /28 subnet
		 bernam@ivv-mindaugas-2019-09-23-jump:~$ for i in {33..47} ;do (ping 10.5.0.$i -c 1 -w 1  > /dev/null && printf "\n%s" "10.5.0.$i" &) ;done
		10.5.0.44
		10.5.0.45

		############################################################# - skip expected failures	
 			#!/usr/bin/env bash	

 			# returns success error code - 0 if the execution output of an error matches the expected error pattern. 	
			# Swaps the return code to 0 in case a failure happens that we expect.	
			ignore-error() {	
			    local expected_error=$1	
			    shift	
			#xo - execution output ; xc - execution exit code	
			    local xo; local xc=0	
			    xo=$("$@" 2>&1) || xc=$?	
			    echo "$xo" >&2	
			    [[ $xc -eq 0 || "$xo" = *"$expected_error"* ]] || return $xc	
			}	

 			ignore-error 'files' ls nonexistant	
			echo "$?"	
			ignore-error 'is already installed' ls test.sh	
			echo "$?"	
 		############################################################# batch_create_many_webapps.sh	
			#!/bin/bash	

 			WEB_APP_BEGINNING_INDEX=1000; \	
			WEB_APP_LAST_INDEX=1020; \	
			API_HOME_WEBAPPS="https://dojo-rc.zulu.com/api/v2/webapps/"; \	
			TOKEN_HOME="https://dojo-rc.zulu.com/api/oauth/token"; \	
			client_id="bc2056bf6396e5f060aa10de9b90f909c2f61629435c2dd0378415c5d9a23953"; \	
			client_secret="f9c22a2d88c8d47e55f9f63adec7c3aaa378af3950c6937f6f0bd00365b9b1d4"; \	
			response="$(curl -s -X POST $TOKEN_HOME -F client_id=$client_id -F client_secret=$client_secret)"; \	
			acc_token="$(echo $response | egrep -o "\w{15,}")"	

 			for i in $(seq $WEB_APP_BEGINNING_INDEX $WEB_APP_LAST_INDEX); do	
			        echo "Webapp number $i is being created"	
			        curl -X POST $API_HOME_WEBAPPS?access_token=$acc_token \	
			        -d "{\"name\":\"test$i-mindaugas.com\",\"domain\":\"test$i-mindaugas.com\",\"origin_servers\":[{\"ip\":\"1.1.1.1\",\"port\":\"80\",\"weight\":\"1\"}]}" \	
			        -H "Content-Type:application/json"	
			        echo ""	
			        echo ""	
			done	
		###############################################################	
		#!/bin/bash	

 		URLS=('\"/shop/ccNotify.do\"' '\"/shop/apply-sbpform.ajax\"' '\"/shop/vbv-payload.ajax\"' '\"/shop/ccAuthorization.do\"');	

 		mycurl() {	

 			URL="$1";	

 		  # URLS=('a/a.1'); touch "`date +%Y-%m-%d`_${URLS[0]//[\/.]/-}".log ;	
		  # URLS=('a/a.1'); touch "`date +%Y-%m-%d`_`echo $URLS | perl -pne 's/.+\/(.+?)\..+/\1/g'`".log ;	
		  FILENAME=$(echo "`date +%Y-%m-%d`_`echo $URL | perl -pne 's/.+\/(.+?)\..+/\1/g'`".log);	
		  touch $FILENAME;	

 			curl -s -u zulubot:123 \	
				-XPOST 'https://es.zulu.com/_search' \	
				-d "{\"query\":{\"filtered\":{\"query\":{\"query_string\":{\"query\":\"_type:caching_logs AND webapp_domain:www.examples.com AND request.raw:${URL}\",\"analyze_wildcard\":false}},\"filter\":{\"bool\":{\"must\":[{\"range\":{\"@timestamp\":{\"gte\":\"2016-05-10T00:00:00.001Z\",\"lte\":\"2016-05-10T23:59:59.999Z\"}}}],\"must_not\":[]}}}},\"size\":999}" | \	
				python -m json.tool > $FILENAME	

 		   zip $FILENAME.zip $FILENAME	
		   rm -f $FILENAME	
		}	

 		export -f mycurl	

 		printf '%s\n' "${URLS[@]}" | \	
		parallel --jobs ${#URLS[@]} --load 6 mycurl {}	

 		###############################################################	

 			#!/usr/bin/env bash	

 			############### GLOBALS	
			token_from_user=$1	
			days_into_the_past=100	

 			############### FUNCTION DEFINITIONS	
			function get_hostnames_save_to_file(){	
			  node_hostnames=$( 	
			    sudo ansible -m shell -a "hostname" prod-node | grep -P - | grep -v msg | sort | uniq )	
			  echo "$node_hostnames" > ./hostnames	
			  exit 0	
			}	

 			function sha_calculator(){	
			  the_date=$1	
			  node_hostname=$2	
			  echo -n "${node_hostname}:${the_date}" | sha1sum | awk '{print $1}'	
			}	

 			function generate_days(){	
			  for ((i=0; i<=days_into_the_past; i++)); do	
			    echo $(date -d "-$i day" '+%Y%m%d')	
			  done	
			}	

 			display_help() {	
			  echo	
			  echo "Usage:" >&2	
			  echo "   $0 {-u|-h|token}"	
			  echo "      -u,    update the hostnames file, that can be found in same directory as this script and has all the host names from ansible inventory"	
			  echo "      -h,    display this help function"	
			  echo "      token  the X-zul-Fury header that can be found in the response headers that are returned from zulu servers"	
			  echo	
			  echo "Example:"	
			  echo "   zulu@ansible:~$ ./deconstruct_fury.sh 942cfe7541f6fcb5b8d319c90a2fea51c6d7ba6b"	
			  echo "   ec2-us-east-node09-2xl on 20170126"	
			  echo	
			  exit 1	
			}	

 			function main(){	
			  token_reversed=0	

 			  for day in `generate_days`; do	
			    for node_hostname in `cat ./hostnames`; do	
			      token_reversed=$(sha_calculator $day $node_hostname)	
			      if [ $token_from_user != $token_reversed ]; then continue	
			      else printf "$node_hostname on $day\n" ; exit 0; fi	
			    done	
			  done	
			}	

 			############### INPUT HANDLING	
			if [ -z "$1" ]; then	
			    display_help;	
			fi	

 			if [ "$1" == "-u" ]; then	
			  get_hostnames_save_to_file	
			fi	

 			u_input="$1"	
			if [ "$1" != "-u" ] && [ ${#u_input} -lt 40 ]; then 	
			  echo "The token is two short, has to be 40 bytes (chars) long" ; exit 1	
			fi	

 			############### STARTING POINT	
			main	


 		###############################################################	


 }	

 Installed UBUNTU - now what? {	
	- get root pass and connenct as root;	
	- adduser mb 						===> create a new user;	
	- gpasswd -a demo sudo 				===> give the new user possibility to elevate to root;	
	- sudo visudo 						===> modify sudoers file;	
	- mb ALL=(ALL:ALL) ALL 				===> add this to grant user sudo provileges w/ pass;	
	- mb ALL = NOPASSWD: ALL 			===> add this to grant user sudo provileges no-pass;	
	- mkdir ~/.ssh 						===> create the .ssh dir;	
	- chmod 700 ~/.ssh 					===> grant appropriate privileges;	
	- vim ~/.ssh/authorized_keys 		===> create authorized_keys and add the public key to it;	
	- chmod 600 ~/.ssh/authorized_keys 	===> grant appropriate privileges;	
	- ssh to the node using the keys auth mechanism before disabling root login;	
	- check that you can ssh to the node as root so you would be sure that it was indeed your changes that made effect;	
	- PermitRootLogin no 				===> disallow root ssh access in /etc/ssh/sshd_config;	
	- sudo service ssh restart 			===> restart ssh;	
	- test that root can not login via ssh anymore;	
	- passwd -l username 				===> suspend the possibility to log in for a user using a password;	
	- passwd -u username 				===> allow the user to log in with a password (for example when you need to provide credentials for wordpress plugin update);	
}	

 Octave {	
	format long 					===> display more numbers after the comma: 2.46062823398782e-18	
	b = [ones(size(b, 1), 1) b]; 	===> Add a column to a matrix (usefull when adding bias units);	
	A = 1   2 						===> Will illustrate the behavior of the sum(X, DIM) function.	
	    3   4	
	sum(A) 							===> 4 6	
	sum(A, 1) 						===> 4 6	
	sum(A, 2) 						===> 	3	
											7	
	sum(sum(A,2)) 					===> summing over the rows first, then over the collumns. 	
										Result is the sum of all the numbers in the matrix	
}	

 WGET {	
	 wget --header="Host:devtplsg.torontopubliclibrary.ca" "https://205.189.188.80/rest/v1/auth" --no-check-certificate -nv 	===> ignore certificate errors, use a hosts header	
	 wget -r -p https://stage.goodyear.com --user=digitas --password=*** --auth-no-challenge 									===> download all URLs reachable from the initial starting point https://stage.goodyear.com	
	 wget -r -p http://www.mindaugas.ml/ 2>&1 | grep -- "^--" 																	===> get all URLs reachable from the initial starting point http://www.mindaugas.ml. Choose another 																																	starting point if you know more URLs exist.	
}	

 OPENSSL {	
	openssl s_client -servername devtplsg.torontopubliclibrary.ca  -connect 205.189.188.80:443 									===> SNI example	
	openssl s_client -servername securitycompass.com -connect 52.21.110.142:443	
	openssl s_client -servername securitycompass.com -connect 205.147.88.100:443	
	echo | openssl s_client -showcerts -servername blog.mindaugas.cf -connect 185.69.52.233:443 2>/dev/null | openssl x509 -inform pem -noout -text | grep -P DNS 		===> DNS:*.mindaugas.cf, DNS:mindaugas.cf	

 }	


 Namecheap DNS {	
	freedns1.registrar-servers.com	
	freedns2.registrar-servers.com	
	freedns3.registrar-servers.com 	
	freedns4.registrar-servers.com 	
	freedns5.registrar-servers.com	
}	

 Nmap{	
	nmap --script ssl-enum-ciphers -p 443 vpn.zulu.com 	> 	
	nmap -PnO 149.140.219.94 								> 	
	nmap -sP 192.168.0.0/24 								> Scan a network and find out which servers and devices are up and running	
	nmap 192.168.1.1 192.168.1.2 192.168.1.3 				> Scan multiple instances in the network	
	nmap 192.168.1.0/24 --exclude 192.168.1.10 				> Scan by Excluding a Host	
	nmap --packet-trace 192.168.1.10 						> To See Packets send and receving using Nmap	
	nmap -p 80,22,21,111 									> Scan for a port or multiple ones	
	nmap -p "*" 192.168.1.10 								> Scan all ports	
	nmap -p 9100,515,631 192.168.1.1/24 -oX printers.xml 	> Targeted port-scan	
}	


 Nginx development and debugging {	

 	TESTS: http://search.cpan.org/~agent/Test-Nginx-0.23/lib/Test/Nginx/Socket.pm#response_body	

         ngx_log_error(NGX_LOG_ERR, r->connection->log, 0, 	
        "Mindaugas Debug: \n\	
        r->request_length = %O ;; \n\	
        r->request_body = %d ;; \n\	
        r.request_body_in_single_buf = %d ;; \n\	
        r->request_body->bufs = %d \n\	
        ", 	
        r->request_length, 	
        r->request_body, 	
        r->request_body_in_single_buf, 	
        r->request_body->bufs	
        );	

         // http://lxr.nginx.org/source/src/http/ngx_http_request.h#0026 	
        // 0023 #define NGX_HTTP_VERSION_9                 9	
        // 0024 #define NGX_HTTP_VERSION_10                1000	
        // 0025 #define NGX_HTTP_VERSION_11                1001	
        // 0026 #define NGX_HTTP_VERSION_20                2000	
        // ngx_log_error(NGX_LOG_ERR, r->connection->log, 0, 	
        //     "Mindaugas Debug: r->http_version = %d", 	
        //     r->http_version);	

         // r == ngx_http_request_t == ngx_http_request_s	
        // ngx_http_request_s  { ngx_connection_t  *connection; }	
        //     ngx_connection_t == ngx_connection_s 	
        // ngx_connection_s    {ngx_log_t *log;}	
        // ngx_log_t == ngx_log_s	
        // ngx_log_s           {ngx_open_file_t *file;}	
        // ngx_open_file_t == ngx_open_file_s	
        // ngx_open_file_s     {ngx_str_t name;} // if this was ngx_str_t *name; r->connection->log->file->name would work	
        // ngx_log_error(NGX_LOG_ERR, r->connection->log, 0, 	
        //     "Mindaugas Debug: r->method = %d ;; &r->connection->log->file->name = %V", 	
        //     r->method , &r->connection->log->file->name);	

         // void **ctx;	
        // void **main_conf;	
        // void **srv_conf;	
        // void **loc_conf;	



         // if(r->request_body != NULL ) ngx_log_error(NGX_LOG_ERR, r->connection->log, 0, "Mindaugas Debug: request_body != NULL");	
        // if(r->request_body != "" ) ngx_log_error(NGX_LOG_ERR, r->connection->log, 0, "Mindaugas Debug: request_body != \"\"");	

         // if(r->header_in->last == NULL ) ngx_log_error(NGX_LOG_ERR, r->connection->log, 0, "Mindaugas Debug: r->header_in->last == NULL");	
        // if(r->header_in->pos == NULL ) ngx_log_error(NGX_LOG_ERR, r->connection->log, 0, "Mindaugas Debug: r->header_in->pos == NULL");	
        // if(r->request_body->buf == NULL ) ngx_log_error(NGX_LOG_ERR, r->connection->log, 0, "Mindaugas Debug: r->request_body->buf == NULL");	
        // if(r->request_body->bufs == NULL ) ngx_log_error(NGX_LOG_ERR, r->connection->log, 0, "Mindaugas Debug: r->request_body->bufs == NULL");	
        // ngx_log_error(NGX_LOG_ERR, r->connection->log, 0, "Mindaugas Debug: r->request_body->bufs->buf == %d", r->request_body->bufs->buf);	


         // if (r->request_body->bufs != NULL) { 	
        //     ngx_log_error(NGX_LOG_ERR, r->connection->log, 0, "Mindaugas Debug: r->request_body->bufs == %d", r->request_body->bufs); }	
        // else { 	
        //     ngx_log_error(NGX_LOG_ERR, r->connection->log, 0, "Mindaugas Debug: r->request_body->bufs == NULL" ); }	




         // ngx_log_error(NGX_LOG_ERR, r->connection->log, 0, "Mindaugas Debug: r->header_size=%[0][width][u][x|X]z ;;r->request_length=%[0][width][x][X]O", r->header_size, r->request_length);	
        // ngx_log_error(NGX_LOG_ERR, r->connection->log, 0, 	
        // "Mindaugas Debug: \n\	
        // r->header_size = %z ;; \n\	
        // r->request_length = %O ;; \n\	
        // r->header_only = %d ;; \n\	
        // r->request_body = %d ;; \n\	
        // r.headers_in.content_length_n = %O ;; \n\	
        // r.request_body_in_single_buf = %d ;; \n\	
        // sizeof(r->request_body) = %d ;; \n\	
        // (r->header_in->last - r->header_in->pos) = %d ;; \n\	
        // r->header_only = %d \n\	
        // r->request_body->buf = %d \n\	
        // r->request_body->bufs = %d \n\	
        // r->request_body->bufs->buf = %d \n\	
        // r->request_body->bufs->next = %d \n\	
        // (long long)r->request_body->bufs - (long long)r->request_body->bufs->buf = %d \n\	
        // r->request_body->bufs - r->request_body = %d \n\	
        // sizeof(r->request_body->bufs) = %d \n\	
        // sizeof(r->request_body->bufs->buf) = %d \n\	
        // sizeof(struct ngx_chain_s) = %d \n\	
        // ", 	
        // r->header_size, 	
        // r->request_length, 	
        // r->header_only, 	
        // r->request_body, 	
        // r->headers_in.content_length_n, 	
        // r->request_body_in_single_buf, 	
        // sizeof(r->request_body), 	
        // r->header_in->last - r->header_in->pos, 	
        // r->header_only,	
        // (long long)r->request_body->buf,	
        // (long long)r->request_body->bufs,	
        // r->request_body->bufs->buf,	
        // r->request_body->bufs->next,	
        // (long long)r->request_body->bufs - (long long)r->request_body->bufs->buf,	
        // (long long)r->request_body->bufs - (long long)r->request_body,	
        // sizeof(r->request_body->bufs),	
        // sizeof(r->request_body->bufs->buf),	
        // sizeof(struct ngx_chain_s)	
        // );	

         // ngx_log_error(NGX_LOG_ERR, r->connection->log, 0,	
        //        "Mindaugas Debug: --------------- 2 -------------------"	
        // );	

 }	

 Ipset {	
	- sudo apt-get install xtables-addons-common	
	- sudo apt-get install ipset	
	- sudo ipset create cloudflare_ipv4 hash:net 			===> This creates a new "hash" set of "net" network addresses named "myset".	
	- sudo ipset add myset 14.144.0.0/12 				===> 	
	- sudo iptables -I INPUT -m set --match-set cloudflare_ipv4 src -j DROP	
}	

 GNUplot {	
	- primes 1 1000 | gnuplot -persist -e "set terminal dumb 121 20; set yrange[200:400]; plot '-' with impulses title 'Ping (ms)';"	
	- primes 0 100 | gnuplot -p -e 'set terminal dumb; plot "/dev/stdin"'	
}	

 tmux {	
	- $ tmux 					===> launch a new tmux session, after which you will be able to run a process inside a newly opened shell	
	- ctrl+b -> d 					===> detach from tmux session	
	- tmux attach 					===> attach to the latest tmux session	
	- tmux attach-session -t {number|name} 		===> attach to a specific session when multiple are running	
	- tmux list-sessions 				===> SE	
		0: 1 windows (created Wed Mar  8 07:52:57 2017) [196x56]	
		1: 1 windows (created Wed Mar  8 07:55:07 2017) [196x56]	
	- CTRL+C --> CTRL+D 				===> terminates the process and the tmux session	
}	

 Midnight Commander {	
	- <Tab> 					===> move to a different panel;	
	- alias mc='. /usr/libexec/mc/mc-wrapper.sh' 	===> use this wrapper to navigate to the directory that you were in MC after you have exited MC;	
	- <Insert> / <ctrl+t> 				===> select files (press again to unselect);	
	- + 						===> select based on a pattern (non-regex, * for wildcard);	
	- \ 						===> unselect based on a pattern (non-regex, * for wildcard);	
	- * 						===> reverse selection (files). If nothing was selected, all files will get selected. You can also use 
